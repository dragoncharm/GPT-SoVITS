{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dragoncharm/GPT-SoVITS/blob/main/colab_webui.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "34e3295d-f19e-460a-b9b7-fc5f23c1bbfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNMmJsqIyOat"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: /usr/local/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
            "Running on local URL:  http://0.0.0.0:9874\n",
            "Running on public URL: https://ecc269405413477232.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/uvr5/webui.py \"cuda\" True 9873 True\n",
            "Running on local URL:  http://0.0.0.0:9873\n",
            "Running on public URL: https://930249277b7efc625b.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "Vocal Separation WebUI Process Terminated\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/uvr5/webui.py \"cuda\" True 9873 True\n",
            "Running on local URL:  http://0.0.0.0:9873\n",
            "Running on public URL: https://55ab6ff6edeea07e3f.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "clean_empty_cache\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS/tools/uvr5/webui.py\", line 91, in uvr\n",
            "    if info[\"streams\"][0][\"channels\"] == 2 and info[\"streams\"][0][\"sample_rate\"] == \"44100\":\n",
            "KeyError: 'channels'\n",
            "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
            "  built with gcc 11.2.0 (Anaconda gcc)\n",
            "  configuration: --prefix=/usr/local/envs/GPTSoVITS --cc=/croot/ffmpeg_1743153284778/_build_env/bin/x86_64-conda-linux-gnu-cc --ar=/croot/ffmpeg_1743153284778/_build_env/bin/x86_64-conda-linux-gnu-ar --nm=/croot/ffmpeg_1743153284778/_build_env/bin/x86_64-conda-linux-gnu-nm --ranlib=/croot/ffmpeg_1743153284778/_build_env/bin/x86_64-conda-linux-gnu-ranlib --strip=/croot/ffmpeg_1743153284778/_build_env/bin/x86_64-conda-linux-gnu-strip --disable-doc --enable-swresample --enable-swscale --enable-openssl --enable-libxml2 --enable-libtheora --enable-demuxer=dash --enable-postproc --enable-hardcoded-tables --enable-libfreetype --enable-libharfbuzz --enable-libfontconfig --enable-libdav1d --enable-zlib --enable-libaom --enable-pic --enable-shared --disable-static --disable-gpl --enable-version3 --disable-sdl2 --enable-libopenh264 --enable-libopus --enable-libmp3lame --enable-libopenjpeg --enable-libvorbis --enable-pthreads --enable-libtesseract --enable-libvpx\n",
            "  libavutil      58. 29.100 / 58. 29.100\n",
            "  libavcodec     60. 31.102 / 60. 31.102\n",
            "  libavformat    60. 16.100 / 60. 16.100\n",
            "  libavdevice    60.  3.100 / 60.  3.100\n",
            "  libavfilter     9. 12.100 /  9. 12.100\n",
            "  libswscale      7.  5.100 /  7.  5.100\n",
            "  libswresample   4. 12.100 /  4. 12.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/content/GPT-SoVITS/input/1-1.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2avc1mp41\n",
            "    encoder         : Lavf58.29.100\n",
            "    description     : Packed by Bilibili XCoder v2.0.2\n",
            "  Duration: 00:01:50.92, start: 0.000000, bitrate: 1959 kb/s\n",
            "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 1280x720 [SAR 1:1 DAR 16:9], 1742 kb/s, 30 fps, 30 tbr, 16k tbn (default)\n",
            "    Metadata:\n",
            "      handler_name    : VideoHandler\n",
            "      vendor_id       : [0][0][0][0]\n",
            "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 209 kb/s (default)\n",
            "    Metadata:\n",
            "      handler_name    : SoundHandler\n",
            "      vendor_id       : [0][0][0][0]\n",
            "Stream mapping:\n",
            "  Stream #0:1 -> #0:0 (aac (native) -> pcm_s16le (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, wav, to '/content/GPT-SoVITS/TEMP/1-1.mp4.reformatted.wav':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2avc1mp41\n",
            "    description     : Packed by Bilibili XCoder v2.0.2\n",
            "    ISFT            : Lavf60.16.100\n",
            "  Stream #0:0(und): Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s (default)\n",
            "    Metadata:\n",
            "      handler_name    : SoundHandler\n",
            "      vendor_id       : [0][0][0][0]\n",
            "      encoder         : Lavc60.31.102 pcm_s16le\n",
            "\u001b[1;35m[out#0/wav @ 0x1f1526c0] \u001b[0mvideo:0kB audio:19108kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.000399%\n",
            "size=   19108kB time=00:01:50.89 bitrate=1411.5kbits/s speed= 362x    \n",
            "100% 40/40 [00:03<00:00, 10.20it/s]\n",
            "clean_empty_cache\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/slice_audio.py \"/content/GPT-SoVITS/output/uvr5_opt\" \"output/slicer_opt\" -34 4000 300 10 500 0.9 0.25 0 4\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/slice_audio.py \"/content/GPT-SoVITS/output/uvr5_opt\" \"output/slicer_opt\" -34 4000 300 10 500 0.9 0.25 1 4\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/slice_audio.py \"/content/GPT-SoVITS/output/uvr5_opt\" \"output/slicer_opt\" -34 4000 300 10 500 0.9 0.25 2 4\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/slice_audio.py \"/content/GPT-SoVITS/output/uvr5_opt\" \"output/slicer_opt\" -34 4000 300 10 500 0.9 0.25 3 4\n",
            "Speech Slicing Process Terminated\n",
            "Speech Slicing Process Terminated\n",
            "Speech Slicing Process Terminated\n",
            "Speech Slicing Process Terminated\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/slice_audio.py \"/content/GPT-SoVITS/output/uvr5_opt\" \"output/slicer_opt\" -34 4000 300 10 500 0.9 0.25 0 4\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/slice_audio.py \"/content/GPT-SoVITS/output/uvr5_opt\" \"output/slicer_opt\" -34 4000 300 10 500 0.9 0.25 1 4\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/slice_audio.py \"/content/GPT-SoVITS/output/uvr5_opt\" \"output/slicer_opt\" -34 4000 300 10 500 0.9 0.25 2 4\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/slice_audio.py \"/content/GPT-SoVITS/output/uvr5_opt\" \"output/slicer_opt\" -34 4000 300 10 500 0.9 0.25 3 4\n",
            "执行完毕，请检查输出文件\n",
            "执行完毕，请检查输出文件\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS/tools/my_utils.py\", line 21, in load_audio\n",
            "    ffmpeg.input(file, threads=0)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/ffmpeg/_run.py\", line 325, in run\n",
            "    raise Error('ffmpeg', out, err)\n",
            "ffmpeg._run.Error: ffmpeg error (see stderr output for detail)\n",
            "/content/GPT-SoVITS/output/uvr5_opt/.ipynb_checkpoints ->fail-> Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS/tools/my_utils.py\", line 21, in load_audio\n",
            "    ffmpeg.input(file, threads=0)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/ffmpeg/_run.py\", line 325, in run\n",
            "    raise Error('ffmpeg', out, err)\n",
            "ffmpeg._run.Error: ffmpeg error (see stderr output for detail)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS/tools/slice_audio.py\", line 35, in slice\n",
            "    audio = load_audio(inp_path, 32000)\n",
            "  File \"/content/GPT-SoVITS/tools/my_utils.py\", line 27, in load_audio\n",
            "    raise RuntimeError(i18n(\"音频加载失败\"))\n",
            "RuntimeError: Failed to Load Audio\n",
            "\n",
            "执行完毕，请检查输出文件\n",
            "执行完毕，请检查输出文件\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/slice_audio.py \"/content/GPT-SoVITS/output/uvr5_opt\" \"output/slicer_opt\" -34 4000 300 10 500 0.9 0.25 0 4\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/slice_audio.py \"/content/GPT-SoVITS/output/uvr5_opt\" \"output/slicer_opt\" -34 4000 300 10 500 0.9 0.25 1 4\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/slice_audio.py \"/content/GPT-SoVITS/output/uvr5_opt\" \"output/slicer_opt\" -34 4000 300 10 500 0.9 0.25 2 4\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/slice_audio.py \"/content/GPT-SoVITS/output/uvr5_opt\" \"output/slicer_opt\" -34 4000 300 10 500 0.9 0.25 3 4\n",
            "执行完毕，请检查输出文件\n",
            "执行完毕，请检查输出文件\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS/tools/my_utils.py\", line 21, in load_audio\n",
            "    ffmpeg.input(file, threads=0)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/ffmpeg/_run.py\", line 325, in run\n",
            "    raise Error('ffmpeg', out, err)\n",
            "ffmpeg._run.Error: ffmpeg error (see stderr output for detail)\n",
            "/content/GPT-SoVITS/output/uvr5_opt/.ipynb_checkpoints ->fail-> Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS/tools/my_utils.py\", line 21, in load_audio\n",
            "    ffmpeg.input(file, threads=0)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/ffmpeg/_run.py\", line 325, in run\n",
            "    raise Error('ffmpeg', out, err)\n",
            "ffmpeg._run.Error: ffmpeg error (see stderr output for detail)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS/tools/slice_audio.py\", line 35, in slice\n",
            "    audio = load_audio(inp_path, 32000)\n",
            "  File \"/content/GPT-SoVITS/tools/my_utils.py\", line 27, in load_audio\n",
            "    raise RuntimeError(i18n(\"音频加载失败\"))\n",
            "RuntimeError: Failed to Load Audio\n",
            "\n",
            "执行完毕，请检查输出文件\n",
            "执行完毕，请检查输出文件\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/subfix_webui.py --load_list \"D:/RVC1006/GPT-SoVITS/raw/xxx.list\" --webui_port 9871 --is_share True\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS/tools/subfix_webui.py\", line 304, in <module>\n",
            "    set_global(args.load_json, args.load_list, args.json_key_text, args.json_key_path, args.g_batch)\n",
            "  File \"/content/GPT-SoVITS/tools/subfix_webui.py\", line 289, in set_global\n",
            "    b_load_file()\n",
            "  File \"/content/GPT-SoVITS/tools/subfix_webui.py\", line 268, in b_load_file\n",
            "    b_load_list()\n",
            "  File \"/content/GPT-SoVITS/tools/subfix_webui.py\", line 243, in b_load_list\n",
            "    with open(g_load_file, \"r\", encoding=\"utf-8\") as source:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'D:/RVC1006/GPT-SoVITS/raw/xxx.list'\n",
            "Audio Labeling WebUI Process Terminated\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/asr/funasr_asr.py -i \"output/slicer_opt\" -o \"output/asr_opt\" -s large -l zh -p float32\n",
            "2025-04-28 13:53:49,998 - modelscope - INFO - PyTorch version 2.5.1+cu124 Found.\n",
            "2025-04-28 13:53:49,999 - modelscope - INFO - Loading ast index from /root/.cache/modelscope/ast_indexer\n",
            "2025-04-28 13:53:49,999 - modelscope - INFO - No valid ast index found from /root/.cache/modelscope/ast_indexer, generating ast index from prebuilt!\n",
            "2025-04-28 13:53:50,058 - modelscope - INFO - Loading done! Current index file version is 1.10.0, with md5 9710ac4fb2f8068bd74ea2bbac1a05b0 and a total number of 946 components indexed\n",
            "2025-04-28 13:53:51,968 - modelscope - INFO - Use user-specified model revision: v2.0.4\n",
            "Downloading: 100% 10.9k/10.9k [00:00<00:00, 39.0MB/s]\n",
            "Downloading: 100% 173k/173k [00:00<00:00, 581kB/s]\n",
            "Downloading: 100% 2.45k/2.45k [00:00<00:00, 14.8MB/s]\n",
            "Downloading: 100% 472/472 [00:00<00:00, 2.56MB/s]\n",
            "Downloading: 100% 840M/840M [00:21<00:00, 41.2MB/s]\n",
            "Downloading: 100% 19.1k/19.1k [00:00<00:00, 260kB/s]\n",
            "Downloading: 100% 7.90M/7.90M [00:01<00:00, 8.13MB/s]\n",
            "Downloading: 100% 48.7k/48.7k [00:00<00:00, 336kB/s]\n",
            "Downloading: 100% 91.5k/91.5k [00:00<00:00, 416kB/s]\n",
            "ckpt: /root/.cache/modelscope/hub/iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/model.pt\n",
            "/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/funasr/train_utils/load_pretrained_model.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  src_state = torch.load(path, map_location=map_location)\n",
            "2025-04-28 13:54:33,553 - modelscope - INFO - Use user-specified model revision: v2.0.4\n",
            "Downloading: 100% 7.85k/7.85k [00:00<00:00, 27.5MB/s]\n",
            "Downloading: 100% 1.19k/1.19k [00:00<00:00, 6.34MB/s]\n",
            "Downloading: 100% 365/365 [00:00<00:00, 1.86MB/s]\n",
            "Downloading: 100% 1.64M/1.64M [00:00<00:00, 2.83MB/s]\n",
            "Downloading: 100% 8.45k/8.45k [00:00<00:00, 28.7MB/s]\n",
            "Downloading: 100% 27.3k/27.3k [00:00<00:00, 370kB/s]\n",
            "Downloading: 100% 2.16M/2.16M [00:00<00:00, 3.67MB/s]\n",
            "ckpt: /root/.cache/modelscope/hub/iic/speech_fsmn_vad_zh-cn-16k-common-pytorch/model.pt\n",
            "2025-04-28 13:54:44,022 - modelscope - INFO - Use user-specified model revision: v2.0.4\n",
            "Downloading: 100% 6.00k/6.00k [00:00<00:00, 18.1MB/s]\n",
            "Downloading: 100% 810/810 [00:00<00:00, 4.70MB/s]\n",
            "Downloading: 100% 373/373 [00:00<00:00, 1.65MB/s]\n",
            "Downloading: 100% 278M/278M [00:12<00:00, 23.6MB/s]\n",
            "Downloading: 100% 863/863 [00:00<00:00, 4.96MB/s]\n",
            "Downloading: 100% 11.2k/11.2k [00:00<00:00, 39.0MB/s]\n",
            "Downloading: 100% 151k/151k [00:00<00:00, 506kB/s]\n",
            "Downloading: 100% 4.01M/4.01M [00:00<00:00, 6.13MB/s]\n",
            "ckpt: /root/.cache/modelscope/hub/iic/punc_ct-transformer_zh-cn-common-vocab272727-pytorch/model.pt\n",
            "FunASR 模型加载完成: ZH\n",
            "  0% 0/9 [00:00<?, ?it/s]\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0000000000_0000498560.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  1.32it/s]\u001b[A\n",
            "{'load_data': '0.268', 'extract_feat': '0.165', 'forward': '0.759', 'batch_size': '1', 'rtf': '0.049'}, : 100% 1/1 [00:00<00:00,  1.32it/s]\u001b[A\n",
            "rtf_avg: 0.049: 100% 1/1 [00:00<00:00,  1.32it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/funasr/models/paraformer/model.py:249: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(False):\n",
            "/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/funasr/models/paraformer/cif_predictor.py:212: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(False):\n",
            "\n",
            "\n",
            "100% 1/1 [00:00<00:00,  1.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.019', 'forward': '0.952', 'batch_size': '1', 'rtf': '0.061'}, : 100% 1/1 [00:00<00:00,  1.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.061: 100% 1/1 [00:00<00:00,  1.05it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.068', 'batch_size': '1', 'rtf': '-0.068'}, : 100% 1/1 [00:00<00:00, 14.60it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.068: 100% 1/1 [00:00<00:00, 14.52it/s]\n",
            "\n",
            "100% 1/1 [00:01<00:00,  1.05s/it]\u001b[A\n",
            "rtf_avg: 0.066, time_speech:  15.580, time_escape: 1.028: 100% 1/1 [00:01<00:00,  1.05s/it]\n",
            " 11% 1/9 [00:01<00:14,  1.81s/it]\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0000498560_0000778880.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  5.49it/s]\u001b[A\n",
            "{'load_data': '0.042', 'extract_feat': '0.022', 'forward': '0.182', 'batch_size': '1', 'rtf': '0.021'}, : 100% 1/1 [00:00<00:00,  5.49it/s]\u001b[A\n",
            "rtf_avg: 0.021: 100% 1/1 [00:00<00:00,  5.45it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  4.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.022', 'forward': '0.205', 'batch_size': '1', 'rtf': '0.023'}, : 100% 1/1 [00:00<00:00,  4.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.023: 100% 1/1 [00:00<00:00,  4.82it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.018', 'batch_size': '1', 'rtf': '-0.018'}, : 100% 1/1 [00:00<00:00, 55.99it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.018: 100% 1/1 [00:00<00:00, 54.81it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  3.87it/s]\u001b[A\n",
            "rtf_avg: 0.027, time_speech:  8.760, time_escape: 0.233: 100% 1/1 [00:00<00:00,  3.86it/s]\n",
            " 22% 2/9 [00:02<00:07,  1.01s/it]\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0000778880_0001596160.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  2.20it/s]\u001b[A\n",
            "{'load_data': '0.056', 'extract_feat': '0.062', 'forward': '0.455', 'batch_size': '1', 'rtf': '0.018'}, : 100% 1/1 [00:00<00:00,  2.20it/s]\u001b[A\n",
            "rtf_avg: 0.018: 100% 1/1 [00:00<00:00,  2.19it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  3.15it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.042', 'forward': '0.317', 'batch_size': '1', 'rtf': '0.012'}, : 100% 1/1 [00:00<00:00,  3.15it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.012: 100% 1/1 [00:00<00:00,  3.13it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.034', 'batch_size': '1', 'rtf': '-0.034'}, : 100% 1/1 [00:00<00:00, 29.72it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.034: 100% 1/1 [00:00<00:00, 29.45it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  2.44it/s]\u001b[A\n",
            "rtf_avg: 0.014, time_speech:  25.540, time_escape: 0.361: 100% 1/1 [00:00<00:00,  2.44it/s]\n",
            " 33% 3/9 [00:03<00:05,  1.06it/s]\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0001596160_0002227200.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.03it/s]\u001b[A\n",
            "{'load_data': '0.046', 'extract_feat': '0.047', 'forward': '0.330', 'batch_size': '1', 'rtf': '0.017'}, : 100% 1/1 [00:00<00:00,  3.03it/s]\u001b[A\n",
            "rtf_avg: 0.017: 100% 1/1 [00:00<00:00,  3.02it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  3.46it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.039', 'forward': '0.289', 'batch_size': '1', 'rtf': '0.015'}, : 100% 1/1 [00:00<00:00,  3.46it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.015: 100% 1/1 [00:00<00:00,  3.45it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.040', 'batch_size': '1', 'rtf': '-0.040'}, : 100% 1/1 [00:00<00:00, 25.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.040: 100% 1/1 [00:00<00:00, 24.82it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  2.66it/s]\u001b[A\n",
            "rtf_avg: 0.017, time_speech:  19.720, time_escape: 0.339: 100% 1/1 [00:00<00:00,  2.66it/s]\n",
            " 44% 4/9 [00:03<00:04,  1.18it/s]\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0002227200_0002548480.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  5.04it/s]\u001b[A\n",
            "{'load_data': '0.034', 'extract_feat': '0.026', 'forward': '0.198', 'batch_size': '1', 'rtf': '0.020'}, : 100% 1/1 [00:00<00:00,  5.04it/s]\u001b[A\n",
            "rtf_avg: 0.020: 100% 1/1 [00:00<00:00,  5.01it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  4.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.022', 'forward': '0.223', 'batch_size': '1', 'rtf': '0.022'}, : 100% 1/1 [00:00<00:00,  4.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.022: 100% 1/1 [00:00<00:00,  4.32it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.021', 'batch_size': '1', 'rtf': '-0.021'}, : 100% 1/1 [00:00<00:00, 48.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.021: 100% 1/1 [00:00<00:00, 47.33it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  3.39it/s]\u001b[A\n",
            "rtf_avg: 0.026, time_speech:  10.040, time_escape: 0.261: 100% 1/1 [00:00<00:00,  3.39it/s]\n",
            " 56% 5/9 [00:04<00:02,  1.38it/s]\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0002548480_0002688000.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "{'load_data': '0.028', 'extract_feat': '0.018', 'forward': '0.089', 'batch_size': '1', 'rtf': '0.020'}, : 100% 1/1 [00:00<00:00, 11.26it/s]\u001b[A\n",
            "rtf_avg: 0.020: 100% 1/1 [00:00<00:00, 11.22it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  6.01it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.007', 'forward': '0.166', 'batch_size': '1', 'rtf': '0.038'}, : 100% 1/1 [00:00<00:00,  6.01it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.038: 100% 1/1 [00:00<00:00,  5.98it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.006', 'batch_size': '1', 'rtf': '-0.006'}, : 100% 1/1 [00:00<00:00, 151.85it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.006: 100% 1/1 [00:00<00:00, 146.27it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  5.20it/s]\u001b[A\n",
            "rtf_avg: 0.041, time_speech:  4.360, time_escape: 0.179: 100% 1/1 [00:00<00:00,  5.19it/s]\n",
            " 67% 6/9 [00:04<00:01,  1.74it/s]\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0002688000_0002827520.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "{'load_data': '0.017', 'extract_feat': '0.009', 'forward': '0.069', 'batch_size': '1', 'rtf': '0.016'}, : 100% 1/1 [00:00<00:00, 14.41it/s]\u001b[A\n",
            "rtf_avg: 0.016: 100% 1/1 [00:00<00:00, 14.35it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  9.95it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.007', 'forward': '0.100', 'batch_size': '1', 'rtf': '0.023'}, : 100% 1/1 [00:00<00:00,  9.95it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.023: 100% 1/1 [00:00<00:00,  9.79it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.006', 'batch_size': '1', 'rtf': '-0.006'}, : 100% 1/1 [00:00<00:00, 157.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.006: 100% 1/1 [00:00<00:00, 150.87it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.88it/s]\u001b[A\n",
            "rtf_avg: 0.026, time_speech:  4.360, time_escape: 0.113: 100% 1/1 [00:00<00:00,  7.86it/s]\n",
            " 78% 7/9 [00:04<00:00,  2.22it/s]\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0002827520_0003172800.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  6.65it/s]\u001b[A\n",
            "{'load_data': '0.021', 'extract_feat': '0.017', 'forward': '0.150', 'batch_size': '1', 'rtf': '0.014'}, : 100% 1/1 [00:00<00:00,  6.65it/s]\u001b[A\n",
            "rtf_avg: 0.014: 100% 1/1 [00:00<00:00,  6.63it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.014', 'forward': '0.137', 'batch_size': '1', 'rtf': '0.013'}, : 100% 1/1 [00:00<00:00,  7.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.013: 100% 1/1 [00:00<00:00,  7.24it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.013', 'batch_size': '1', 'rtf': '-0.013'}, : 100% 1/1 [00:00<00:00, 74.99it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.013: 100% 1/1 [00:00<00:00, 72.64it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  5.67it/s]\u001b[A\n",
            "rtf_avg: 0.015, time_speech:  10.790, time_escape: 0.157: 100% 1/1 [00:00<00:00,  5.66it/s]\n",
            " 89% 8/9 [00:05<00:00,  2.43it/s]\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0003172800_0003549440.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  7.05it/s]\u001b[A\n",
            "{'load_data': '0.025', 'extract_feat': '0.018', 'forward': '0.142', 'batch_size': '1', 'rtf': '0.012'}, : 100% 1/1 [00:00<00:00,  7.05it/s]\u001b[A\n",
            "rtf_avg: 0.012: 100% 1/1 [00:00<00:00,  7.00it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  6.98it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.014', 'forward': '0.143', 'batch_size': '1', 'rtf': '0.012'}, : 100% 1/1 [00:00<00:00,  6.98it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.012: 100% 1/1 [00:00<00:00,  6.95it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.014', 'batch_size': '1', 'rtf': '-0.014'}, : 100% 1/1 [00:00<00:00, 72.10it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.014: 100% 1/1 [00:00<00:00, 70.69it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  5.51it/s]\u001b[A\n",
            "rtf_avg: 0.014, time_speech:  11.762, time_escape: 0.163: 100% 1/1 [00:00<00:00,  5.50it/s]\n",
            "100% 9/9 [00:05<00:00,  1.65it/s]\n",
            "ASR 任务完成->标注文件路径: /content/GPT-SoVITS/output/asr_opt/slicer_opt.list\n",
            "\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/subfix_webui.py --load_list \"/content/GPT-SoVITS/output/asr_opt/slicer_opt.list\" --webui_port 9871 --is_share True\n",
            "Running on local URL:  http://0.0.0.0:9871\n",
            "Running on public URL: https://0ba4e1d12d6ef3b334.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/prepare_datasets/1-get-text.py\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/prepare_datasets/1-get-text.py\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/prepare_datasets/2-get-hubert-wav32k.py\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/prepare_datasets/2-get-hubert-wav32k.py\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/prepare_datasets/3-get-semantic.py\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/prepare_datasets/3-get-semantic.py\n",
            "Tokenization & BERT Feature Extraction Process Terminated\n",
            "Tokenization & BERT Feature Extraction Process Terminated\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/queueing.py\", line 575, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/blocks.py\", line 1935, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/blocks.py\", line 1532, in call_function\n",
            "    prediction = await utils.async_iteration(iterator)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/utils.py\", line 671, in async_iteration\n",
            "    return await iterator.__anext__()\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/utils.py\", line 664, in __anext__\n",
            "    return await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/utils.py\", line 647, in run_sync_iterator_async\n",
            "    return next(iterator)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/utils.py\", line 809, in gen_wrapper\n",
            "    response = next(iterator)\n",
            "  File \"/content/GPT-SoVITS/webui.py\", line 904, in open1a\n",
            "    with open(txt_path, \"r\", encoding=\"utf8\") as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'logs/demo01/2-name2text-0.txt'\n",
            "Speech SSL Feature Extraction Process Terminated\n",
            "Speech SSL Feature Extraction Process Terminated\n",
            "Semantics Token Extraction Process Terminated\n",
            "Semantics Token Extraction Process Terminated\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/queueing.py\", line 575, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/blocks.py\", line 1935, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/blocks.py\", line 1532, in call_function\n",
            "    prediction = await utils.async_iteration(iterator)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/utils.py\", line 671, in async_iteration\n",
            "    return await iterator.__anext__()\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/utils.py\", line 664, in __anext__\n",
            "    return await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/utils.py\", line 647, in run_sync_iterator_async\n",
            "    return next(iterator)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/utils.py\", line 809, in gen_wrapper\n",
            "    response = next(iterator)\n",
            "  File \"/content/GPT-SoVITS/webui.py\", line 1063, in open1c\n",
            "    with open(semantic_path, \"r\", encoding=\"utf8\") as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'logs/demo01/6-name2semantic-0.tsv'\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/prepare_datasets/1-get-text.py\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/prepare_datasets/1-get-text.py\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0000498560_0000778880.wav\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0000000000_0000498560.wav\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0001596160_0002227200.wav\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0000778880_0001596160.wav\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0002548480_0002688000.wav\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0002227200_0002548480.wav\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0002827520_0003172800.wav\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0002688000_0002827520.wav\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0003172800_0003549440.wav\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/prepare_datasets/2-get-hubert-wav32k.py\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/prepare_datasets/2-get-hubert-wav32k.py\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/prepare_datasets/3-get-semantic.py\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/prepare_datasets/3-get-semantic.py\n",
            "<All keys matched successfully>\n",
            "<All keys matched successfully>\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/s2_train.py --config \"/content/GPT-SoVITS/TEMP/tmp_s2.json\"\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/s1_train.py --config_file \"/content/GPT-SoVITS/TEMP/tmp_s1.yaml\" \n",
            "Seed set to 1234\n",
            "/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:513: You passed `Trainer(accelerator='cpu', precision='16-mixed')` but AMP with fp16 is not supported on CPU. Using `precision='bf16-mixed'` instead.\n",
            "Using bfloat16 Automatic Mixed Precision (AMP)\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "/content/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_lightning_module.py:29: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "<All keys matched successfully>\n",
            "ckpt_path: None\n",
            "semantic_data_len: 9\n",
            "phoneme_data_len: 9\n",
            "                                           item_name                                     semantic_audio\n",
            "0  vocal_1-1.mp4.reformatted.wav_10.flac_00000000...  520 486 53 53 262 197 907 219 369 532 265 532 ...\n",
            "1  vocal_1-1.mp4.reformatted.wav_10.flac_00007788...  913 295 685 949 994 886 69 543 915 69 547 617 ...\n",
            "2  vocal_1-1.mp4.reformatted.wav_10.flac_00022272...  23 673 702 983 825 825 893 692 662 628 282 222...\n",
            "3  vocal_1-1.mp4.reformatted.wav_10.flac_00026880...  913 511 245 0 369 825 825 266 580 330 614 68 5...\n",
            "4  vocal_1-1.mp4.reformatted.wav_10.flac_00031728...  520 17 171 657 566 295 902 994 723 723 723 560...\n",
            "5  vocal_1-1.mp4.reformatted.wav_10.flac_00004985...  726 720 571 70 88 40 172 498 20 886 598 479 17...\n",
            "6  vocal_1-1.mp4.reformatted.wav_10.flac_00015961...  1012 479 735 803 81 835 621 378 589 1016 904 1...\n",
            "7  vocal_1-1.mp4.reformatted.wav_10.flac_00025484...  1005 775 90 582 132 612 642 229 19 869 19 894 ...\n",
            "8  vocal_1-1.mp4.reformatted.wav_10.flac_00028275...  913 596 411 560 893 893 661 266 266 580 621 56...\n",
            "dataset.__len__(): 99\n",
            "\n",
            "  | Name  | Type                 | Params | Mode \n",
            "-------------------------------------------------------\n",
            "0 | model | Text2SemanticDecoder | 77.6 M | train\n",
            "-------------------------------------------------------\n",
            "77.6 M    Trainable params\n",
            "0         Non-trainable params\n",
            "77.6 M    Total params\n",
            "310.426   Total estimated model params size (MB)\n",
            "257       Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/content/GPT-SoVITS/GPT_SoVITS/AR/data/dataset.py:224: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  bert_feature = torch.load(path_bert, map_location=\"cpu\")\n",
            "/content/GPT-SoVITS/GPT_SoVITS/AR/data/dataset.py:224: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  bert_feature = torch.load(path_bert, map_location=\"cpu\")\n",
            "/content/GPT-SoVITS/GPT_SoVITS/AR/data/dataset.py:224: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  bert_feature = torch.load(path_bert, map_location=\"cpu\")\n",
            "/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "Epoch 0:   0% 0/15 [00:00<?, ?it/s] /content/GPT-SoVITS/GPT_SoVITS/AR/data/dataset.py:224: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  bert_feature = torch.load(path_bert, map_location=\"cpu\")\n",
            "phoneme_data_len: 9\n",
            "wav_data_len: 99\n",
            "100% 99/99 [00:00<00:00, 26471.76it/s]\n",
            "skipped_phone:  0 , skipped_dur:  0\n",
            "total left:  99\n",
            "loaded pretrained GPT_SoVITS/pretrained_models/gsv-v2final-pretrained/s2G2333k.pth <All keys matched successfully>\n",
            "loaded pretrained GPT_SoVITS/pretrained_models/gsv-v2final-pretrained/s2D2333k.pth <All keys matched successfully>\n",
            "start training from epoch 1\n",
            "  0% 0/18 [00:00<?, ?it/s]GPT Training Process Terminated\n",
            "SoVITS Training Process Terminated\n",
            "/usr/local/envs/GPTSoVITS/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 27 leaked semaphore objects to clean up at shutdown\n",
            "  warnings.warn('resource_tracker: There appear to be %d '\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/s2_train.py --config \"/content/GPT-SoVITS/TEMP/tmp_s2.json\"\n",
            "[rank: 0] Received SIGTERM: 15\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS/GPT_SoVITS/s1_train.py\", line 171, in <module>\n",
            "    main(args)\n",
            "  File \"/content/GPT-SoVITS/GPT_SoVITS/s1_train.py\", line 147, in main\n",
            "    trainer.fit(model, data_module, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 561, in fit\n",
            "    call._call_and_handle_interrupt(\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\", line 48, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 599, in _fit_impl\n",
            "    self._run(model, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1012, in _run\n",
            "    results = self._run_stage()\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1056, in _run_stage\n",
            "    self.fit_loop.run()\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py\", line 216, in run\n",
            "    self.advance()\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py\", line 455, in advance\n",
            "    self.epoch_loop.run(self._data_fetcher)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 150, in run\n",
            "    self.advance(data_fetcher)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 322, in advance\n",
            "    batch_output = self.manual_optimization.run(kwargs)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/manual.py\", line 94, in run\n",
            "    self.advance(kwargs)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/manual.py\", line 114, in advance\n",
            "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\", line 328, in _call_strategy_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py\", line 391, in training_step\n",
            "    return self.lightning_module.training_step(*args, **kwargs)\n",
            "  File \"/content/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_lightning_module.py\", line 45, in training_step\n",
            "    loss, acc = forward(\n",
            "  File \"/content/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_model.py\", line 501, in forward_old\n",
            "    xy_dec, _ = self.h(\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/GPT-SoVITS/GPT_SoVITS/AR/modules/transformer.py\", line 162, in forward\n",
            "    output = mod(\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/GPT-SoVITS/GPT_SoVITS/AR/modules/transformer.py\", line 298, in forward\n",
            "    x = self.norm2(x + self._ff_block(x), stage_embedding)\n",
            "  File \"/content/GPT-SoVITS/GPT_SoVITS/AR/modules/transformer.py\", line 329, in _ff_block\n",
            "    x = self.linear2(self.dropout(self.activation(self.linear1(x))))\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/torch/utils/data/_utils/signal_handling.py\", line 73, in handler\n",
            "    _error_if_any_worker_fails()\n",
            "RuntimeError: DataLoader worker (pid 14490) is killed by signal: Terminated. \n",
            "Epoch 0:   0%|          | 0/15 [00:20<?, ?it/s]\n",
            "phoneme_data_len: 9\n",
            "wav_data_len: 99\n",
            "100% 99/99 [00:00<00:00, 73688.75it/s]\n",
            "skipped_phone:  0 , skipped_dur:  0\n",
            "total left:  99\n",
            "loaded pretrained GPT_SoVITS/pretrained_models/gsv-v2final-pretrained/s2G2333k.pth <All keys matched successfully>\n",
            "loaded pretrained GPT_SoVITS/pretrained_models/gsv-v2final-pretrained/s2D2333k.pth <All keys matched successfully>\n",
            "start training from epoch 1\n",
            "  0% 0/18 [00:00<?, ?it/s][rank0]:[W428 14:15:17.995674878 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
            "100% 18/18 [01:03<00:00,  3.56s/it]\n",
            "100% 18/18 [00:18<00:00,  1.05s/it]\n",
            "100% 18/18 [00:19<00:00,  1.07s/it]\n",
            "100% 18/18 [00:17<00:00,  1.01it/s]\n",
            "100% 18/18 [00:19<00:00,  1.06s/it]\n",
            "100% 18/18 [00:19<00:00,  1.08s/it]\n",
            "100% 18/18 [00:20<00:00,  1.13s/it]\n",
            "100% 18/18 [00:17<00:00,  1.01it/s]\n",
            "training done\n",
            "[rank0]:[W428 14:19:00.735671019 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/s1_train.py --config_file \"/content/GPT-SoVITS/TEMP/tmp_s1.yaml\" \n",
            "Seed set to 1234\n",
            "/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:513: You passed `Trainer(accelerator='cpu', precision='16-mixed')` but AMP with fp16 is not supported on CPU. Using `precision='bf16-mixed'` instead.\n",
            "Using bfloat16 Automatic Mixed Precision (AMP)\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "/content/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_lightning_module.py:29: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "<All keys matched successfully>\n",
            "ckpt_path: None\n",
            "semantic_data_len: 9\n",
            "phoneme_data_len: 9\n",
            "                                           item_name                                     semantic_audio\n",
            "0  vocal_1-1.mp4.reformatted.wav_10.flac_00000000...  520 486 53 53 262 197 907 219 369 532 265 532 ...\n",
            "1  vocal_1-1.mp4.reformatted.wav_10.flac_00007788...  913 295 685 949 994 886 69 543 915 69 547 617 ...\n",
            "2  vocal_1-1.mp4.reformatted.wav_10.flac_00022272...  23 673 702 983 825 825 893 692 662 628 282 222...\n",
            "3  vocal_1-1.mp4.reformatted.wav_10.flac_00026880...  913 511 245 0 369 825 825 266 580 330 614 68 5...\n",
            "4  vocal_1-1.mp4.reformatted.wav_10.flac_00031728...  520 17 171 657 566 295 902 994 723 723 723 560...\n",
            "5  vocal_1-1.mp4.reformatted.wav_10.flac_00004985...  726 720 571 70 88 40 172 498 20 886 598 479 17...\n",
            "6  vocal_1-1.mp4.reformatted.wav_10.flac_00015961...  1012 479 735 803 81 835 621 378 589 1016 904 1...\n",
            "7  vocal_1-1.mp4.reformatted.wav_10.flac_00025484...  1005 775 90 582 132 612 642 229 19 869 19 894 ...\n",
            "8  vocal_1-1.mp4.reformatted.wav_10.flac_00028275...  913 596 411 560 893 893 661 266 266 580 621 56...\n",
            "dataset.__len__(): 99\n",
            "\n",
            "  | Name  | Type                 | Params | Mode \n",
            "-------------------------------------------------------\n",
            "0 | model | Text2SemanticDecoder | 77.6 M | train\n",
            "-------------------------------------------------------\n",
            "77.6 M    Trainable params\n",
            "0         Non-trainable params\n",
            "77.6 M    Total params\n",
            "310.426   Total estimated model params size (MB)\n",
            "257       Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/content/GPT-SoVITS/GPT_SoVITS/AR/data/dataset.py:224: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  bert_feature = torch.load(path_bert, map_location=\"cpu\")\n",
            "/content/GPT-SoVITS/GPT_SoVITS/AR/data/dataset.py:224: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  bert_feature = torch.load(path_bert, map_location=\"cpu\")\n",
            "/content/GPT-SoVITS/GPT_SoVITS/AR/data/dataset.py:224: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  bert_feature = torch.load(path_bert, map_location=\"cpu\")\n",
            "/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "Epoch 0:   0% 0/15 [00:00<?, ?it/s] /content/GPT-SoVITS/GPT_SoVITS/AR/data/dataset.py:224: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  bert_feature = torch.load(path_bert, map_location=\"cpu\")\n",
            "Killed\n"
          ]
        }
      ],
      "source": [
        "!cd /content/GPT-SoVITS && source activate GPTSoVITS && export is_share=True && python webui.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "34e3295d-f19e-460a-b9b7-fc5f23c1bbfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naPZv5iuyTlu"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: /usr/local/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
            "Running on local URL:  http://0.0.0.0:9874\n",
            "Running on public URL: https://ecc269405413477232.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/uvr5/webui.py \"cuda\" True 9873 True\n",
            "Running on local URL:  http://0.0.0.0:9873\n",
            "Running on public URL: https://930249277b7efc625b.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "Vocal Separation WebUI Process Terminated\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/uvr5/webui.py \"cuda\" True 9873 True\n",
            "Running on local URL:  http://0.0.0.0:9873\n",
            "Running on public URL: https://55ab6ff6edeea07e3f.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "clean_empty_cache\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS/tools/uvr5/webui.py\", line 91, in uvr\n",
            "    if info[\"streams\"][0][\"channels\"] == 2 and info[\"streams\"][0][\"sample_rate\"] == \"44100\":\n",
            "KeyError: 'channels'\n",
            "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
            "  built with gcc 11.2.0 (Anaconda gcc)\n",
            "  configuration: --prefix=/usr/local/envs/GPTSoVITS --cc=/croot/ffmpeg_1743153284778/_build_env/bin/x86_64-conda-linux-gnu-cc --ar=/croot/ffmpeg_1743153284778/_build_env/bin/x86_64-conda-linux-gnu-ar --nm=/croot/ffmpeg_1743153284778/_build_env/bin/x86_64-conda-linux-gnu-nm --ranlib=/croot/ffmpeg_1743153284778/_build_env/bin/x86_64-conda-linux-gnu-ranlib --strip=/croot/ffmpeg_1743153284778/_build_env/bin/x86_64-conda-linux-gnu-strip --disable-doc --enable-swresample --enable-swscale --enable-openssl --enable-libxml2 --enable-libtheora --enable-demuxer=dash --enable-postproc --enable-hardcoded-tables --enable-libfreetype --enable-libharfbuzz --enable-libfontconfig --enable-libdav1d --enable-zlib --enable-libaom --enable-pic --enable-shared --disable-static --disable-gpl --enable-version3 --disable-sdl2 --enable-libopenh264 --enable-libopus --enable-libmp3lame --enable-libopenjpeg --enable-libvorbis --enable-pthreads --enable-libtesseract --enable-libvpx\n",
            "  libavutil      58. 29.100 / 58. 29.100\n",
            "  libavcodec     60. 31.102 / 60. 31.102\n",
            "  libavformat    60. 16.100 / 60. 16.100\n",
            "  libavdevice    60.  3.100 / 60.  3.100\n",
            "  libavfilter     9. 12.100 /  9. 12.100\n",
            "  libswscale      7.  5.100 /  7.  5.100\n",
            "  libswresample   4. 12.100 /  4. 12.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/content/GPT-SoVITS/input/1-1.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2avc1mp41\n",
            "    encoder         : Lavf58.29.100\n",
            "    description     : Packed by Bilibili XCoder v2.0.2\n",
            "  Duration: 00:01:50.92, start: 0.000000, bitrate: 1959 kb/s\n",
            "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 1280x720 [SAR 1:1 DAR 16:9], 1742 kb/s, 30 fps, 30 tbr, 16k tbn (default)\n",
            "    Metadata:\n",
            "      handler_name    : VideoHandler\n",
            "      vendor_id       : [0][0][0][0]\n",
            "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 209 kb/s (default)\n",
            "    Metadata:\n",
            "      handler_name    : SoundHandler\n",
            "      vendor_id       : [0][0][0][0]\n",
            "Stream mapping:\n",
            "  Stream #0:1 -> #0:0 (aac (native) -> pcm_s16le (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, wav, to '/content/GPT-SoVITS/TEMP/1-1.mp4.reformatted.wav':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2avc1mp41\n",
            "    description     : Packed by Bilibili XCoder v2.0.2\n",
            "    ISFT            : Lavf60.16.100\n",
            "  Stream #0:0(und): Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s (default)\n",
            "    Metadata:\n",
            "      handler_name    : SoundHandler\n",
            "      vendor_id       : [0][0][0][0]\n",
            "      encoder         : Lavc60.31.102 pcm_s16le\n",
            "\u001b[1;35m[out#0/wav @ 0x1f1526c0] \u001b[0mvideo:0kB audio:19108kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.000399%\n",
            "size=   19108kB time=00:01:50.89 bitrate=1411.5kbits/s speed= 362x    \n",
            "100% 40/40 [00:03<00:00, 10.20it/s]\n",
            "clean_empty_cache\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/slice_audio.py \"/content/GPT-SoVITS/output/uvr5_opt\" \"output/slicer_opt\" -34 4000 300 10 500 0.9 0.25 0 4\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/slice_audio.py \"/content/GPT-SoVITS/output/uvr5_opt\" \"output/slicer_opt\" -34 4000 300 10 500 0.9 0.25 1 4\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/slice_audio.py \"/content/GPT-SoVITS/output/uvr5_opt\" \"output/slicer_opt\" -34 4000 300 10 500 0.9 0.25 2 4\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/slice_audio.py \"/content/GPT-SoVITS/output/uvr5_opt\" \"output/slicer_opt\" -34 4000 300 10 500 0.9 0.25 3 4\n",
            "Speech Slicing Process Terminated\n",
            "Speech Slicing Process Terminated\n",
            "Speech Slicing Process Terminated\n",
            "Speech Slicing Process Terminated\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/slice_audio.py \"/content/GPT-SoVITS/output/uvr5_opt\" \"output/slicer_opt\" -34 4000 300 10 500 0.9 0.25 0 4\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/slice_audio.py \"/content/GPT-SoVITS/output/uvr5_opt\" \"output/slicer_opt\" -34 4000 300 10 500 0.9 0.25 1 4\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/slice_audio.py \"/content/GPT-SoVITS/output/uvr5_opt\" \"output/slicer_opt\" -34 4000 300 10 500 0.9 0.25 2 4\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/slice_audio.py \"/content/GPT-SoVITS/output/uvr5_opt\" \"output/slicer_opt\" -34 4000 300 10 500 0.9 0.25 3 4\n",
            "执行完毕，请检查输出文件\n",
            "执行完毕，请检查输出文件\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS/tools/my_utils.py\", line 21, in load_audio\n",
            "    ffmpeg.input(file, threads=0)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/ffmpeg/_run.py\", line 325, in run\n",
            "    raise Error('ffmpeg', out, err)\n",
            "ffmpeg._run.Error: ffmpeg error (see stderr output for detail)\n",
            "/content/GPT-SoVITS/output/uvr5_opt/.ipynb_checkpoints ->fail-> Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS/tools/my_utils.py\", line 21, in load_audio\n",
            "    ffmpeg.input(file, threads=0)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/ffmpeg/_run.py\", line 325, in run\n",
            "    raise Error('ffmpeg', out, err)\n",
            "ffmpeg._run.Error: ffmpeg error (see stderr output for detail)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS/tools/slice_audio.py\", line 35, in slice\n",
            "    audio = load_audio(inp_path, 32000)\n",
            "  File \"/content/GPT-SoVITS/tools/my_utils.py\", line 27, in load_audio\n",
            "    raise RuntimeError(i18n(\"音频加载失败\"))\n",
            "RuntimeError: Failed to Load Audio\n",
            "\n",
            "执行完毕，请检查输出文件\n",
            "执行完毕，请检查输出文件\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/slice_audio.py \"/content/GPT-SoVITS/output/uvr5_opt\" \"output/slicer_opt\" -34 4000 300 10 500 0.9 0.25 0 4\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/slice_audio.py \"/content/GPT-SoVITS/output/uvr5_opt\" \"output/slicer_opt\" -34 4000 300 10 500 0.9 0.25 1 4\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/slice_audio.py \"/content/GPT-SoVITS/output/uvr5_opt\" \"output/slicer_opt\" -34 4000 300 10 500 0.9 0.25 2 4\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/slice_audio.py \"/content/GPT-SoVITS/output/uvr5_opt\" \"output/slicer_opt\" -34 4000 300 10 500 0.9 0.25 3 4\n",
            "执行完毕，请检查输出文件\n",
            "执行完毕，请检查输出文件\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS/tools/my_utils.py\", line 21, in load_audio\n",
            "    ffmpeg.input(file, threads=0)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/ffmpeg/_run.py\", line 325, in run\n",
            "    raise Error('ffmpeg', out, err)\n",
            "ffmpeg._run.Error: ffmpeg error (see stderr output for detail)\n",
            "/content/GPT-SoVITS/output/uvr5_opt/.ipynb_checkpoints ->fail-> Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS/tools/my_utils.py\", line 21, in load_audio\n",
            "    ffmpeg.input(file, threads=0)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/ffmpeg/_run.py\", line 325, in run\n",
            "    raise Error('ffmpeg', out, err)\n",
            "ffmpeg._run.Error: ffmpeg error (see stderr output for detail)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS/tools/slice_audio.py\", line 35, in slice\n",
            "    audio = load_audio(inp_path, 32000)\n",
            "  File \"/content/GPT-SoVITS/tools/my_utils.py\", line 27, in load_audio\n",
            "    raise RuntimeError(i18n(\"音频加载失败\"))\n",
            "RuntimeError: Failed to Load Audio\n",
            "\n",
            "执行完毕，请检查输出文件\n",
            "执行完毕，请检查输出文件\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/subfix_webui.py --load_list \"D:/RVC1006/GPT-SoVITS/raw/xxx.list\" --webui_port 9871 --is_share True\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS/tools/subfix_webui.py\", line 304, in <module>\n",
            "    set_global(args.load_json, args.load_list, args.json_key_text, args.json_key_path, args.g_batch)\n",
            "  File \"/content/GPT-SoVITS/tools/subfix_webui.py\", line 289, in set_global\n",
            "    b_load_file()\n",
            "  File \"/content/GPT-SoVITS/tools/subfix_webui.py\", line 268, in b_load_file\n",
            "    b_load_list()\n",
            "  File \"/content/GPT-SoVITS/tools/subfix_webui.py\", line 243, in b_load_list\n",
            "    with open(g_load_file, \"r\", encoding=\"utf-8\") as source:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'D:/RVC1006/GPT-SoVITS/raw/xxx.list'\n",
            "Audio Labeling WebUI Process Terminated\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/asr/funasr_asr.py -i \"output/slicer_opt\" -o \"output/asr_opt\" -s large -l zh -p float32\n",
            "2025-04-28 13:53:49,998 - modelscope - INFO - PyTorch version 2.5.1+cu124 Found.\n",
            "2025-04-28 13:53:49,999 - modelscope - INFO - Loading ast index from /root/.cache/modelscope/ast_indexer\n",
            "2025-04-28 13:53:49,999 - modelscope - INFO - No valid ast index found from /root/.cache/modelscope/ast_indexer, generating ast index from prebuilt!\n",
            "2025-04-28 13:53:50,058 - modelscope - INFO - Loading done! Current index file version is 1.10.0, with md5 9710ac4fb2f8068bd74ea2bbac1a05b0 and a total number of 946 components indexed\n",
            "2025-04-28 13:53:51,968 - modelscope - INFO - Use user-specified model revision: v2.0.4\n",
            "Downloading: 100% 10.9k/10.9k [00:00<00:00, 39.0MB/s]\n",
            "Downloading: 100% 173k/173k [00:00<00:00, 581kB/s]\n",
            "Downloading: 100% 2.45k/2.45k [00:00<00:00, 14.8MB/s]\n",
            "Downloading: 100% 472/472 [00:00<00:00, 2.56MB/s]\n",
            "Downloading: 100% 840M/840M [00:21<00:00, 41.2MB/s]\n",
            "Downloading: 100% 19.1k/19.1k [00:00<00:00, 260kB/s]\n",
            "Downloading: 100% 7.90M/7.90M [00:01<00:00, 8.13MB/s]\n",
            "Downloading: 100% 48.7k/48.7k [00:00<00:00, 336kB/s]\n",
            "Downloading: 100% 91.5k/91.5k [00:00<00:00, 416kB/s]\n",
            "ckpt: /root/.cache/modelscope/hub/iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/model.pt\n",
            "/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/funasr/train_utils/load_pretrained_model.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  src_state = torch.load(path, map_location=map_location)\n",
            "2025-04-28 13:54:33,553 - modelscope - INFO - Use user-specified model revision: v2.0.4\n",
            "Downloading: 100% 7.85k/7.85k [00:00<00:00, 27.5MB/s]\n",
            "Downloading: 100% 1.19k/1.19k [00:00<00:00, 6.34MB/s]\n",
            "Downloading: 100% 365/365 [00:00<00:00, 1.86MB/s]\n",
            "Downloading: 100% 1.64M/1.64M [00:00<00:00, 2.83MB/s]\n",
            "Downloading: 100% 8.45k/8.45k [00:00<00:00, 28.7MB/s]\n",
            "Downloading: 100% 27.3k/27.3k [00:00<00:00, 370kB/s]\n",
            "Downloading: 100% 2.16M/2.16M [00:00<00:00, 3.67MB/s]\n",
            "ckpt: /root/.cache/modelscope/hub/iic/speech_fsmn_vad_zh-cn-16k-common-pytorch/model.pt\n",
            "2025-04-28 13:54:44,022 - modelscope - INFO - Use user-specified model revision: v2.0.4\n",
            "Downloading: 100% 6.00k/6.00k [00:00<00:00, 18.1MB/s]\n",
            "Downloading: 100% 810/810 [00:00<00:00, 4.70MB/s]\n",
            "Downloading: 100% 373/373 [00:00<00:00, 1.65MB/s]\n",
            "Downloading: 100% 278M/278M [00:12<00:00, 23.6MB/s]\n",
            "Downloading: 100% 863/863 [00:00<00:00, 4.96MB/s]\n",
            "Downloading: 100% 11.2k/11.2k [00:00<00:00, 39.0MB/s]\n",
            "Downloading: 100% 151k/151k [00:00<00:00, 506kB/s]\n",
            "Downloading: 100% 4.01M/4.01M [00:00<00:00, 6.13MB/s]\n",
            "ckpt: /root/.cache/modelscope/hub/iic/punc_ct-transformer_zh-cn-common-vocab272727-pytorch/model.pt\n",
            "FunASR 模型加载完成: ZH\n",
            "  0% 0/9 [00:00<?, ?it/s]\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0000000000_0000498560.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  1.32it/s]\u001b[A\n",
            "{'load_data': '0.268', 'extract_feat': '0.165', 'forward': '0.759', 'batch_size': '1', 'rtf': '0.049'}, : 100% 1/1 [00:00<00:00,  1.32it/s]\u001b[A\n",
            "rtf_avg: 0.049: 100% 1/1 [00:00<00:00,  1.32it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/funasr/models/paraformer/model.py:249: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(False):\n",
            "/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/funasr/models/paraformer/cif_predictor.py:212: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(False):\n",
            "\n",
            "\n",
            "100% 1/1 [00:00<00:00,  1.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.019', 'forward': '0.952', 'batch_size': '1', 'rtf': '0.061'}, : 100% 1/1 [00:00<00:00,  1.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.061: 100% 1/1 [00:00<00:00,  1.05it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.068', 'batch_size': '1', 'rtf': '-0.068'}, : 100% 1/1 [00:00<00:00, 14.60it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.068: 100% 1/1 [00:00<00:00, 14.52it/s]\n",
            "\n",
            "100% 1/1 [00:01<00:00,  1.05s/it]\u001b[A\n",
            "rtf_avg: 0.066, time_speech:  15.580, time_escape: 1.028: 100% 1/1 [00:01<00:00,  1.05s/it]\n",
            " 11% 1/9 [00:01<00:14,  1.81s/it]\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0000498560_0000778880.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  5.49it/s]\u001b[A\n",
            "{'load_data': '0.042', 'extract_feat': '0.022', 'forward': '0.182', 'batch_size': '1', 'rtf': '0.021'}, : 100% 1/1 [00:00<00:00,  5.49it/s]\u001b[A\n",
            "rtf_avg: 0.021: 100% 1/1 [00:00<00:00,  5.45it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  4.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.022', 'forward': '0.205', 'batch_size': '1', 'rtf': '0.023'}, : 100% 1/1 [00:00<00:00,  4.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.023: 100% 1/1 [00:00<00:00,  4.82it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.018', 'batch_size': '1', 'rtf': '-0.018'}, : 100% 1/1 [00:00<00:00, 55.99it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.018: 100% 1/1 [00:00<00:00, 54.81it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  3.87it/s]\u001b[A\n",
            "rtf_avg: 0.027, time_speech:  8.760, time_escape: 0.233: 100% 1/1 [00:00<00:00,  3.86it/s]\n",
            " 22% 2/9 [00:02<00:07,  1.01s/it]\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0000778880_0001596160.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  2.20it/s]\u001b[A\n",
            "{'load_data': '0.056', 'extract_feat': '0.062', 'forward': '0.455', 'batch_size': '1', 'rtf': '0.018'}, : 100% 1/1 [00:00<00:00,  2.20it/s]\u001b[A\n",
            "rtf_avg: 0.018: 100% 1/1 [00:00<00:00,  2.19it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  3.15it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.042', 'forward': '0.317', 'batch_size': '1', 'rtf': '0.012'}, : 100% 1/1 [00:00<00:00,  3.15it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.012: 100% 1/1 [00:00<00:00,  3.13it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.034', 'batch_size': '1', 'rtf': '-0.034'}, : 100% 1/1 [00:00<00:00, 29.72it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.034: 100% 1/1 [00:00<00:00, 29.45it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  2.44it/s]\u001b[A\n",
            "rtf_avg: 0.014, time_speech:  25.540, time_escape: 0.361: 100% 1/1 [00:00<00:00,  2.44it/s]\n",
            " 33% 3/9 [00:03<00:05,  1.06it/s]\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0001596160_0002227200.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.03it/s]\u001b[A\n",
            "{'load_data': '0.046', 'extract_feat': '0.047', 'forward': '0.330', 'batch_size': '1', 'rtf': '0.017'}, : 100% 1/1 [00:00<00:00,  3.03it/s]\u001b[A\n",
            "rtf_avg: 0.017: 100% 1/1 [00:00<00:00,  3.02it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  3.46it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.039', 'forward': '0.289', 'batch_size': '1', 'rtf': '0.015'}, : 100% 1/1 [00:00<00:00,  3.46it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.015: 100% 1/1 [00:00<00:00,  3.45it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.040', 'batch_size': '1', 'rtf': '-0.040'}, : 100% 1/1 [00:00<00:00, 25.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.040: 100% 1/1 [00:00<00:00, 24.82it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  2.66it/s]\u001b[A\n",
            "rtf_avg: 0.017, time_speech:  19.720, time_escape: 0.339: 100% 1/1 [00:00<00:00,  2.66it/s]\n",
            " 44% 4/9 [00:03<00:04,  1.18it/s]\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0002227200_0002548480.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  5.04it/s]\u001b[A\n",
            "{'load_data': '0.034', 'extract_feat': '0.026', 'forward': '0.198', 'batch_size': '1', 'rtf': '0.020'}, : 100% 1/1 [00:00<00:00,  5.04it/s]\u001b[A\n",
            "rtf_avg: 0.020: 100% 1/1 [00:00<00:00,  5.01it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  4.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.022', 'forward': '0.223', 'batch_size': '1', 'rtf': '0.022'}, : 100% 1/1 [00:00<00:00,  4.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.022: 100% 1/1 [00:00<00:00,  4.32it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.021', 'batch_size': '1', 'rtf': '-0.021'}, : 100% 1/1 [00:00<00:00, 48.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.021: 100% 1/1 [00:00<00:00, 47.33it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  3.39it/s]\u001b[A\n",
            "rtf_avg: 0.026, time_speech:  10.040, time_escape: 0.261: 100% 1/1 [00:00<00:00,  3.39it/s]\n",
            " 56% 5/9 [00:04<00:02,  1.38it/s]\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0002548480_0002688000.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "{'load_data': '0.028', 'extract_feat': '0.018', 'forward': '0.089', 'batch_size': '1', 'rtf': '0.020'}, : 100% 1/1 [00:00<00:00, 11.26it/s]\u001b[A\n",
            "rtf_avg: 0.020: 100% 1/1 [00:00<00:00, 11.22it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  6.01it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.007', 'forward': '0.166', 'batch_size': '1', 'rtf': '0.038'}, : 100% 1/1 [00:00<00:00,  6.01it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.038: 100% 1/1 [00:00<00:00,  5.98it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.006', 'batch_size': '1', 'rtf': '-0.006'}, : 100% 1/1 [00:00<00:00, 151.85it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.006: 100% 1/1 [00:00<00:00, 146.27it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  5.20it/s]\u001b[A\n",
            "rtf_avg: 0.041, time_speech:  4.360, time_escape: 0.179: 100% 1/1 [00:00<00:00,  5.19it/s]\n",
            " 67% 6/9 [00:04<00:01,  1.74it/s]\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0002688000_0002827520.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "{'load_data': '0.017', 'extract_feat': '0.009', 'forward': '0.069', 'batch_size': '1', 'rtf': '0.016'}, : 100% 1/1 [00:00<00:00, 14.41it/s]\u001b[A\n",
            "rtf_avg: 0.016: 100% 1/1 [00:00<00:00, 14.35it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  9.95it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.007', 'forward': '0.100', 'batch_size': '1', 'rtf': '0.023'}, : 100% 1/1 [00:00<00:00,  9.95it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.023: 100% 1/1 [00:00<00:00,  9.79it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.006', 'batch_size': '1', 'rtf': '-0.006'}, : 100% 1/1 [00:00<00:00, 157.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.006: 100% 1/1 [00:00<00:00, 150.87it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.88it/s]\u001b[A\n",
            "rtf_avg: 0.026, time_speech:  4.360, time_escape: 0.113: 100% 1/1 [00:00<00:00,  7.86it/s]\n",
            " 78% 7/9 [00:04<00:00,  2.22it/s]\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0002827520_0003172800.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  6.65it/s]\u001b[A\n",
            "{'load_data': '0.021', 'extract_feat': '0.017', 'forward': '0.150', 'batch_size': '1', 'rtf': '0.014'}, : 100% 1/1 [00:00<00:00,  6.65it/s]\u001b[A\n",
            "rtf_avg: 0.014: 100% 1/1 [00:00<00:00,  6.63it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.014', 'forward': '0.137', 'batch_size': '1', 'rtf': '0.013'}, : 100% 1/1 [00:00<00:00,  7.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.013: 100% 1/1 [00:00<00:00,  7.24it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.013', 'batch_size': '1', 'rtf': '-0.013'}, : 100% 1/1 [00:00<00:00, 74.99it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.013: 100% 1/1 [00:00<00:00, 72.64it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  5.67it/s]\u001b[A\n",
            "rtf_avg: 0.015, time_speech:  10.790, time_escape: 0.157: 100% 1/1 [00:00<00:00,  5.66it/s]\n",
            " 89% 8/9 [00:05<00:00,  2.43it/s]\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0003172800_0003549440.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  7.05it/s]\u001b[A\n",
            "{'load_data': '0.025', 'extract_feat': '0.018', 'forward': '0.142', 'batch_size': '1', 'rtf': '0.012'}, : 100% 1/1 [00:00<00:00,  7.05it/s]\u001b[A\n",
            "rtf_avg: 0.012: 100% 1/1 [00:00<00:00,  7.00it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  6.98it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.014', 'forward': '0.143', 'batch_size': '1', 'rtf': '0.012'}, : 100% 1/1 [00:00<00:00,  6.98it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.012: 100% 1/1 [00:00<00:00,  6.95it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.014', 'batch_size': '1', 'rtf': '-0.014'}, : 100% 1/1 [00:00<00:00, 72.10it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.014: 100% 1/1 [00:00<00:00, 70.69it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  5.51it/s]\u001b[A\n",
            "rtf_avg: 0.014, time_speech:  11.762, time_escape: 0.163: 100% 1/1 [00:00<00:00,  5.50it/s]\n",
            "100% 9/9 [00:05<00:00,  1.65it/s]\n",
            "ASR 任务完成->标注文件路径: /content/GPT-SoVITS/output/asr_opt/slicer_opt.list\n",
            "\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/subfix_webui.py --load_list \"/content/GPT-SoVITS/output/asr_opt/slicer_opt.list\" --webui_port 9871 --is_share True\n",
            "Running on local URL:  http://0.0.0.0:9871\n",
            "Running on public URL: https://0ba4e1d12d6ef3b334.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/prepare_datasets/1-get-text.py\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/prepare_datasets/1-get-text.py\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/prepare_datasets/2-get-hubert-wav32k.py\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/prepare_datasets/2-get-hubert-wav32k.py\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/prepare_datasets/3-get-semantic.py\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/prepare_datasets/3-get-semantic.py\n",
            "Tokenization & BERT Feature Extraction Process Terminated\n",
            "Tokenization & BERT Feature Extraction Process Terminated\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/queueing.py\", line 575, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/blocks.py\", line 1935, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/blocks.py\", line 1532, in call_function\n",
            "    prediction = await utils.async_iteration(iterator)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/utils.py\", line 671, in async_iteration\n",
            "    return await iterator.__anext__()\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/utils.py\", line 664, in __anext__\n",
            "    return await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/utils.py\", line 647, in run_sync_iterator_async\n",
            "    return next(iterator)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/utils.py\", line 809, in gen_wrapper\n",
            "    response = next(iterator)\n",
            "  File \"/content/GPT-SoVITS/webui.py\", line 904, in open1a\n",
            "    with open(txt_path, \"r\", encoding=\"utf8\") as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'logs/demo01/2-name2text-0.txt'\n",
            "Speech SSL Feature Extraction Process Terminated\n",
            "Speech SSL Feature Extraction Process Terminated\n",
            "Semantics Token Extraction Process Terminated\n",
            "Semantics Token Extraction Process Terminated\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/queueing.py\", line 575, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/blocks.py\", line 1935, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/blocks.py\", line 1532, in call_function\n",
            "    prediction = await utils.async_iteration(iterator)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/utils.py\", line 671, in async_iteration\n",
            "    return await iterator.__anext__()\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/utils.py\", line 664, in __anext__\n",
            "    return await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/utils.py\", line 647, in run_sync_iterator_async\n",
            "    return next(iterator)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/utils.py\", line 809, in gen_wrapper\n",
            "    response = next(iterator)\n",
            "  File \"/content/GPT-SoVITS/webui.py\", line 1063, in open1c\n",
            "    with open(semantic_path, \"r\", encoding=\"utf8\") as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'logs/demo01/6-name2semantic-0.tsv'\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/prepare_datasets/1-get-text.py\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/prepare_datasets/1-get-text.py\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0000498560_0000778880.wav\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0000000000_0000498560.wav\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0001596160_0002227200.wav\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0000778880_0001596160.wav\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0002548480_0002688000.wav\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0002227200_0002548480.wav\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0002827520_0003172800.wav\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0002688000_0002827520.wav\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0003172800_0003549440.wav\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/prepare_datasets/2-get-hubert-wav32k.py\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/prepare_datasets/2-get-hubert-wav32k.py\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/prepare_datasets/3-get-semantic.py\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/prepare_datasets/3-get-semantic.py\n",
            "<All keys matched successfully>\n",
            "<All keys matched successfully>\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/s2_train.py --config \"/content/GPT-SoVITS/TEMP/tmp_s2.json\"\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/s1_train.py --config_file \"/content/GPT-SoVITS/TEMP/tmp_s1.yaml\" \n",
            "Seed set to 1234\n",
            "/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:513: You passed `Trainer(accelerator='cpu', precision='16-mixed')` but AMP with fp16 is not supported on CPU. Using `precision='bf16-mixed'` instead.\n",
            "Using bfloat16 Automatic Mixed Precision (AMP)\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "/content/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_lightning_module.py:29: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "<All keys matched successfully>\n",
            "ckpt_path: None\n",
            "semantic_data_len: 9\n",
            "phoneme_data_len: 9\n",
            "                                           item_name                                     semantic_audio\n",
            "0  vocal_1-1.mp4.reformatted.wav_10.flac_00000000...  520 486 53 53 262 197 907 219 369 532 265 532 ...\n",
            "1  vocal_1-1.mp4.reformatted.wav_10.flac_00007788...  913 295 685 949 994 886 69 543 915 69 547 617 ...\n",
            "2  vocal_1-1.mp4.reformatted.wav_10.flac_00022272...  23 673 702 983 825 825 893 692 662 628 282 222...\n",
            "3  vocal_1-1.mp4.reformatted.wav_10.flac_00026880...  913 511 245 0 369 825 825 266 580 330 614 68 5...\n",
            "4  vocal_1-1.mp4.reformatted.wav_10.flac_00031728...  520 17 171 657 566 295 902 994 723 723 723 560...\n",
            "5  vocal_1-1.mp4.reformatted.wav_10.flac_00004985...  726 720 571 70 88 40 172 498 20 886 598 479 17...\n",
            "6  vocal_1-1.mp4.reformatted.wav_10.flac_00015961...  1012 479 735 803 81 835 621 378 589 1016 904 1...\n",
            "7  vocal_1-1.mp4.reformatted.wav_10.flac_00025484...  1005 775 90 582 132 612 642 229 19 869 19 894 ...\n",
            "8  vocal_1-1.mp4.reformatted.wav_10.flac_00028275...  913 596 411 560 893 893 661 266 266 580 621 56...\n",
            "dataset.__len__(): 99\n",
            "\n",
            "  | Name  | Type                 | Params | Mode \n",
            "-------------------------------------------------------\n",
            "0 | model | Text2SemanticDecoder | 77.6 M | train\n",
            "-------------------------------------------------------\n",
            "77.6 M    Trainable params\n",
            "0         Non-trainable params\n",
            "77.6 M    Total params\n",
            "310.426   Total estimated model params size (MB)\n",
            "257       Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/content/GPT-SoVITS/GPT_SoVITS/AR/data/dataset.py:224: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  bert_feature = torch.load(path_bert, map_location=\"cpu\")\n",
            "/content/GPT-SoVITS/GPT_SoVITS/AR/data/dataset.py:224: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  bert_feature = torch.load(path_bert, map_location=\"cpu\")\n",
            "/content/GPT-SoVITS/GPT_SoVITS/AR/data/dataset.py:224: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  bert_feature = torch.load(path_bert, map_location=\"cpu\")\n",
            "/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "Epoch 0:   0% 0/15 [00:00<?, ?it/s] /content/GPT-SoVITS/GPT_SoVITS/AR/data/dataset.py:224: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  bert_feature = torch.load(path_bert, map_location=\"cpu\")\n",
            "phoneme_data_len: 9\n",
            "wav_data_len: 99\n",
            "100% 99/99 [00:00<00:00, 26471.76it/s]\n",
            "skipped_phone:  0 , skipped_dur:  0\n",
            "total left:  99\n",
            "loaded pretrained GPT_SoVITS/pretrained_models/gsv-v2final-pretrained/s2G2333k.pth <All keys matched successfully>\n",
            "loaded pretrained GPT_SoVITS/pretrained_models/gsv-v2final-pretrained/s2D2333k.pth <All keys matched successfully>\n",
            "start training from epoch 1\n",
            "  0% 0/18 [00:00<?, ?it/s]GPT Training Process Terminated\n",
            "SoVITS Training Process Terminated\n",
            "/usr/local/envs/GPTSoVITS/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 27 leaked semaphore objects to clean up at shutdown\n",
            "  warnings.warn('resource_tracker: There appear to be %d '\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/s2_train.py --config \"/content/GPT-SoVITS/TEMP/tmp_s2.json\"\n",
            "[rank: 0] Received SIGTERM: 15\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS/GPT_SoVITS/s1_train.py\", line 171, in <module>\n",
            "    main(args)\n",
            "  File \"/content/GPT-SoVITS/GPT_SoVITS/s1_train.py\", line 147, in main\n",
            "    trainer.fit(model, data_module, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 561, in fit\n",
            "    call._call_and_handle_interrupt(\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\", line 48, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 599, in _fit_impl\n",
            "    self._run(model, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1012, in _run\n",
            "    results = self._run_stage()\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1056, in _run_stage\n",
            "    self.fit_loop.run()\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py\", line 216, in run\n",
            "    self.advance()\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py\", line 455, in advance\n",
            "    self.epoch_loop.run(self._data_fetcher)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 150, in run\n",
            "    self.advance(data_fetcher)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 322, in advance\n",
            "    batch_output = self.manual_optimization.run(kwargs)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/manual.py\", line 94, in run\n",
            "    self.advance(kwargs)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/manual.py\", line 114, in advance\n",
            "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\", line 328, in _call_strategy_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py\", line 391, in training_step\n",
            "    return self.lightning_module.training_step(*args, **kwargs)\n",
            "  File \"/content/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_lightning_module.py\", line 45, in training_step\n",
            "    loss, acc = forward(\n",
            "  File \"/content/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_model.py\", line 501, in forward_old\n",
            "    xy_dec, _ = self.h(\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/GPT-SoVITS/GPT_SoVITS/AR/modules/transformer.py\", line 162, in forward\n",
            "    output = mod(\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/GPT-SoVITS/GPT_SoVITS/AR/modules/transformer.py\", line 298, in forward\n",
            "    x = self.norm2(x + self._ff_block(x), stage_embedding)\n",
            "  File \"/content/GPT-SoVITS/GPT_SoVITS/AR/modules/transformer.py\", line 329, in _ff_block\n",
            "    x = self.linear2(self.dropout(self.activation(self.linear1(x))))\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/torch/utils/data/_utils/signal_handling.py\", line 73, in handler\n",
            "    _error_if_any_worker_fails()\n",
            "RuntimeError: DataLoader worker (pid 14490) is killed by signal: Terminated. \n",
            "Epoch 0:   0%|          | 0/15 [00:20<?, ?it/s]\n",
            "phoneme_data_len: 9\n",
            "wav_data_len: 99\n",
            "100% 99/99 [00:00<00:00, 73688.75it/s]\n",
            "skipped_phone:  0 , skipped_dur:  0\n",
            "total left:  99\n",
            "loaded pretrained GPT_SoVITS/pretrained_models/gsv-v2final-pretrained/s2G2333k.pth <All keys matched successfully>\n",
            "loaded pretrained GPT_SoVITS/pretrained_models/gsv-v2final-pretrained/s2D2333k.pth <All keys matched successfully>\n",
            "start training from epoch 1\n",
            "  0% 0/18 [00:00<?, ?it/s][rank0]:[W428 14:15:17.995674878 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
            "100% 18/18 [01:03<00:00,  3.56s/it]\n",
            "100% 18/18 [00:18<00:00,  1.05s/it]\n",
            "100% 18/18 [00:19<00:00,  1.07s/it]\n",
            "100% 18/18 [00:17<00:00,  1.01it/s]\n",
            "100% 18/18 [00:19<00:00,  1.06s/it]\n",
            "100% 18/18 [00:19<00:00,  1.08s/it]\n",
            "100% 18/18 [00:20<00:00,  1.13s/it]\n",
            "100% 18/18 [00:17<00:00,  1.01it/s]\n",
            "training done\n",
            "[rank0]:[W428 14:19:00.735671019 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/s1_train.py --config_file \"/content/GPT-SoVITS/TEMP/tmp_s1.yaml\" \n",
            "Seed set to 1234\n",
            "/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:513: You passed `Trainer(accelerator='cpu', precision='16-mixed')` but AMP with fp16 is not supported on CPU. Using `precision='bf16-mixed'` instead.\n",
            "Using bfloat16 Automatic Mixed Precision (AMP)\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "/content/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_lightning_module.py:29: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "<All keys matched successfully>\n",
            "ckpt_path: None\n",
            "semantic_data_len: 9\n",
            "phoneme_data_len: 9\n",
            "                                           item_name                                     semantic_audio\n",
            "0  vocal_1-1.mp4.reformatted.wav_10.flac_00000000...  520 486 53 53 262 197 907 219 369 532 265 532 ...\n",
            "1  vocal_1-1.mp4.reformatted.wav_10.flac_00007788...  913 295 685 949 994 886 69 543 915 69 547 617 ...\n",
            "2  vocal_1-1.mp4.reformatted.wav_10.flac_00022272...  23 673 702 983 825 825 893 692 662 628 282 222...\n",
            "3  vocal_1-1.mp4.reformatted.wav_10.flac_00026880...  913 511 245 0 369 825 825 266 580 330 614 68 5...\n",
            "4  vocal_1-1.mp4.reformatted.wav_10.flac_00031728...  520 17 171 657 566 295 902 994 723 723 723 560...\n",
            "5  vocal_1-1.mp4.reformatted.wav_10.flac_00004985...  726 720 571 70 88 40 172 498 20 886 598 479 17...\n",
            "6  vocal_1-1.mp4.reformatted.wav_10.flac_00015961...  1012 479 735 803 81 835 621 378 589 1016 904 1...\n",
            "7  vocal_1-1.mp4.reformatted.wav_10.flac_00025484...  1005 775 90 582 132 612 642 229 19 869 19 894 ...\n",
            "8  vocal_1-1.mp4.reformatted.wav_10.flac_00028275...  913 596 411 560 893 893 661 266 266 580 621 56...\n",
            "dataset.__len__(): 99\n",
            "\n",
            "  | Name  | Type                 | Params | Mode \n",
            "-------------------------------------------------------\n",
            "0 | model | Text2SemanticDecoder | 77.6 M | train\n",
            "-------------------------------------------------------\n",
            "77.6 M    Trainable params\n",
            "0         Non-trainable params\n",
            "77.6 M    Total params\n",
            "310.426   Total estimated model params size (MB)\n",
            "257       Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/content/GPT-SoVITS/GPT_SoVITS/AR/data/dataset.py:224: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  bert_feature = torch.load(path_bert, map_location=\"cpu\")\n",
            "/content/GPT-SoVITS/GPT_SoVITS/AR/data/dataset.py:224: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  bert_feature = torch.load(path_bert, map_location=\"cpu\")\n",
            "/content/GPT-SoVITS/GPT_SoVITS/AR/data/dataset.py:224: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  bert_feature = torch.load(path_bert, map_location=\"cpu\")\n",
            "/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "Epoch 0:   0% 0/15 [00:00<?, ?it/s] /content/GPT-SoVITS/GPT_SoVITS/AR/data/dataset.py:224: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  bert_feature = torch.load(path_bert, map_location=\"cpu\")\n",
            "Killed\n"
          ]
        }
      ],
      "source": [
        "!cd /content/GPT-SoVITS && source activate GPTSoVITS && export is_share=True && python webui.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GYQ6CWPkQOP"
      },
      "source": [
        "# GPT-SoVITS WebUI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_o6a8GS2lWQM"
      },
      "source": [
        "## Env Setup (Run Once Only)\n",
        "## 环境配置, 只需运行一次"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wApQ3Od_kQOR"
      },
      "source": [
        "### 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3WFtm7-5kQOR",
        "outputId": "a958b306-1955-4d99-daa6-587e90f879f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/setup.sh\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/setup.sh\n",
        "set -e\n",
        "\n",
        "cd /content\n",
        "\n",
        "git clone https://github.com/RVC-Boss/GPT-SoVITS.git\n",
        "\n",
        "cd GPT-SoVITS\n",
        "\n",
        "if conda env list | awk '{print $1}' | grep -Fxq \"GPTSoVITS\"; then\n",
        "    :\n",
        "else\n",
        "    conda create -n GPTSoVITS python=3.10 -y\n",
        "fi\n",
        "\n",
        "source activate GPTSoVITS\n",
        "\n",
        "pip install ipykernel\n",
        "\n",
        "bash install.sh --source HF --download-uvr5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oD1HKk5vkQOR"
      },
      "source": [
        "### 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GlfSRacxkQOS",
        "outputId": "cce2d82e-74eb-4c98-c908-097e48b9b1c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏬ Downloading https://repo.anaconda.com/archive/Anaconda3-2024.10-1-Linux-x86_64.sh...\n",
            "📦 Installing...\n",
            "📌 Adjusting configuration...\n",
            "🩹 Patching environment...\n",
            "⏲ Done in 0:01:54\n",
            "🔁 Restarting kernel...\n",
            "Cloning into 'GPT-SoVITS'...\n",
            "remote: Enumerating objects: 5100, done.\u001b[K\n",
            "remote: Counting objects: 100% (270/270), done.\u001b[K\n",
            "remote: Compressing objects: 100% (210/210), done.\u001b[K\n",
            "remote: Total 5100 (delta 135), reused 60 (delta 60), pack-reused 4830 (from 3)\u001b[K\n",
            "Receiving objects: 100% (5100/5100), 13.21 MiB | 17.32 MiB/s, done.\n",
            "Resolving deltas: 100% (2927/2927), done.\n",
            "Channels:\n",
            " - defaults\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/GPTSoVITS\n",
            "\n",
            "  added / updated specs:\n",
            "    - python=3.10\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    ca-certificates-2025.2.25  |       h06a4308_0         129 KB\n",
            "    openssl-3.0.16             |       h5eee18b_0         5.2 MB\n",
            "    pip-25.0                   |  py310h06a4308_0         2.3 MB\n",
            "    python-3.10.16             |       he870216_1        26.9 MB\n",
            "    setuptools-75.8.0          |  py310h06a4308_0         1.6 MB\n",
            "    tzdata-2025a               |       h04d1e81_0         117 KB\n",
            "    wheel-0.45.1               |  py310h06a4308_0         115 KB\n",
            "    xz-5.6.4                   |       h5eee18b_1         567 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        37.0 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main \n",
            "  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu \n",
            "  bzip2              pkgs/main/linux-64::bzip2-1.0.8-h5eee18b_6 \n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2025.2.25-h06a4308_0 \n",
            "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.40-h12ee557_0 \n",
            "  libffi             pkgs/main/linux-64::libffi-3.4.4-h6a678d5_1 \n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-11.2.0-h1234567_1 \n",
            "  libgomp            pkgs/main/linux-64::libgomp-11.2.0-h1234567_1 \n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-11.2.0-h1234567_1 \n",
            "  libuuid            pkgs/main/linux-64::libuuid-1.41.5-h5eee18b_0 \n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.4-h6a678d5_0 \n",
            "  openssl            pkgs/main/linux-64::openssl-3.0.16-h5eee18b_0 \n",
            "  pip                pkgs/main/linux-64::pip-25.0-py310h06a4308_0 \n",
            "  python             pkgs/main/linux-64::python-3.10.16-he870216_1 \n",
            "  readline           pkgs/main/linux-64::readline-8.2-h5eee18b_0 \n",
            "  setuptools         pkgs/main/linux-64::setuptools-75.8.0-py310h06a4308_0 \n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.45.3-h5eee18b_0 \n",
            "  tk                 pkgs/main/linux-64::tk-8.6.14-h39e8969_0 \n",
            "  tzdata             pkgs/main/noarch::tzdata-2025a-h04d1e81_0 \n",
            "  wheel              pkgs/main/linux-64::wheel-0.45.1-py310h06a4308_0 \n",
            "  xz                 pkgs/main/linux-64::xz-5.6.4-h5eee18b_1 \n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.13-h5eee18b_1 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "python-3.10.16       | 26.9 MB   | :   0% 0/1 [00:00<?, ?it/s]\n",
            "openssl-3.0.16       | 5.2 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "pip-25.0             | 2.3 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "setuptools-75.8.0    | 1.6 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "xz-5.6.4             | 567 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2025 | 129 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2025a         | 117 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.16       | 26.9 MB   | :   0% 0.002327735711921963/1 [00:00<00:43, 43.21s/it]\n",
            "\n",
            "pip-25.0             | 2.3 MB    | :   1% 0.013479243289892995/1 [00:00<00:07,  7.70s/it]\u001b[A\u001b[A\n",
            "openssl-3.0.16       | 5.2 MB    | :   1% 0.005965187900324128/1 [00:00<00:17, 17.64s/it]\u001b[A\n",
            "\n",
            "\n",
            "setuptools-75.8.0    | 1.6 MB    | :   2% 0.019094625266230986/1 [00:00<00:05,  5.33s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.16       | 26.9 MB   | :  16% 0.15828602841069347/1 [00:00<00:00,  1.08s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2025 | 129 KB    | :  12% 0.12381823265796574/1 [00:00<00:01,  1.60s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "openssl-3.0.16       | 5.2 MB    | :  44% 0.4444064985741475/1 [00:00<00:00,  2.55it/s]  \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wheel-0.45.1         | 115 KB    | :  14% 0.13956539146286406/1 [00:00<00:01,  1.74s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.16       | 26.9 MB   | :  62% 0.6185957654432617/1 [00:00<00:00,  1.86it/s]\n",
            "\n",
            "\n",
            "\n",
            "xz-5.6.4             | 567 KB    | : 100% 1.0/1 [00:00<00:00,  2.29it/s]                \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "xz-5.6.4             | 567 KB    | : 100% 1.0/1 [00:00<00:00,  2.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2025 | 129 KB    | : 100% 1.0/1 [00:00<00:00,  2.24it/s]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.16       | 26.9 MB   | :  85% 0.8548609402033409/1 [00:00<00:00,  2.04it/s]\n",
            "\n",
            "\n",
            "setuptools-75.8.0    | 1.6 MB    | : 100% 1.0/1 [00:01<00:00,  1.07s/it]                 \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "setuptools-75.8.0    | 1.6 MB    | : 100% 1.0/1 [00:01<00:00,  1.07s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pip-25.0             | 2.3 MB    | : 100% 1.0/1 [00:01<00:00,  1.22s/it]                 \u001b[A\u001b[A\n",
            "\n",
            "pip-25.0             | 2.3 MB    | : 100% 1.0/1 [00:01<00:00,  1.22s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wheel-0.45.1         | 115 KB    | : 100% 1.0/1 [00:01<00:00,  1.28s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "wheel-0.45.1         | 115 KB    | : 100% 1.0/1 [00:01<00:00,  1.28s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2025a         | 117 KB    | : 100% 1.0/1 [00:01<00:00,  1.38s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2025a         | 117 KB    | : 100% 1.0/1 [00:01<00:00,  1.38s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "openssl-3.0.16       | 5.2 MB    | : 100% 1.0/1 [00:01<00:00,  1.71s/it]               \u001b[A\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Preparing transaction: | \b\b/ \b\bdone\n",
            "Verifying transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate GPTSoVITS\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n",
            "Collecting ipykernel\n",
            "  Downloading ipykernel-6.29.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting comm>=0.1.1 (from ipykernel)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting debugpy>=1.6.5 (from ipykernel)\n",
            "  Downloading debugpy-1.8.14-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting ipython>=7.23.1 (from ipykernel)\n",
            "  Downloading ipython-8.36.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting jupyter-client>=6.1.12 (from ipykernel)\n",
            "  Downloading jupyter_client-8.6.3-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting jupyter-core!=5.0.*,>=4.12 (from ipykernel)\n",
            "  Downloading jupyter_core-5.7.2-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting matplotlib-inline>=0.1 (from ipykernel)\n",
            "  Downloading matplotlib_inline-0.1.7-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting nest-asyncio (from ipykernel)\n",
            "  Downloading nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting packaging (from ipykernel)\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting psutil (from ipykernel)\n",
            "  Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting pyzmq>=24 (from ipykernel)\n",
            "  Downloading pyzmq-26.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.0 kB)\n",
            "Collecting tornado>=6.1 (from ipykernel)\n",
            "  Downloading tornado-6.4.2-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting traitlets>=5.4.0 (from ipykernel)\n",
            "  Downloading traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting decorator (from ipython>=7.23.1->ipykernel)\n",
            "  Downloading decorator-5.2.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting exceptiongroup (from ipython>=7.23.1->ipykernel)\n",
            "  Downloading exceptiongroup-1.2.2-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting pexpect>4.3 (from ipython>=7.23.1->ipykernel)\n",
            "  Downloading pexpect-4.9.0-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting prompt_toolkit<3.1.0,>=3.0.41 (from ipython>=7.23.1->ipykernel)\n",
            "  Downloading prompt_toolkit-3.0.51-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting pygments>=2.4.0 (from ipython>=7.23.1->ipykernel)\n",
            "  Downloading pygments-2.19.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting stack_data (from ipython>=7.23.1->ipykernel)\n",
            "  Downloading stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting typing_extensions>=4.6 (from ipython>=7.23.1->ipykernel)\n",
            "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting python-dateutil>=2.8.2 (from jupyter-client>=6.1.12->ipykernel)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting platformdirs>=2.5 (from jupyter-core!=5.0.*,>=4.12->ipykernel)\n",
            "  Downloading platformdirs-4.3.7-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting parso<0.9.0,>=0.8.4 (from jedi>=0.16->ipython>=7.23.1->ipykernel)\n",
            "  Downloading parso-0.8.4-py2.py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting ptyprocess>=0.5 (from pexpect>4.3->ipython>=7.23.1->ipykernel)\n",
            "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting wcwidth (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel)\n",
            "  Downloading wcwidth-0.2.13-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting six>=1.5 (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel)\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting executing>=1.2.0 (from stack_data->ipython>=7.23.1->ipykernel)\n",
            "  Downloading executing-2.2.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting asttokens>=2.1.0 (from stack_data->ipython>=7.23.1->ipykernel)\n",
            "  Downloading asttokens-3.0.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting pure-eval (from stack_data->ipython>=7.23.1->ipykernel)\n",
            "  Downloading pure_eval-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Downloading ipykernel-6.29.5-py3-none-any.whl (117 kB)\n",
            "Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Downloading debugpy-1.8.14-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipython-8.36.0-py3-none-any.whl (831 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m831.1/831.1 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_client-8.6.3-py3-none-any.whl (106 kB)\n",
            "Downloading jupyter_core-5.7.2-py3-none-any.whl (28 kB)\n",
            "Downloading matplotlib_inline-0.1.7-py3-none-any.whl (9.9 kB)\n",
            "Downloading pyzmq-26.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (862 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m862.5/862.5 kB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tornado-6.4.2-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (437 kB)\n",
            "Downloading traitlets-5.14.3-py3-none-any.whl (85 kB)\n",
            "Downloading nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
            "Downloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\n",
            "Downloading platformdirs-4.3.7-py3-none-any.whl (18 kB)\n",
            "Downloading prompt_toolkit-3.0.51-py3-none-any.whl (387 kB)\n",
            "Downloading pygments-2.19.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "Downloading decorator-5.2.1-py3-none-any.whl (9.2 kB)\n",
            "Downloading exceptiongroup-1.2.2-py3-none-any.whl (16 kB)\n",
            "Downloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
            "Downloading asttokens-3.0.0-py3-none-any.whl (26 kB)\n",
            "Downloading executing-2.2.0-py2.py3-none-any.whl (26 kB)\n",
            "Downloading parso-0.8.4-py2.py3-none-any.whl (103 kB)\n",
            "Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading pure_eval-0.2.3-py3-none-any.whl (11 kB)\n",
            "Downloading wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
            "Installing collected packages: wcwidth, pure-eval, ptyprocess, typing_extensions, traitlets, tornado, six, pyzmq, pygments, psutil, prompt_toolkit, platformdirs, pexpect, parso, packaging, nest-asyncio, executing, exceptiongroup, decorator, debugpy, asttokens, stack_data, python-dateutil, matplotlib-inline, jupyter-core, jedi, comm, jupyter-client, ipython, ipykernel\n",
            "Successfully installed asttokens-3.0.0 comm-0.2.2 debugpy-1.8.14 decorator-5.2.1 exceptiongroup-1.2.2 executing-2.2.0 ipykernel-6.29.5 ipython-8.36.0 jedi-0.19.2 jupyter-client-8.6.3 jupyter-core-5.7.2 matplotlib-inline-0.1.7 nest-asyncio-1.6.0 packaging-25.0 parso-0.8.4 pexpect-4.9.0 platformdirs-4.3.7 prompt_toolkit-3.0.51 psutil-7.0.0 ptyprocess-0.7.0 pure-eval-0.2.3 pygments-2.19.1 python-dateutil-2.9.0.post0 pyzmq-26.4.0 six-1.17.0 stack_data-0.6.3 tornado-6.4.2 traitlets-5.14.3 typing_extensions-4.13.2 wcwidth-0.2.13\n",
            "Download Model From HuggingFace\n",
            "Download Pretrained Models\n",
            "--2025-04-28 13:26:07--  https://huggingface.co/XXXXRT/GPT-SoVITS-Pretrained/resolve/main/pretrained_models.zip\n",
            "Resolving huggingface.co (huggingface.co)... 3.166.152.105, 3.166.152.65, 3.166.152.44, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.166.152.105|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.hf.co/repos/31/9c/319c14180e05be63e78aa42441a0f6fd2b9b495cbfd3594dc75d553a4b84c330/0dfc8b39df98bcce2b8b2861de56db22667a6a287b84c2d4396c8a404a02df21?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pretrained_models.zip%3B+filename%3D%22pretrained_models.zip%22%3B&response-content-type=application%2Fzip&Expires=1745850367&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NTg1MDM2N319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzMxLzljLzMxOWMxNDE4MGUwNWJlNjNlNzhhYTQyNDQxYTBmNmZkMmI5YjQ5NWNiZmQzNTk0ZGM3NWQ1NTNhNGI4NGMzMzAvMGRmYzhiMzlkZjk4YmNjZTJiOGIyODYxZGU1NmRiMjI2NjdhNmEyODdiODRjMmQ0Mzk2YzhhNDA0YTAyZGYyMT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=rwqYRtjH%7EKvgq7YiwhF2W4tR8aTzaiBJYnk7q3QjLMT15HrhBD1f2koj2iT4FboiApdLYOnDNlhO%7E0O4NWmqT2mruhx50MjGEabrrATJCQtr7GVsdJ2uOQVpUeZCSLA7bnEAKnOkxkwygSmRSrrm51zEvcSRn3vLhUcYj3cly-GZlt5CPIPdQtgsUZuf9j5RnYhYYueupbk3MwqsKByTShAx-d1Hq5ee1IAEd-KjJB-tXe7TAZl9eiW16COpAeVJBy-gRpZbTxrqMrUxpJDnGWkB1PNB0c4q2d2dDoBZsxsfaoVyZpUOa2iobYUVR56cKPEyP1Z3rzt-0AcxZl9NVA__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2025-04-28 13:26:12--  https://cdn-lfs-us-1.hf.co/repos/31/9c/319c14180e05be63e78aa42441a0f6fd2b9b495cbfd3594dc75d553a4b84c330/0dfc8b39df98bcce2b8b2861de56db22667a6a287b84c2d4396c8a404a02df21?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pretrained_models.zip%3B+filename%3D%22pretrained_models.zip%22%3B&response-content-type=application%2Fzip&Expires=1745850367&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NTg1MDM2N319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzMxLzljLzMxOWMxNDE4MGUwNWJlNjNlNzhhYTQyNDQxYTBmNmZkMmI5YjQ5NWNiZmQzNTk0ZGM3NWQ1NTNhNGI4NGMzMzAvMGRmYzhiMzlkZjk4YmNjZTJiOGIyODYxZGU1NmRiMjI2NjdhNmEyODdiODRjMmQ0Mzk2YzhhNDA0YTAyZGYyMT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=rwqYRtjH%7EKvgq7YiwhF2W4tR8aTzaiBJYnk7q3QjLMT15HrhBD1f2koj2iT4FboiApdLYOnDNlhO%7E0O4NWmqT2mruhx50MjGEabrrATJCQtr7GVsdJ2uOQVpUeZCSLA7bnEAKnOkxkwygSmRSrrm51zEvcSRn3vLhUcYj3cly-GZlt5CPIPdQtgsUZuf9j5RnYhYYueupbk3MwqsKByTShAx-d1Hq5ee1IAEd-KjJB-tXe7TAZl9eiW16COpAeVJBy-gRpZbTxrqMrUxpJDnGWkB1PNB0c4q2d2dDoBZsxsfaoVyZpUOa2iobYUVR56cKPEyP1Z3rzt-0AcxZl9NVA__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 3.166.135.49, 3.166.135.42, 3.166.135.95, ...\n",
            "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|3.166.135.49|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3380113991 (3.1G) [application/zip]\n",
            "Saving to: ‘pretrained_models.zip’\n",
            "\n",
            "pretrained_models.z 100%[===================>]   3.15G   167MB/s    in 17s     \n",
            "\n",
            "2025-04-28 13:26:29 (192 MB/s) - ‘pretrained_models.zip’ saved [3380113991/3380113991]\n",
            "\n",
            "Archive:  pretrained_models.zip\n",
            "   creating: pretrained_models/\n",
            "  inflating: pretrained_models/s2D488k.pth  \n",
            "   creating: pretrained_models/fast_langdetect/\n",
            "  inflating: pretrained_models/fast_langdetect/lid.176.bin  \n",
            "   creating: pretrained_models/gsv-v2final-pretrained/\n",
            "  inflating: pretrained_models/gsv-v2final-pretrained/s2D2333k.pth  \n",
            "  inflating: pretrained_models/gsv-v2final-pretrained/s2G2333k.pth  \n",
            "  inflating: pretrained_models/gsv-v2final-pretrained/s1bert25hz-5kh-longer-epoch=12-step=369668.ckpt  \n",
            "  inflating: pretrained_models/s2G488k.pth  \n",
            "   creating: pretrained_models/chinese-roberta-wwm-ext-large/\n",
            "  inflating: pretrained_models/chinese-roberta-wwm-ext-large/config.json  \n",
            "  inflating: pretrained_models/chinese-roberta-wwm-ext-large/tokenizer.json  \n",
            "  inflating: pretrained_models/chinese-roberta-wwm-ext-large/pytorch_model.bin  \n",
            "  inflating: pretrained_models/README.md  \n",
            " extracting: pretrained_models/.gitignore  \n",
            "  inflating: pretrained_models/s1v3.ckpt  \n",
            "   creating: pretrained_models/gsv-v4-pretrained/\n",
            "  inflating: pretrained_models/gsv-v4-pretrained/s2Gv4.pth  \n",
            "  inflating: pretrained_models/gsv-v4-pretrained/vocoder.pth  \n",
            "  inflating: pretrained_models/s2Gv3.pth  \n",
            "   creating: pretrained_models/chinese-hubert-base/\n",
            "  inflating: pretrained_models/chinese-hubert-base/config.json  \n",
            "  inflating: pretrained_models/chinese-hubert-base/pytorch_model.bin  \n",
            "  inflating: pretrained_models/chinese-hubert-base/preprocessor_config.json  \n",
            "  inflating: pretrained_models/s1bert25hz-2kh-longer-epoch=68e-step=50232.ckpt  \n",
            "   creating: pretrained_models/models--nvidia--bigvgan_v2_24khz_100band_256x/\n",
            "  inflating: pretrained_models/models--nvidia--bigvgan_v2_24khz_100band_256x/config.json  \n",
            "  inflating: pretrained_models/models--nvidia--bigvgan_v2_24khz_100band_256x/bigvgan_generator.pt  \n",
            "Download G2PWModel\n",
            "--2025-04-28 13:27:14--  https://huggingface.co/XXXXRT/GPT-SoVITS-Pretrained/resolve/main/G2PWModel.zip\n",
            "Resolving huggingface.co (huggingface.co)... 3.166.152.110, 3.166.152.44, 3.166.152.65, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.166.152.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.hf.co/repos/31/9c/319c14180e05be63e78aa42441a0f6fd2b9b495cbfd3594dc75d553a4b84c330/46292be0374a49308069233cd5c147ae4c41806558e4781a2467a31a4d8099da?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27G2PWModel.zip%3B+filename%3D%22G2PWModel.zip%22%3B&response-content-type=application%2Fzip&Expires=1745850435&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NTg1MDQzNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzMxLzljLzMxOWMxNDE4MGUwNWJlNjNlNzhhYTQyNDQxYTBmNmZkMmI5YjQ5NWNiZmQzNTk0ZGM3NWQ1NTNhNGI4NGMzMzAvNDYyOTJiZTAzNzRhNDkzMDgwNjkyMzNjZDVjMTQ3YWU0YzQxODA2NTU4ZTQ3ODFhMjQ2N2EzMWE0ZDgwOTlkYT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=Mo5iAHozHaULHONoWwuRLUMZqnHhgXKaMQKhhFokDITfWLFH9cQm5pzjAMSYz7b4WXjTUQd%7E524zRcnMm5xMWNW4yLvaIq1CzTXpkFbWuCCXYVK6AlYFGVIk%7E5AFIrb2G76j1UGh-1iSqOm-eTTV1nT8GAjM9lnD2C5bYSuWbwAzy21tuLKzBA1oALuvO3QNDRlP6QEpqW11xAlU4EXjskm5-1w29%7EaIH2az9-ZGzFh5NbIjtm%7EZLUzDyMJlcg9n%7E8A728FjFfj5E1JswJ0CgI3tO62ZzMbwwrWa8XjebO%7Eg1G3cfPx75S6S2OqFmHsvTUP5GO7AHslHOOJ5cNKsqA__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2025-04-28 13:27:20--  https://cdn-lfs-us-1.hf.co/repos/31/9c/319c14180e05be63e78aa42441a0f6fd2b9b495cbfd3594dc75d553a4b84c330/46292be0374a49308069233cd5c147ae4c41806558e4781a2467a31a4d8099da?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27G2PWModel.zip%3B+filename%3D%22G2PWModel.zip%22%3B&response-content-type=application%2Fzip&Expires=1745850435&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NTg1MDQzNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzMxLzljLzMxOWMxNDE4MGUwNWJlNjNlNzhhYTQyNDQxYTBmNmZkMmI5YjQ5NWNiZmQzNTk0ZGM3NWQ1NTNhNGI4NGMzMzAvNDYyOTJiZTAzNzRhNDkzMDgwNjkyMzNjZDVjMTQ3YWU0YzQxODA2NTU4ZTQ3ODFhMjQ2N2EzMWE0ZDgwOTlkYT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=Mo5iAHozHaULHONoWwuRLUMZqnHhgXKaMQKhhFokDITfWLFH9cQm5pzjAMSYz7b4WXjTUQd%7E524zRcnMm5xMWNW4yLvaIq1CzTXpkFbWuCCXYVK6AlYFGVIk%7E5AFIrb2G76j1UGh-1iSqOm-eTTV1nT8GAjM9lnD2C5bYSuWbwAzy21tuLKzBA1oALuvO3QNDRlP6QEpqW11xAlU4EXjskm5-1w29%7EaIH2az9-ZGzFh5NbIjtm%7EZLUzDyMJlcg9n%7E8A728FjFfj5E1JswJ0CgI3tO62ZzMbwwrWa8XjebO%7Eg1G3cfPx75S6S2OqFmHsvTUP5GO7AHslHOOJ5cNKsqA__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 108.157.173.35, 108.157.173.71, 108.157.173.114, ...\n",
            "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|108.157.173.35|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 588856634 (562M) [application/zip]\n",
            "Saving to: ‘G2PWModel.zip’\n",
            "\n",
            "G2PWModel.zip       100%[===================>] 561.58M   227MB/s    in 2.5s    \n",
            "\n",
            "2025-04-28 13:27:22 (227 MB/s) - ‘G2PWModel.zip’ saved [588856634/588856634]\n",
            "\n",
            "Archive:  G2PWModel.zip\n",
            "   creating: G2PWModel/\n",
            "  inflating: G2PWModel/config.py     \n",
            "  inflating: G2PWModel/g2pW.onnx     \n",
            "  inflating: G2PWModel/char_bopomofo_dict.json  \n",
            "  inflating: G2PWModel/MONOPHONIC_CHARS.txt  \n",
            "  inflating: G2PWModel/bopomofo_to_pinyin_wo_tune_dict.json  \n",
            " extracting: G2PWModel/version       \n",
            "  inflating: G2PWModel/record.log    \n",
            "  inflating: G2PWModel/POLYPHONIC_CHARS.txt  \n",
            "Download UVR5 Model\n",
            "--2025-04-28 13:27:29--  https://huggingface.co/XXXXRT/GPT-SoVITS-Pretrained/resolve/main/uvr5_weights.zip\n",
            "Resolving huggingface.co (huggingface.co)... 3.166.152.110, 3.166.152.44, 3.166.152.65, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.166.152.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.hf.co/repos/31/9c/319c14180e05be63e78aa42441a0f6fd2b9b495cbfd3594dc75d553a4b84c330/1317c4117aed4f08f1780df08d0e6c8d63b3c34b987f8d9bef4ef3bc1f290c21?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27uvr5_weights.zip%3B+filename%3D%22uvr5_weights.zip%22%3B&response-content-type=application%2Fzip&Expires=1745850449&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NTg1MDQ0OX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzMxLzljLzMxOWMxNDE4MGUwNWJlNjNlNzhhYTQyNDQxYTBmNmZkMmI5YjQ5NWNiZmQzNTk0ZGM3NWQ1NTNhNGI4NGMzMzAvMTMxN2M0MTE3YWVkNGYwOGYxNzgwZGYwOGQwZTZjOGQ2M2IzYzM0Yjk4N2Y4ZDliZWY0ZWYzYmMxZjI5MGMyMT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=nOU3UTrpwjoa1aX7x-aNlZ37xVNKHfb7jBB%7Ez46nbrgc-8o%7EhKHpEhDRCVdATFR%7E35aiI67e52tUBXDFu%7EPgjjnBO34fOSiG0bZzWohGZEvtIg3-g7Ko8Tj7KJ36Qis6WC9zteVOqaoPFOETz3Wg9Bj3PDJVxlVY5zk2L3suDSDuPDbfVnP1LLKOdyuQZKl2x0VrgpJscIl0bKe%7ENzv3j1wv7dS%7EjMD6tS-NLm-sJ14lNSRmdGPsC6Si6hhqS0m5mdMKn%7EwvzPD%7ENZX9566qWYlSr6QycX8VN7LV9d-c%7EIdtDQdYAotWQ3X4BADp492fcwWbJilFn1eX5SKlsxUqVw__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2025-04-28 13:27:34--  https://cdn-lfs-us-1.hf.co/repos/31/9c/319c14180e05be63e78aa42441a0f6fd2b9b495cbfd3594dc75d553a4b84c330/1317c4117aed4f08f1780df08d0e6c8d63b3c34b987f8d9bef4ef3bc1f290c21?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27uvr5_weights.zip%3B+filename%3D%22uvr5_weights.zip%22%3B&response-content-type=application%2Fzip&Expires=1745850449&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NTg1MDQ0OX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzMxLzljLzMxOWMxNDE4MGUwNWJlNjNlNzhhYTQyNDQxYTBmNmZkMmI5YjQ5NWNiZmQzNTk0ZGM3NWQ1NTNhNGI4NGMzMzAvMTMxN2M0MTE3YWVkNGYwOGYxNzgwZGYwOGQwZTZjOGQ2M2IzYzM0Yjk4N2Y4ZDliZWY0ZWYzYmMxZjI5MGMyMT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=nOU3UTrpwjoa1aX7x-aNlZ37xVNKHfb7jBB%7Ez46nbrgc-8o%7EhKHpEhDRCVdATFR%7E35aiI67e52tUBXDFu%7EPgjjnBO34fOSiG0bZzWohGZEvtIg3-g7Ko8Tj7KJ36Qis6WC9zteVOqaoPFOETz3Wg9Bj3PDJVxlVY5zk2L3suDSDuPDbfVnP1LLKOdyuQZKl2x0VrgpJscIl0bKe%7ENzv3j1wv7dS%7EjMD6tS-NLm-sJ14lNSRmdGPsC6Si6hhqS0m5mdMKn%7EwvzPD%7ENZX9566qWYlSr6QycX8VN7LV9d-c%7EIdtDQdYAotWQ3X4BADp492fcwWbJilFn1eX5SKlsxUqVw__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 108.157.173.35, 108.157.173.71, 108.157.173.114, ...\n",
            "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|108.157.173.35|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 522922580 (499M) [application/zip]\n",
            "Saving to: ‘uvr5_weights.zip’\n",
            "\n",
            "uvr5_weights.zip    100%[===================>] 498.70M   271MB/s    in 1.8s    \n",
            "\n",
            "2025-04-28 13:27:36 (271 MB/s) - ‘uvr5_weights.zip’ saved [522922580/522922580]\n",
            "\n",
            "Archive:  uvr5_weights.zip\n",
            "   creating: uvr5_weights/\n",
            "   creating: uvr5_weights/onnx_dereverb_By_FoxJoy/\n",
            "  inflating: uvr5_weights/onnx_dereverb_By_FoxJoy/vocals.onnx  \n",
            "  inflating: uvr5_weights/HP5_only_main_vocal.pth  \n",
            "  inflating: uvr5_weights/model_bs_roformer_ep_317_sdr_12.9755.ckpt  \n",
            " extracting: uvr5_weights/.gitignore  \n",
            "  inflating: uvr5_weights/HP2_all_vocals.pth  \n",
            "  inflating: uvr5_weights/VR-DeEchoNormal.pth  \n",
            "  inflating: uvr5_weights/VR-DeEchoAggressive.pth  \n",
            "  inflating: uvr5_weights/VR-DeEchoDeReverb.pth  \n",
            "Installing GCC...\n",
            "Channels:\n",
            " - conda-forge\n",
            " - defaults\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\b| \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/GPTSoVITS\n",
            "\n",
            "  added / updated specs:\n",
            "    - gcc=14\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    binutils_impl_linux-64-2.40|       h5293946_0         8.7 MB\n",
            "    ca-certificates-2025.4.26  |       hbd8a1cb_0         149 KB  conda-forge\n",
            "    gcc-14.2.0                 |       h96c4ede_2          54 KB  conda-forge\n",
            "    gcc_impl_linux-64-14.2.0   |       hdb7739f_2        70.1 MB  conda-forge\n",
            "    kernel-headers_linux-64-3.10.0|      he073ed8_18         921 KB  conda-forge\n",
            "    libgcc-14.2.0              |       h767d61c_2         828 KB  conda-forge\n",
            "    libgcc-devel_linux-64-14.2.0|     h9c4974d_102         2.6 MB  conda-forge\n",
            "    libgcc-ng-14.2.0           |       h69a702a_2          52 KB  conda-forge\n",
            "    libgomp-14.2.0             |       h767d61c_2         449 KB  conda-forge\n",
            "    libsanitizer-14.2.0        |       hed042b8_2         4.3 MB  conda-forge\n",
            "    libstdcxx-14.2.0           |       h8f9b012_2         3.7 MB  conda-forge\n",
            "    openssl-3.5.0              |       h7b32b05_0         3.0 MB  conda-forge\n",
            "    sysroot_linux-64-2.17      |      h0157908_18        14.5 MB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       109.3 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  binutils_impl_lin~ pkgs/main/linux-64::binutils_impl_linux-64-2.40-h5293946_0 \n",
            "  gcc                conda-forge/linux-64::gcc-14.2.0-h96c4ede_2 \n",
            "  gcc_impl_linux-64  conda-forge/linux-64::gcc_impl_linux-64-14.2.0-hdb7739f_2 \n",
            "  kernel-headers_li~ conda-forge/noarch::kernel-headers_linux-64-3.10.0-he073ed8_18 \n",
            "  libgcc             conda-forge/linux-64::libgcc-14.2.0-h767d61c_2 \n",
            "  libgcc-devel_linu~ conda-forge/noarch::libgcc-devel_linux-64-14.2.0-h9c4974d_102 \n",
            "  libsanitizer       conda-forge/linux-64::libsanitizer-14.2.0-hed042b8_2 \n",
            "  libstdcxx          conda-forge/linux-64::libstdcxx-14.2.0-h8f9b012_2 \n",
            "  sysroot_linux-64   conda-forge/noarch::sysroot_linux-64-2.17-h0157908_18 \n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2~ --> conda-forge/noarch::ca-certificates-2025.4.26-hbd8a1cb_0 \n",
            "  libgcc-ng          pkgs/main::libgcc-ng-11.2.0-h1234567_1 --> conda-forge::libgcc-ng-14.2.0-h69a702a_2 \n",
            "  libgomp              pkgs/main::libgomp-11.2.0-h1234567_1 --> conda-forge::libgomp-14.2.0-h767d61c_2 \n",
            "  openssl              pkgs/main::openssl-3.0.16-h5eee18b_0 --> conda-forge::openssl-3.5.0-h7b32b05_0 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "gcc_impl_linux-64-14 | 70.1 MB   | :   0% 0/1 [00:00<?, ?it/s]\n",
            "sysroot_linux-64-2.1 | 14.5 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "binutils_impl_linux- | 8.7 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libsanitizer-14.2.0  | 4.3 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libstdcxx-14.2.0     | 3.7 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openssl-3.5.0        | 3.0 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-devel_linux-6 | 2.6 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "kernel-headers_linux | 921 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-14.2.0        | 828 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-14.2.0       | 449 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2025 | 149 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gcc-14.2.0           | 54 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-ng-14.2.0     | 52 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "binutils_impl_linux- | 8.7 MB    | :   1% 0.014414850357616346/1 [00:00<00:07,  7.49s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libsanitizer-14.2.0  | 4.3 MB    | :   0% 0.003634472832847968/1 [00:00<00:30, 30.69s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "gcc_impl_linux-64-14 | 70.1 MB   | :   0% 0.00022277339965410568/1 [00:00<09:35, 575.45s/it]\n",
            "sysroot_linux-64-2.1 | 14.5 MB   | :   0% 0.001080245621375624/1 [00:00<02:21, 141.73s/it]\u001b[A\n",
            "\n",
            "binutils_impl_linux- | 8.7 MB    | :  64% 0.6378571283245233/1 [00:00<00:00,  3.60it/s]  \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libstdcxx-14.2.0     | 3.7 MB    | :  73% 0.7338846447315986/1 [00:00<00:00,  4.15it/s]   \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "gcc_impl_linux-64-14 | 70.1 MB   | :   4% 0.040544758737047236/1 [00:00<00:04,  4.69s/it]   \n",
            "gcc_impl_linux-64-14 | 70.1 MB   | :  11% 0.10514904463673788/1 [00:00<00:02,  2.51s/it] \n",
            "sysroot_linux-64-2.1 | 14.5 MB   | :  39% 0.38888842369522464/1 [00:00<00:00,  1.35it/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-devel_linux-6 | 2.6 MB    | :   1% 0.005933699312394927/1 [00:00<01:01, 61.48s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gcc_impl_linux-64-14 | 70.1 MB   | :  23% 0.23368929623715687/1 [00:00<00:01,  1.84s/it]\n",
            "sysroot_linux-64-2.1 | 14.5 MB   | :  54% 0.540122810687812/1 [00:00<00:00,  1.11it/s]  \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-14.2.0        | 828 KB    | :   2% 0.01932337522187561/1 [00:00<00:28, 28.83s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "kernel-headers_linux | 921 KB    | :   2% 0.017365387509724575/1 [00:00<00:32, 33.20s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-14.2.0       | 449 KB    | :   4% 0.03562807972826631/1 [00:00<00:15, 16.41s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "gcc_impl_linux-64-14 | 70.1 MB   | :  33% 0.32725412409188126/1 [00:00<00:01,  1.51s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2025 | 149 KB    | :  11% 0.10758915965669182/1 [00:00<00:05,  6.54s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gcc-14.2.0           | 54 KB     | :  30% 0.2956226769153044/1 [00:00<00:01,  2.38s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gcc_impl_linux-64-14 | 70.1 MB   | :  39% 0.3940861439881129/1 [00:00<00:00,  1.52s/it] \n",
            "sysroot_linux-64-2.1 | 14.5 MB   | :  96% 0.9635790942670566/1 [00:00<00:00,  1.56it/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "gcc_impl_linux-64-14 | 70.1 MB   | :  50% 0.5001262822234672/1 [00:00<00:00,  1.28s/it]\n",
            "\n",
            "\n",
            "gcc_impl_linux-64-14 | 70.1 MB   | :  60% 0.5974782578723115/1 [00:00<00:00,  1.19s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-devel_linux-6 | 2.6 MB    | : 100% 1.0/1 [00:01<00:00,  1.07it/s]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gcc_impl_linux-64-14 | 70.1 MB   | :  95% 0.9461186283309868/1 [00:01<00:00,  1.06it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openssl-3.5.0        | 3.0 MB    | : 100% 1.0/1 [00:01<00:00,  1.29s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openssl-3.5.0        | 3.0 MB    | : 100% 1.0/1 [00:01<00:00,  1.29s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "binutils_impl_linux- | 8.7 MB    | : 100% 1.0/1 [00:01<00:00,  3.60it/s]               \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-14.2.0       | 449 KB    | : 100% 1.0/1 [00:01<00:00,  1.33s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-14.2.0       | 449 KB    | : 100% 1.0/1 [00:01<00:00,  1.33s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-14.2.0        | 828 KB    | : 100% 1.0/1 [00:01<00:00,  1.42s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-14.2.0        | 828 KB    | : 100% 1.0/1 [00:01<00:00,  1.42s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gcc-14.2.0           | 54 KB     | : 100% 1.0/1 [00:01<00:00,  1.58s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gcc-14.2.0           | 54 KB     | : 100% 1.0/1 [00:01<00:00,  1.58s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2025 | 149 KB    | : 100% 1.0/1 [00:01<00:00,  1.51s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2025 | 149 KB    | : 100% 1.0/1 [00:01<00:00,  1.51s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-ng-14.2.0     | 52 KB     | : 100% 1.0/1 [00:01<00:00,  1.69s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-ng-14.2.0     | 52 KB     | : 100% 1.0/1 [00:01<00:00,  1.69s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "kernel-headers_linux | 921 KB    | : 100% 1.0/1 [00:02<00:00,  2.03s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "kernel-headers_linux | 921 KB    | : 100% 1.0/1 [00:02<00:00,  2.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Preparing transaction: - \b\bdone\n",
            "Verifying transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\bdone\n",
            "Installing G++...\n",
            "Channels:\n",
            " - conda-forge\n",
            " - defaults\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/GPTSoVITS\n",
            "\n",
            "  added / updated specs:\n",
            "    - gxx\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    gxx-14.2.0                 |       h96c4ede_2          54 KB  conda-forge\n",
            "    gxx_impl_linux-64-14.2.0   |       h2ead766_2        13.9 MB  conda-forge\n",
            "    libstdcxx-devel_linux-64-14.2.0|     h9c4974d_102        12.9 MB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        26.9 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  gxx                conda-forge/linux-64::gxx-14.2.0-h96c4ede_2 \n",
            "  gxx_impl_linux-64  conda-forge/linux-64::gxx_impl_linux-64-14.2.0-h2ead766_2 \n",
            "  libstdcxx-devel_l~ conda-forge/noarch::libstdcxx-devel_linux-64-14.2.0-h9c4974d_102 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "gxx_impl_linux-64-14 | 13.9 MB   | :   0% 0/1 [00:00<?, ?it/s]\n",
            "libstdcxx-devel_linu | 12.9 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "gxx-14.2.0           | 54 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "gxx_impl_linux-64-14 | 13.9 MB   | :   0% 0.0011212732583445342/1 [00:00<01:49, 110.02s/it]\n",
            "\n",
            "gxx-14.2.0           | 54 KB     | :  30% 0.2984117732769926/1 [00:00<00:00,  2.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "gxx-14.2.0           | 54 KB     | : 100% 1.0/1 [00:00<00:00,  2.49it/s]               \u001b[A\u001b[A\n",
            "gxx_impl_linux-64-14 | 13.9 MB   | :  99% 0.9945693801516018/1 [00:00<00:00,  3.83it/s] \n",
            "gxx_impl_linux-64-14 | 13.9 MB   | : 100% 1.0/1 [00:00<00:00,  3.83it/s]               \n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\n",
            "Preparing transaction: / \b\bdone\n",
            "Verifying transaction: \\ \b\b| \b\bdone\n",
            "Executing transaction: - \b\bdone\n",
            "Installing ffmpeg and cmake...\n",
            "Channels:\n",
            " - defaults\n",
            " - conda-forge\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\b/ \b\b- \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/GPTSoVITS\n",
            "\n",
            "  added / updated specs:\n",
            "    - cmake\n",
            "    - ffmpeg\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    cairo-1.16.0               |       hb05425b_5         1.2 MB\n",
            "    cmake-3.31.2               |       h27e300b_0        20.9 MB\n",
            "    expat-2.7.1                |       h6a678d5_0         182 KB\n",
            "    ffmpeg-6.1.1               |       h2a67f75_3         9.6 MB\n",
            "    fontconfig-2.14.1          |       h55d465d_3         281 KB\n",
            "    freetype-2.13.3            |       h4a9f257_0         686 KB\n",
            "    giflib-5.2.2               |       h5eee18b_0          80 KB\n",
            "    graphite2-1.3.14           |       h295c915_1          97 KB\n",
            "    harfbuzz-10.2.0            |       hf296adc_0         2.4 MB\n",
            "    lame-3.100                 |       h7b6447c_0         323 KB\n",
            "    leptonica-1.82.0           |       hfdeec58_3         2.5 MB\n",
            "    lerc-4.0.0                 |       h6a678d5_0         261 KB\n",
            "    libarchive-3.7.7           |       hfab0078_0         936 KB\n",
            "    libcurl-8.12.1             |       hc9e6f67_0         469 KB\n",
            "    libdeflate-1.22            |       h5eee18b_0          68 KB\n",
            "    libogg-1.3.5               |       h27cfd23_1         199 KB\n",
            "    libopus-1.3.1              |       h5eee18b_1         345 KB\n",
            "    libssh2-1.11.1             |       h251f7ec_0         308 KB\n",
            "    libtheora-1.1.1            |       h7f8727e_3         338 KB\n",
            "    libtiff-4.7.0              |       hde9077f_0         447 KB\n",
            "    libuv-1.48.0               |       h5eee18b_0         950 KB\n",
            "    libvorbis-1.3.7            |       h7b6447c_0         398 KB\n",
            "    libvpx-1.13.1              |       h6a678d5_0         1.0 MB\n",
            "    libwebp-1.3.2              |       h9f374a3_1          94 KB\n",
            "    libwebp-base-1.3.2         |       h5eee18b_1         425 KB\n",
            "    libxml2-2.13.7             |       hfdd30dd_0         739 KB\n",
            "    openh264-2.1.1             |       h4ff587b_0         711 KB\n",
            "    openjpeg-2.5.2             |       h0d4d230_1         373 KB\n",
            "    pixman-0.40.0              |       h7f8727e_1         373 KB\n",
            "    rhash-1.4.3                |       hdbd6064_0         220 KB\n",
            "    tesseract-5.2.0            |       h6a678d5_2       173.0 MB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       219.6 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  aom                pkgs/main/linux-64::aom-3.6.0-h6a678d5_0 \n",
            "  c-ares             pkgs/main/linux-64::c-ares-1.19.1-h5eee18b_0 \n",
            "  cairo              pkgs/main/linux-64::cairo-1.16.0-hb05425b_5 \n",
            "  cmake              pkgs/main/linux-64::cmake-3.31.2-h27e300b_0 \n",
            "  dav1d              pkgs/main/linux-64::dav1d-1.2.1-h5eee18b_0 \n",
            "  expat              pkgs/main/linux-64::expat-2.7.1-h6a678d5_0 \n",
            "  ffmpeg             pkgs/main/linux-64::ffmpeg-6.1.1-h2a67f75_3 \n",
            "  fontconfig         pkgs/main/linux-64::fontconfig-2.14.1-h55d465d_3 \n",
            "  freetype           pkgs/main/linux-64::freetype-2.13.3-h4a9f257_0 \n",
            "  giflib             pkgs/main/linux-64::giflib-5.2.2-h5eee18b_0 \n",
            "  glib               pkgs/main/linux-64::glib-2.78.4-h6a678d5_0 \n",
            "  glib-tools         pkgs/main/linux-64::glib-tools-2.78.4-h6a678d5_0 \n",
            "  graphite2          pkgs/main/linux-64::graphite2-1.3.14-h295c915_1 \n",
            "  harfbuzz           pkgs/main/linux-64::harfbuzz-10.2.0-hf296adc_0 \n",
            "  icu                pkgs/main/linux-64::icu-73.1-h6a678d5_0 \n",
            "  jpeg               pkgs/main/linux-64::jpeg-9e-h5eee18b_3 \n",
            "  krb5               pkgs/main/linux-64::krb5-1.20.1-h143b758_1 \n",
            "  lame               pkgs/main/linux-64::lame-3.100-h7b6447c_0 \n",
            "  leptonica          pkgs/main/linux-64::leptonica-1.82.0-hfdeec58_3 \n",
            "  lerc               pkgs/main/linux-64::lerc-4.0.0-h6a678d5_0 \n",
            "  libarchive         pkgs/main/linux-64::libarchive-3.7.7-hfab0078_0 \n",
            "  libcurl            pkgs/main/linux-64::libcurl-8.12.1-hc9e6f67_0 \n",
            "  libdeflate         pkgs/main/linux-64::libdeflate-1.22-h5eee18b_0 \n",
            "  libedit            pkgs/main/linux-64::libedit-3.1.20230828-h5eee18b_0 \n",
            "  libev              pkgs/main/linux-64::libev-4.33-h7f8727e_1 \n",
            "  libglib            pkgs/main/linux-64::libglib-2.78.4-hdc74915_0 \n",
            "  libiconv           pkgs/main/linux-64::libiconv-1.16-h5eee18b_3 \n",
            "  libnghttp2         pkgs/main/linux-64::libnghttp2-1.57.0-h2d74bed_0 \n",
            "  libogg             pkgs/main/linux-64::libogg-1.3.5-h27cfd23_1 \n",
            "  libopus            pkgs/main/linux-64::libopus-1.3.1-h5eee18b_1 \n",
            "  libpng             pkgs/main/linux-64::libpng-1.6.39-h5eee18b_0 \n",
            "  libssh2            pkgs/main/linux-64::libssh2-1.11.1-h251f7ec_0 \n",
            "  libtheora          pkgs/main/linux-64::libtheora-1.1.1-h7f8727e_3 \n",
            "  libtiff            pkgs/main/linux-64::libtiff-4.7.0-hde9077f_0 \n",
            "  libuv              pkgs/main/linux-64::libuv-1.48.0-h5eee18b_0 \n",
            "  libvorbis          pkgs/main/linux-64::libvorbis-1.3.7-h7b6447c_0 \n",
            "  libvpx             pkgs/main/linux-64::libvpx-1.13.1-h6a678d5_0 \n",
            "  libwebp            pkgs/main/linux-64::libwebp-1.3.2-h9f374a3_1 \n",
            "  libwebp-base       pkgs/main/linux-64::libwebp-base-1.3.2-h5eee18b_1 \n",
            "  libxcb             pkgs/main/linux-64::libxcb-1.15-h7f8727e_0 \n",
            "  libxml2            pkgs/main/linux-64::libxml2-2.13.7-hfdd30dd_0 \n",
            "  lz4-c              pkgs/main/linux-64::lz4-c-1.9.4-h6a678d5_1 \n",
            "  openh264           pkgs/main/linux-64::openh264-2.1.1-h4ff587b_0 \n",
            "  openjpeg           pkgs/main/linux-64::openjpeg-2.5.2-h0d4d230_1 \n",
            "  pcre2              pkgs/main/linux-64::pcre2-10.42-hebb0a14_1 \n",
            "  pixman             pkgs/main/linux-64::pixman-0.40.0-h7f8727e_1 \n",
            "  rhash              pkgs/main/linux-64::rhash-1.4.3-hdbd6064_0 \n",
            "  tesseract          pkgs/main/linux-64::tesseract-5.2.0-h6a678d5_2 \n",
            "  zstd               pkgs/main/linux-64::zstd-1.5.6-hc292b87_0 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "tesseract-5.2.0      | 173.0 MB  | :   0% 0/1 [00:00<?, ?it/s]\n",
            "cmake-3.31.2         | 20.9 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "ffmpeg-6.1.1         | 9.6 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "leptonica-1.82.0     | 2.5 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "harfbuzz-10.2.0      | 2.4 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cairo-1.16.0         | 1.2 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libvpx-1.13.1        | 1.0 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libuv-1.48.0         | 950 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libarchive-3.7.7     | 936 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libxml2-2.13.7       | 739 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openh264-2.1.1       | 711 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "freetype-2.13.3      | 686 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurl-8.12.1       | 469 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libtiff-4.7.0        | 447 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libwebp-base-1.3.2   | 425 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libvorbis-1.3.7      | 398 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pixman-0.40.0        | 373 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openjpeg-2.5.2       | 373 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopus-1.3.1        | 345 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "tesseract-5.2.0      | 173.0 MB  | :   0% 0.0003613238142386283/1 [00:00<05:00, 300.74s/it]\n",
            "\n",
            "\n",
            "leptonica-1.82.0     | 2.5 MB    | :   1% 0.01265434649460545/1 [00:00<00:08,  8.25s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "ffmpeg-6.1.1         | 9.6 MB    | :   2% 0.016335384262895197/1 [00:00<00:06,  6.59s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "harfbuzz-10.2.0      | 2.4 MB    | :   1% 0.006552108740050765/1 [00:00<00:15, 16.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "tesseract-5.2.0      | 173.0 MB  | :   2% 0.0197824788295649/1 [00:00<00:08,  8.98s/it]    \n",
            "\n",
            "ffmpeg-6.1.1         | 9.6 MB    | :  48% 0.4802602973291188/1 [00:00<00:00,  2.71it/s]  \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "harfbuzz-10.2.0      | 2.4 MB    | :  97% 0.9697120935275131/1 [00:00<00:00,  5.28it/s]  \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cairo-1.16.0         | 1.2 MB    | :   1% 0.013563823402065868/1 [00:00<00:20, 21.24s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cmake-3.31.2         | 20.9 MB   | :  40% 0.4033045211788197/1 [00:00<00:00,  1.54it/s] \u001b[A\n",
            "\n",
            "tesseract-5.2.0      | 173.0 MB  | :   5% 0.0523919530646011/1 [00:00<00:04,  4.86s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libvpx-1.13.1        | 1.0 MB    | :   1% 0.014986754869963557/1 [00:00<00:21, 21.39s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tesseract-5.2.0      | 173.0 MB  | :   8% 0.07678131052570851/1 [00:00<00:04,  4.53s/it]\n",
            "cmake-3.31.2         | 20.9 MB   | :  56% 0.5589396610771398/1 [00:00<00:00,  1.51it/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libarchive-3.7.7     | 936 KB    | :   2% 0.01709225163082656/1 [00:00<00:23, 24.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tesseract-5.2.0      | 173.0 MB  | :  10% 0.09927371796206312/1 [00:00<00:04,  4.51s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openh264-2.1.1       | 711 KB    | :   2% 0.022519043050626613/1 [00:00<00:21, 22.33s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "cmake-3.31.2         | 20.9 MB   | :  77% 0.7654555197883721/1 [00:00<00:00,  1.70it/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "freetype-2.13.3      | 686 KB    | :   2% 0.023320560923257364/1 [00:00<00:21, 21.77s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libtiff-4.7.0        | 447 KB    | :   4% 0.035764101870062626/1 [00:00<00:15, 15.72s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurl-8.12.1       | 469 KB    | :   3% 0.034121106603467094/1 [00:00<00:15, 16.52s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tesseract-5.2.0      | 173.0 MB  | :  12% 0.12438572305164779/1 [00:00<00:03,  4.33s/it]\n",
            "cmake-3.31.2         | 20.9 MB   | :  98% 0.9772090995538748/1 [00:00<00:00,  1.83it/s]\u001b[A\n",
            "\n",
            "\n",
            "leptonica-1.82.0     | 2.5 MB    | : 100% 1.0/1 [00:00<00:00,  1.72it/s]                \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "leptonica-1.82.0     | 2.5 MB    | : 100% 1.0/1 [00:00<00:00,  1.72it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pixman-0.40.0        | 373 KB    | :   4% 0.04287523682915851/1 [00:00<00:13, 14.33s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libvorbis-1.3.7      | 398 KB    | :   4% 0.04017163172735074/1 [00:00<00:14, 15.39s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openjpeg-2.5.2       | 373 KB    | :   4% 0.04290454106229591/1 [00:00<00:14, 14.70s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopus-1.3.1        | 345 KB    | :   5% 0.046311397793537774/1 [00:00<00:13, 14.36s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tesseract-5.2.0      | 173.0 MB  | :  15% 0.1483234257449569/1 [00:00<00:03,  4.30s/it] \n",
            "\n",
            "\n",
            "\n",
            "tesseract-5.2.0      | 173.0 MB  | :  18% 0.18418481430814077/1 [00:00<00:03,  3.68s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libvpx-1.13.1        | 1.0 MB    | : 100% 1.0/1 [00:00<00:00,  1.30it/s]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tesseract-5.2.0      | 173.0 MB  | :  22% 0.22420142673506885/1 [00:00<00:02,  3.21s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cairo-1.16.0         | 1.2 MB    | : 100% 1.0/1 [00:00<00:00,  1.13it/s]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libuv-1.48.0         | 950 KB    | : 100% 1.0/1 [00:00<00:00,  1.16it/s]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cairo-1.16.0         | 1.2 MB    | : 100% 1.0/1 [00:00<00:00,  1.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tesseract-5.2.0      | 173.0 MB  | :  27% 0.2692765725613377/1 [00:01<00:02,  2.83s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libxml2-2.13.7       | 739 KB    | : 100% 1.0/1 [00:01<00:00,  1.03it/s]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tesseract-5.2.0      | 173.0 MB  | :  31% 0.3072155730563937/1 [00:01<00:01,  2.77s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libarchive-3.7.7     | 936 KB    | : 100% 1.0/1 [00:01<00:00,  1.01s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tesseract-5.2.0      | 173.0 MB  | :  34% 0.3433479544802565/1 [00:01<00:01,  2.82s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "freetype-2.13.3      | 686 KB    | : 100% 1.0/1 [00:01<00:00,  1.09s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tesseract-5.2.0      | 173.0 MB  | :  39% 0.3892360788885623/1 [00:01<00:01,  2.63s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openh264-2.1.1       | 711 KB    | : 100% 1.0/1 [00:01<00:00,  1.19s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openh264-2.1.1       | 711 KB    | : 100% 1.0/1 [00:01<00:00,  1.19s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libtiff-4.7.0        | 447 KB    | : 100% 1.0/1 [00:01<00:00,  1.24s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tesseract-5.2.0      | 173.0 MB  | :  45% 0.4522870844732029/1 [00:01<00:01,  2.20s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurl-8.12.1       | 469 KB    | : 100% 1.0/1 [00:01<00:00,  1.27s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcurl-8.12.1       | 469 KB    | : 100% 1.0/1 [00:01<00:00,  1.27s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libwebp-base-1.3.2   | 425 KB    | : 100% 1.0/1 [00:01<00:00,  1.32s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libwebp-base-1.3.2   | 425 KB    | : 100% 1.0/1 [00:01<00:00,  1.32s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pixman-0.40.0        | 373 KB    | : 100% 1.0/1 [00:01<00:00,  1.34s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tesseract-5.2.0      | 173.0 MB  | :  50% 0.49790421602082974/1 [00:01<00:01,  2.69s/it]\n",
            "\n",
            "tesseract-5.2.0      | 173.0 MB  | :  56% 0.5597809192091948/1 [00:01<00:01,  2.32s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libvorbis-1.3.7      | 398 KB    | : 100% 1.0/1 [00:01<00:00,  1.54s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libvorbis-1.3.7      | 398 KB    | : 100% 1.0/1 [00:01<00:00,  1.54s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openjpeg-2.5.2       | 373 KB    | : 100% 1.0/1 [00:01<00:00,  1.56s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openjpeg-2.5.2       | 373 KB    | : 100% 1.0/1 [00:01<00:00,  1.56s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopus-1.3.1        | 345 KB    | : 100% 1.0/1 [00:01<00:00,  1.60s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tesseract-5.2.0      | 173.0 MB  | :  61% 0.6053980507568216/1 [00:01<00:00,  2.39s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tesseract-5.2.0      | 173.0 MB  | :  97% 0.9689801388344413/1 [00:05<00:00, 18.86s/it]\n",
            "tesseract-5.2.0      | 173.0 MB  | : 100% 1.0/1 [00:09<00:00, 18.86s/it]               \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Preparing transaction: | \b\b/ \b\bdone\n",
            "Verifying transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Installing git-lfs and zip...\n",
            "Channels:\n",
            " - defaults\n",
            " - conda-forge\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/GPTSoVITS\n",
            "\n",
            "  added / updated specs:\n",
            "    - git-lfs\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    git-lfs-3.6.1              |       he404d97_0         4.0 MB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:         4.0 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  git-lfs            pkgs/main/linux-64::git-lfs-3.6.1-he404d97_0 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "                                                                        \n",
            "Preparing transaction: / \b\bdone\n",
            "Verifying transaction: \\ \b\b| \b\bdone\n",
            "Executing transaction: - \b\bdone\n",
            "Channels:\n",
            " - defaults\n",
            " - conda-forge\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/GPTSoVITS\n",
            "\n",
            "  added / updated specs:\n",
            "    - zip\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    zip-3.0                    |       h7f8727e_1         111 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:         111 KB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  zip                pkgs/main/linux-64::zip-3.0-h7f8727e_1 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "                                                                        \n",
            "Preparing transaction: / \b\bdone\n",
            "Verifying transaction: \\ \b\b| \b\bdone\n",
            "Executing transaction: - \b\bdone\n",
            "Updated Git hooks.\n",
            "Git LFS initialized.\n",
            "Checking for CUDA installation...\n",
            "CUDA found.\n",
            "Installing PyTorch with CUDA support...\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
            "Collecting torch==2.5.1\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torch-2.5.1%2Bcu124-cp310-cp310-linux_x86_64.whl (908.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.5.1\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.5.1%2Bcu124-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filelock (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/envs/GPTSoVITS/lib/python3.10/site-packages (from torch==2.5.1) (4.13.2)\n",
            "Collecting networkx (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting jinja2 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/Jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting fsspec (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m114.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m114.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.147 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.21.5 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.4.127 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m116.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.1.0 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sympy==1.13.1 (from torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting MarkupSafe>=2.0 (from jinja2->torch==2.5.1)\n",
            "  Downloading https://download.pytorch.org/whl/MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl (11 kB)\n",
            "Downloading https://download.pytorch.org/whl/fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
            "Downloading https://download.pytorch.org/whl/Jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
            "Downloading https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mpmath, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchaudio\n",
            "Successfully installed MarkupSafe-2.1.5 filelock-3.13.1 fsspec-2024.6.1 jinja2-3.1.4 mpmath-1.3.0 networkx-3.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.5.1+cu124 torchaudio-2.5.1+cu124 triton-3.1.0\n",
            "Installing Python dependencies from requirements.txt...\n",
            "Collecting faster-whisper (from -r extra-req.txt (line 1))\n",
            "  Downloading faster_whisper-1.1.1-py3-none-any.whl.metadata (16 kB)\n",
            "Downloading faster_whisper-1.1.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faster-whisper\n",
            "Successfully installed faster-whisper-1.1.1\n",
            "Ignoring onnxruntime: markers 'sys_platform == \"darwin\"' don't match your environment\n",
            "Ignoring opencc: markers 'sys_platform != \"linux\"' don't match your environment\n",
            "Collecting numpy<2.0 (from -r requirements.txt (line 1))\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting scipy (from -r requirements.txt (line 2))\n",
            "  Downloading scipy-1.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting tensorboard (from -r requirements.txt (line 3))\n",
            "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting librosa==0.10.2 (from -r requirements.txt (line 4))\n",
            "  Downloading librosa-0.10.2-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting numba (from -r requirements.txt (line 5))\n",
            "  Downloading numba-0.61.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
            "Collecting pytorch-lightning>=2.4 (from -r requirements.txt (line 6))\n",
            "  Downloading pytorch_lightning-2.5.1.post0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting gradio<5 (from -r requirements.txt (line 7))\n",
            "  Downloading gradio-4.44.1-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting ffmpeg-python (from -r requirements.txt (line 8))\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting onnxruntime-gpu (from -r requirements.txt (line 10))\n",
            "  Downloading onnxruntime_gpu-1.21.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting tqdm (from -r requirements.txt (line 11))\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting funasr==1.0.27 (from -r requirements.txt (line 12))\n",
            "  Downloading funasr-1.0.27-py3-none-any.whl.metadata (26 kB)\n",
            "Collecting cn2an (from -r requirements.txt (line 13))\n",
            "  Downloading cn2an-0.5.23-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pypinyin (from -r requirements.txt (line 14))\n",
            "  Downloading pypinyin-0.54.0-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting pyopenjtalk>=0.4.1 (from -r requirements.txt (line 15))\n",
            "  Downloading pyopenjtalk-0.4.1.tar.gz (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting g2p_en (from -r requirements.txt (line 16))\n",
            "  Downloading g2p_en-2.1.0-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: torchaudio in /usr/local/envs/GPTSoVITS/lib/python3.10/site-packages (from -r requirements.txt (line 17)) (2.5.1+cu124)\n",
            "Collecting modelscope==1.10.0 (from -r requirements.txt (line 18))\n",
            "  Downloading modelscope-1.10.0-py3-none-any.whl.metadata (33 kB)\n",
            "Collecting sentencepiece (from -r requirements.txt (line 19))\n",
            "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting transformers>=4.43 (from -r requirements.txt (line 20))\n",
            "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting peft (from -r requirements.txt (line 21))\n",
            "  Downloading peft-0.15.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting chardet (from -r requirements.txt (line 22))\n",
            "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting PyYAML (from -r requirements.txt (line 23))\n",
            "  Downloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/envs/GPTSoVITS/lib/python3.10/site-packages (from -r requirements.txt (line 24)) (7.0.0)\n",
            "Collecting jieba_fast (from -r requirements.txt (line 25))\n",
            "  Downloading jieba_fast-0.53.tar.gz (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m116.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jieba (from -r requirements.txt (line 26))\n",
            "  Downloading jieba-0.42.1.tar.gz (19.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting split-lang (from -r requirements.txt (line 27))\n",
            "  Downloading split_lang-2.1.0-py3-none-any.whl.metadata (86 kB)\n",
            "Collecting fast_langdetect>=0.3.1 (from -r requirements.txt (line 28))\n",
            "  Downloading fast_langdetect-0.3.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting wordsegment (from -r requirements.txt (line 29))\n",
            "  Downloading wordsegment-1.3.1-py2.py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting rotary_embedding_torch (from -r requirements.txt (line 30))\n",
            "  Downloading rotary_embedding_torch-0.8.6-py3-none-any.whl.metadata (675 bytes)\n",
            "Collecting ToJyutping (from -r requirements.txt (line 31))\n",
            "  Downloading ToJyutping-3.2.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting g2pk2 (from -r requirements.txt (line 32))\n",
            "  Downloading g2pk2-0.0.3-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting ko_pron (from -r requirements.txt (line 33))\n",
            "  Downloading ko_pron-1.3-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting opencc==1.1.1 (from -r requirements.txt (line 35))\n",
            "  Downloading OpenCC-1.1.1-py2.py3-none-manylinux1_x86_64.whl.metadata (10 kB)\n",
            "Collecting python_mecab_ko (from -r requirements.txt (line 36))\n",
            "  Downloading python_mecab_ko-1.3.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting fastapi>=0.115.2 (from fastapi[standard]>=0.115.2->-r requirements.txt (line 37))\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting x_transformers (from -r requirements.txt (line 38))\n",
            "  Downloading x_transformers-2.3.1-py3-none-any.whl.metadata (88 kB)\n",
            "Collecting torchmetrics<=1.5 (from -r requirements.txt (line 39))\n",
            "  Downloading torchmetrics-1.5.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting pydantic<=2.10.6 (from -r requirements.txt (line 40))\n",
            "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting ctranslate2<5,>=4.0 (from -r requirements.txt (line 41))\n",
            "  Downloading ctranslate2-4.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting huggingface_hub>=0.13 (from -r requirements.txt (line 42))\n",
            "  Downloading huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting tokenizers<1,>=0.13 (from -r requirements.txt (line 43))\n",
            "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting av>=11 (from -r requirements.txt (line 44))\n",
            "  Downloading av-14.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
            "Collecting audioread>=2.1.9 (from librosa==0.10.2->-r requirements.txt (line 4))\n",
            "  Downloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting scikit-learn>=0.20.0 (from librosa==0.10.2->-r requirements.txt (line 4))\n",
            "  Downloading scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting joblib>=0.14 (from librosa==0.10.2->-r requirements.txt (line 4))\n",
            "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/envs/GPTSoVITS/lib/python3.10/site-packages (from librosa==0.10.2->-r requirements.txt (line 4)) (5.2.1)\n",
            "Collecting soundfile>=0.12.1 (from librosa==0.10.2->-r requirements.txt (line 4))\n",
            "  Downloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (16 kB)\n",
            "Collecting pooch>=1.1 (from librosa==0.10.2->-r requirements.txt (line 4))\n",
            "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting soxr>=0.3.2 (from librosa==0.10.2->-r requirements.txt (line 4))\n",
            "  Downloading soxr-0.5.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/envs/GPTSoVITS/lib/python3.10/site-packages (from librosa==0.10.2->-r requirements.txt (line 4)) (4.13.2)\n",
            "Collecting lazy-loader>=0.1 (from librosa==0.10.2->-r requirements.txt (line 4))\n",
            "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting msgpack>=1.0 (from librosa==0.10.2->-r requirements.txt (line 4))\n",
            "  Downloading msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
            "Collecting jamo (from funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading jamo-0.4.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting kaldiio>=2.17.0 (from funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading kaldiio-2.18.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting torch-complex (from funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading torch_complex-0.4.4-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting pytorch-wpe (from funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading pytorch_wpe-0.0.1-py3-none-any.whl.metadata (242 bytes)\n",
            "Collecting editdistance>=0.5.2 (from funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading editdistance-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Collecting oss2 (from funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading oss2-2.19.1.tar.gz (298 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting umap-learn (from funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading umap_learn-0.5.7-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting jaconv (from funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading jaconv-0.4.0.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting hydra-core>=1.3.2 (from funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting tensorboardX (from funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting openai-whisper (from funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting addict (from modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting attrs (from modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting datasets>=2.14.5 (from modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting einops (from modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: filelock>=3.3.0 in /usr/local/envs/GPTSoVITS/lib/python3.10/site-packages (from modelscope==1.10.0->-r requirements.txt (line 18)) (3.13.1)\n",
            "Collecting gast>=0.2.2 (from modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting pandas (from modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "Collecting Pillow>=6.2.0 (from modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading pillow-11.2.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
            "Collecting pyarrow!=9.0.0,>=6.0.0 (from modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading pyarrow-20.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/envs/GPTSoVITS/lib/python3.10/site-packages (from modelscope==1.10.0->-r requirements.txt (line 18)) (2.9.0.post0)\n",
            "Collecting requests>=2.25 (from modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/envs/GPTSoVITS/lib/python3.10/site-packages (from modelscope==1.10.0->-r requirements.txt (line 18)) (75.8.0)\n",
            "Collecting simplejson>=3.3.0 (from modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading simplejson-3.20.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Collecting sortedcontainers>=1.5.9 (from modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3>=1.26 (from modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting yapf (from modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading yapf-0.43.0-py3-none-any.whl.metadata (46 kB)\n",
            "Collecting absl-py>=0.4 (from tensorboard->-r requirements.txt (line 3))\n",
            "  Downloading absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting grpcio>=1.48.2 (from tensorboard->-r requirements.txt (line 3))\n",
            "  Downloading grpcio-1.71.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting markdown>=2.6.8 (from tensorboard->-r requirements.txt (line 3))\n",
            "  Downloading markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/envs/GPTSoVITS/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 3)) (25.0)\n",
            "Collecting protobuf!=4.24.0,>=3.19.6 (from tensorboard->-r requirements.txt (line 3))\n",
            "  Downloading protobuf-6.30.2-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/envs/GPTSoVITS/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 3)) (1.17.0)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard->-r requirements.txt (line 3))\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard->-r requirements.txt (line 3))\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba->-r requirements.txt (line 5))\n",
            "  Downloading llvmlite-0.44.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/envs/GPTSoVITS/lib/python3.10/site-packages (from pytorch-lightning>=2.4->-r requirements.txt (line 6)) (2.5.1+cu124)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/envs/GPTSoVITS/lib/python3.10/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=2.4->-r requirements.txt (line 6)) (2024.6.1)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning>=2.4->-r requirements.txt (line 6))\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio<5->-r requirements.txt (line 7))\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting anyio<5.0,>=3.0 (from gradio<5->-r requirements.txt (line 7))\n",
            "  Downloading anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting ffmpy (from gradio<5->-r requirements.txt (line 7))\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.3.0 (from gradio<5->-r requirements.txt (line 7))\n",
            "  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting httpx>=0.24.1 (from gradio<5->-r requirements.txt (line 7))\n",
            "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting importlib-resources<7.0,>=1.3 (from gradio<5->-r requirements.txt (line 7))\n",
            "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/envs/GPTSoVITS/lib/python3.10/site-packages (from gradio<5->-r requirements.txt (line 7)) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/envs/GPTSoVITS/lib/python3.10/site-packages (from gradio<5->-r requirements.txt (line 7)) (2.1.5)\n",
            "Collecting matplotlib~=3.0 (from gradio<5->-r requirements.txt (line 7))\n",
            "  Downloading matplotlib-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting orjson~=3.0 (from gradio<5->-r requirements.txt (line 7))\n",
            "  Downloading orjson-3.10.16-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
            "Collecting Pillow>=6.2.0 (from modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting pydub (from gradio<5->-r requirements.txt (line 7))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio<5->-r requirements.txt (line 7))\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting ruff>=0.2.2 (from gradio<5->-r requirements.txt (line 7))\n",
            "  Downloading ruff-0.11.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio<5->-r requirements.txt (line 7))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio<5->-r requirements.txt (line 7))\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting typer<1.0,>=0.12 (from gradio<5->-r requirements.txt (line 7))\n",
            "  Downloading typer-0.15.2-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting uvicorn>=0.14.0 (from gradio<5->-r requirements.txt (line 7))\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.3.0->gradio<5->-r requirements.txt (line 7))\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting future (from ffmpeg-python->-r requirements.txt (line 8))\n",
            "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting coloredlogs (from onnxruntime-gpu->-r requirements.txt (line 10))\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting flatbuffers (from onnxruntime-gpu->-r requirements.txt (line 10))\n",
            "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Requirement already satisfied: sympy in /usr/local/envs/GPTSoVITS/lib/python3.10/site-packages (from onnxruntime-gpu->-r requirements.txt (line 10)) (1.13.1)\n",
            "Collecting proces>=0.1.7 (from cn2an->-r requirements.txt (line 13))\n",
            "  Downloading proces-0.1.7-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting nltk>=3.2.4 (from g2p_en->-r requirements.txt (line 16))\n",
            "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting inflect>=0.3.1 (from g2p_en->-r requirements.txt (line 16))\n",
            "  Downloading inflect-7.5.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting distance>=0.1.3 (from g2p_en->-r requirements.txt (line 16))\n",
            "  Downloading Distance-0.1.3.tar.gz (180 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: networkx in /usr/local/envs/GPTSoVITS/lib/python3.10/site-packages (from torch>=2.1.0->pytorch-lightning>=2.4->-r requirements.txt (line 6)) (3.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/envs/GPTSoVITS/lib/python3.10/site-packages (from torch>=2.1.0->pytorch-lightning>=2.4->-r requirements.txt (line 6)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/envs/GPTSoVITS/lib/python3.10/site-packages (from torch>=2.1.0->pytorch-lightning>=2.4->-r requirements.txt (line 6)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/envs/GPTSoVITS/lib/python3.10/site-packages (from torch>=2.1.0->pytorch-lightning>=2.4->-r requirements.txt (line 6)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/envs/GPTSoVITS/lib/python3.10/site-packages (from torch>=2.1.0->pytorch-lightning>=2.4->-r requirements.txt (line 6)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/envs/GPTSoVITS/lib/python3.10/site-packages (from torch>=2.1.0->pytorch-lightning>=2.4->-r requirements.txt (line 6)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/envs/GPTSoVITS/lib/python3.10/site-packages (from torch>=2.1.0->pytorch-lightning>=2.4->-r requirements.txt (line 6)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/envs/GPTSoVITS/lib/python3.10/site-packages (from torch>=2.1.0->pytorch-lightning>=2.4->-r requirements.txt (line 6)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/envs/GPTSoVITS/lib/python3.10/site-packages (from torch>=2.1.0->pytorch-lightning>=2.4->-r requirements.txt (line 6)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/envs/GPTSoVITS/lib/python3.10/site-packages (from torch>=2.1.0->pytorch-lightning>=2.4->-r requirements.txt (line 6)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/envs/GPTSoVITS/lib/python3.10/site-packages (from torch>=2.1.0->pytorch-lightning>=2.4->-r requirements.txt (line 6)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/envs/GPTSoVITS/lib/python3.10/site-packages (from torch>=2.1.0->pytorch-lightning>=2.4->-r requirements.txt (line 6)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/envs/GPTSoVITS/lib/python3.10/site-packages (from torch>=2.1.0->pytorch-lightning>=2.4->-r requirements.txt (line 6)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/envs/GPTSoVITS/lib/python3.10/site-packages (from torch>=2.1.0->pytorch-lightning>=2.4->-r requirements.txt (line 6)) (3.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/envs/GPTSoVITS/lib/python3.10/site-packages (from sympy->onnxruntime-gpu->-r requirements.txt (line 10)) (1.3.0)\n",
            "Collecting regex!=2019.12.17 (from transformers>=4.43->-r requirements.txt (line 20))\n",
            "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "Collecting safetensors>=0.4.3 (from transformers>=4.43->-r requirements.txt (line 20))\n",
            "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting accelerate>=0.21.0 (from peft->-r requirements.txt (line 21))\n",
            "  Downloading accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting budoux (from split-lang->-r requirements.txt (line 27))\n",
            "  Downloading budoux-0.7.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting robust-downloader>=0.0.2 (from fast_langdetect>=0.3.1->-r requirements.txt (line 28))\n",
            "  Downloading robust_downloader-0.0.2-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting fasttext-predict>=0.9.2.4 (from fast_langdetect>=0.3.1->-r requirements.txt (line 28))\n",
            "  Downloading fasttext_predict-0.9.2.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting python-mecab-ko-dic (from python_mecab_ko->-r requirements.txt (line 36))\n",
            "  Downloading python_mecab_ko_dic-2.1.1.post2-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting starlette<0.47.0,>=0.40.0 (from fastapi>=0.115.2->fastapi[standard]>=0.115.2->-r requirements.txt (line 37))\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting einx>=0.3.0 (from x_transformers->-r requirements.txt (line 38))\n",
            "  Downloading einx-0.3.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting loguru (from x_transformers->-r requirements.txt (line 38))\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic<=2.10.6->-r requirements.txt (line 40))\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.27.2 (from pydantic<=2.10.6->-r requirements.txt (line 40))\n",
            "  Downloading pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting fastapi-cli>=0.0.5 (from fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.2->-r requirements.txt (line 37))\n",
            "  Downloading fastapi_cli-0.0.7-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting jinja2<4.0 (from gradio<5->-r requirements.txt (line 7))\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting email-validator>=2.0.0 (from fastapi[standard]>=0.115.2->-r requirements.txt (line 37))\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/envs/GPTSoVITS/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio<5->-r requirements.txt (line 7)) (1.2.2)\n",
            "Collecting idna>=2.8 (from anyio<5.0,>=3.0->gradio<5->-r requirements.txt (line 7))\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting sniffio>=1.1 (from anyio<5.0,>=3.0->gradio<5->-r requirements.txt (line 7))\n",
            "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting xxhash (from datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting aiohttp (from datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading aiohttp-3.11.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting frozendict (from einx>=0.3.0->x_transformers->-r requirements.txt (line 38))\n",
            "  Downloading frozendict-2.4.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (23 kB)\n",
            "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->fastapi[standard]>=0.115.2->-r requirements.txt (line 37))\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting rich-toolkit>=0.11.1 (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]>=0.115.2->-r requirements.txt (line 37))\n",
            "  Downloading rich_toolkit-0.14.3-py3-none-any.whl.metadata (999 bytes)\n",
            "Collecting certifi (from httpx>=0.24.1->gradio<5->-r requirements.txt (line 7))\n",
            "  Downloading certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio<5->-r requirements.txt (line 7))\n",
            "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.24.1->gradio<5->-r requirements.txt (line 7))\n",
            "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting omegaconf<2.4,>=2.2 (from hydra-core>=1.3.2->funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.3.2->funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting more_itertools>=8.5.0 (from inflect>=0.3.1->g2p_en->-r requirements.txt (line 16))\n",
            "  Downloading more_itertools-10.7.0-py3-none-any.whl.metadata (37 kB)\n",
            "Collecting typeguard>=4.0.1 (from inflect>=0.3.1->g2p_en->-r requirements.txt (line 16))\n",
            "  Downloading typeguard-4.4.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib~=3.0->gradio<5->-r requirements.txt (line 7))\n",
            "  Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib~=3.0->gradio<5->-r requirements.txt (line 7))\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib~=3.0->gradio<5->-r requirements.txt (line 7))\n",
            "  Downloading fonttools-4.57.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (102 kB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib~=3.0->gradio<5->-r requirements.txt (line 7))\n",
            "  Downloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.2 kB)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib~=3.0->gradio<5->-r requirements.txt (line 7))\n",
            "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting click (from nltk>=3.2.4->g2p_en->-r requirements.txt (line 16))\n",
            "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting pytz>=2020.1 (from pandas->modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas->modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/envs/GPTSoVITS/lib/python3.10/site-packages (from pooch>=1.1->librosa==0.10.2->-r requirements.txt (line 4)) (4.3.7)\n",
            "Collecting charset-normalizer<4,>=2 (from requests>=2.25->modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading charset_normalizer-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Collecting colorlog (from robust-downloader>=0.0.2->fast_langdetect>=0.3.1->-r requirements.txt (line 28))\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=0.20.0->librosa==0.10.2->-r requirements.txt (line 4))\n",
            "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting cffi>=1.0 (from soundfile>=0.12.1->librosa==0.10.2->-r requirements.txt (line 4))\n",
            "  Downloading cffi-1.17.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio<5->-r requirements.txt (line 7))\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rich>=10.11.0 (from typer<1.0,>=0.12->gradio<5->-r requirements.txt (line 7))\n",
            "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.2->-r requirements.txt (line 37))\n",
            "  Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.2->-r requirements.txt (line 37))\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.2->-r requirements.txt (line 37))\n",
            "  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.2->-r requirements.txt (line 37))\n",
            "  Downloading watchfiles-1.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu->-r requirements.txt (line 10))\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting tiktoken (from openai-whisper->funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting crcmod>=1.7 (from oss2->funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pycryptodome>=3.4.7 (from oss2->funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading pycryptodome-3.22.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting aliyun-python-sdk-kms>=2.4.1 (from oss2->funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading aliyun_python_sdk_kms-2.16.5-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting aliyun-python-sdk-core>=2.13.12 (from oss2->funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading aliyun-python-sdk-core-2.16.0.tar.gz (449 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pynndescent>=0.5 (from umap-learn->funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting tomli>=2.0.1 (from yapf->modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Using cached tomli-2.2.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting async-timeout<6.0,>=4.0 (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading frozenlist-1.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading multidict-6.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading propcache-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading yarl-1.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (72 kB)\n",
            "Collecting jmespath<1.0.0,>=0.9.3 (from aliyun-python-sdk-core>=2.13.12->oss2->funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting cryptography>=3.0.0 (from aliyun-python-sdk-core>=2.13.12->oss2->funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading cryptography-44.0.2-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\n",
            "Collecting pycparser (from cffi>=1.0->soundfile>=0.12.1->librosa==0.10.2->-r requirements.txt (line 4))\n",
            "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0,>=0.12->gradio<5->-r requirements.txt (line 7))\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/envs/GPTSoVITS/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio<5->-r requirements.txt (line 7)) (2.19.1)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio<5->-r requirements.txt (line 7))\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Downloading librosa-0.10.2-py3-none-any.whl (260 kB)\n",
            "Downloading funasr-1.0.27-py3-none-any.whl (693 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m693.7/693.7 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading modelscope-1.10.0-py3-none-any.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m115.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading OpenCC-1.1.1-py2.py3-none-manylinux1_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m161.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.6/37.6 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m131.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numba-0.61.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m131.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.5.1.post0-py3-none-any.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.1/823.1 kB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-4.44.1-py3-none-any.whl (18.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m139.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n",
            "Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Downloading onnxruntime_gpu-1.21.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (280.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.8/280.8 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Downloading cn2an-0.5.23-py3-none-any.whl (224 kB)\n",
            "Downloading pypinyin-0.54.0-py2.py3-none-any.whl (837 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m837.0/837.0 kB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading g2p_en-2.1.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m115.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m152.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.15.2-py3-none-any.whl (411 kB)\n",
            "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
            "Downloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m751.2/751.2 kB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading split_lang-2.1.0-py3-none-any.whl (32 kB)\n",
            "Downloading fast_langdetect-0.3.2-py3-none-any.whl (788 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m788.1/788.1 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wordsegment-1.3.1-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m134.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rotary_embedding_torch-0.8.6-py3-none-any.whl (5.6 kB)\n",
            "Downloading ToJyutping-3.2.0-py3-none-any.whl (287 kB)\n",
            "Downloading g2pk2-0.0.3-py3-none-any.whl (25 kB)\n",
            "Downloading ko_pron-1.3-py3-none-any.whl (12 kB)\n",
            "Downloading python_mecab_ko-1.3.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (577 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m577.1/577.1 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "Downloading x_transformers-2.3.1-py3-none-any.whl (83 kB)\n",
            "Downloading torchmetrics-1.5.0-py3-none-any.whl (890 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m890.5/890.5 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
            "Downloading pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ctranslate2-4.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
            "Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m112.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading av-14.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.7/34.7 MB\u001b[0m \u001b[31m130.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
            "Downloading accelerate-1.6.0-py3-none-any.whl (354 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
            "Downloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
            "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "Downloading editdistance-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (401 kB)\n",
            "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
            "Downloading einx-0.3.0-py3-none-any.whl (102 kB)\n",
            "Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Downloading fastapi_cli-0.0.7-py3-none-any.whl (10 kB)\n",
            "Downloading fasttext_predict-0.9.2.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (294 kB)\n",
            "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
            "Downloading grpcio-1.71.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m139.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
            "Downloading inflect-7.5.0-py3-none-any.whl (35 kB)\n",
            "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "Downloading kaldiio-2.18.1-py3-none-any.whl (29 kB)\n",
            "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
            "Downloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading llvmlite-0.44.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markdown-3.8-py3-none-any.whl (106 kB)\n",
            "Downloading matplotlib-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m149.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (378 kB)\n",
            "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.16-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (132 kB)\n",
            "Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m161.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m117.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
            "Downloading proces-0.1.7-py3-none-any.whl (137 kB)\n",
            "Downloading protobuf-6.30.2-cp39-abi3-manylinux2014_x86_64.whl (316 kB)\n",
            "Downloading pyarrow-20.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (42.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "Downloading robust_downloader-0.0.2-py3-none-any.whl (15 kB)\n",
            "Downloading ruff-0.11.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m137.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
            "Downloading scikit_learn-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m131.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading simplejson-3.20.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Downloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading soxr-0.5.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (252 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m131.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typer-0.15.2-py3-none-any.whl (45 kB)\n",
            "Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
            "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "Downloading budoux-0.7.0-py3-none-any.whl (118 kB)\n",
            "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "Downloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Downloading future-1.0.0-py3-none-any.whl (491 kB)\n",
            "Downloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n",
            "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading python_mecab_ko_dic-2.1.1.post2-py3-none-any.whl (34.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_wpe-0.0.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "Downloading torch_complex-0.4.4-py3-none-any.whl (9.1 kB)\n",
            "Downloading umap_learn-0.5.7-py3-none-any.whl (88 kB)\n",
            "Downloading yapf-0.43.0-py3-none-any.whl (256 kB)\n",
            "Downloading aiohttp-3.11.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aliyun_python_sdk_kms-2.16.5-py2.py3-none-any.whl (99 kB)\n",
            "Downloading certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
            "Downloading cffi-1.17.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (446 kB)\n",
            "Downloading charset_normalizer-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (146 kB)\n",
            "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
            "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "Downloading fonttools-4.57.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m129.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
            "Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "Downloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading more_itertools-10.7.0-py3-none-any.whl (65 kB)\n",
            "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "Downloading pycryptodome-3.22.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m98.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
            "Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
            "Downloading rich_toolkit-0.14.3-py3-none-any.whl (24 kB)\n",
            "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Using cached tomli-2.2.1-py3-none-any.whl (14 kB)\n",
            "Downloading typeguard-4.4.2-py3-none-any.whl (35 kB)\n",
            "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m116.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (454 kB)\n",
            "Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading frozendict-2.4.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (117 kB)\n",
            "Downloading tiktoken-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
            "Downloading cryptography-44.0.2-cp39-abi3-manylinux_2_34_x86_64.whl (4.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m120.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading frozenlist-1.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
            "Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "Downloading multidict-6.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (219 kB)\n",
            "Downloading propcache-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (206 kB)\n",
            "Downloading yarl-1.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (333 kB)\n",
            "Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
            "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Building wheels for collected packages: pyopenjtalk, jieba_fast, jieba, distance, antlr4-python3-runtime, jaconv, openai-whisper, oss2, aliyun-python-sdk-core, crcmod\n",
            "  Building wheel for pyopenjtalk (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyopenjtalk: filename=pyopenjtalk-0.4.1-cp310-cp310-linux_x86_64.whl size=1289774 sha256=41070818d21bc0c2af541de2873348ffec07cfd0333f214491e1f24439ba8420\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/00/40/90257df3877dffde7407dced8e2ab05b8a9053c2e659070cb7\n",
            "  Building wheel for jieba_fast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jieba_fast: filename=jieba_fast-0.53-cp310-cp310-linux_x86_64.whl size=7628836 sha256=0c8b464615c4882064431bbb055ebc8d625478835dfd68669d46e7a260ac804e\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/bc/2e/ec85cb24f946d722725b17fc7aa1afca0c2dcfd727d540a06a\n",
            "  Building wheel for jieba (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314508 sha256=9c5230c3c6165ae2b39894557eb046be279abe8592e092f39209f15d7d9ada02\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/69/31/d56d90b22a1777b0b231e234b00302a55be255930f8bd92dcd\n",
            "  Building wheel for distance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for distance: filename=Distance-0.1.3-py3-none-any.whl size=16293 sha256=01795bd0449efaf506e42446e2aa3e3cb6554ea4fde99d16fbddc4aaa1039306\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/bb/de/f71bf63559ea9a921059a5405806f7ff6ed612a9231c4a9309\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144591 sha256=20d534746809e3cb0999b9378a9d6d8b54aace8f4773fcbc47c931ea69adc9ab\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for jaconv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jaconv: filename=jaconv-0.4.0-py3-none-any.whl size=18278 sha256=fd3fd6cebe66fd9fe1bae8a9bd8c8bd63b0e7a007511676596b8cc3a0ebb3730\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/95/99/94e8d7545125181756857f6b1fc085ed4e0811ad9be7321af7\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803405 sha256=b61907c6d948336349819a3a0f0c24cd0d7482fcb03f0adad11a32c14a02ae61\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/4a/1f/d1c4bf3b9133c8168fe617ed979cab7b14fe381d059ffb9d83\n",
            "  Building wheel for oss2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for oss2: filename=oss2-2.19.1-py3-none-any.whl size=124002 sha256=6e937aa1cdad4ed4de14191fe41b8186a8d0ec21a6333130beee2435738bf7fe\n",
            "  Stored in directory: /root/.cache/pip/wheels/7d/1b/c6/dbf318597d350b50a94408a23a56b7349e706d61e0a06a6407\n",
            "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for aliyun-python-sdk-core: filename=aliyun_python_sdk_core-2.16.0-py3-none-any.whl size=535380 sha256=f201ecd2452be552c69a54ea0fff6c71bbc96a761317d0028478c40273c2095e\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/11/5e/08e7cb4e03a3e83b4862edd12d1143c8d3936a3dd57a3ee46d\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=23242 sha256=974c451817721d05b4a998d3242f0606c7b49c3757b7cd6e9b454d12ded4b9b1\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "Successfully built pyopenjtalk jieba_fast jieba distance antlr4-python3-runtime jaconv openai-whisper oss2 aliyun-python-sdk-core crcmod\n",
            "Installing collected packages: wordsegment, sortedcontainers, sentencepiece, pytz, python-mecab-ko-dic, pydub, opencc, ko_pron, jieba_fast, jieba, jamo, jaconv, flatbuffers, fasttext-predict, distance, crcmod, antlr4-python3-runtime, addict, xxhash, werkzeug, websockets, uvloop, urllib3, tzdata, typeguard, tqdm, tomlkit, tomli, ToJyutping, threadpoolctl, tensorboard-data-server, sniffio, simplejson, shellingham, semantic-version, safetensors, ruff, regex, PyYAML, python-multipart, python_mecab_ko, python-dotenv, pypinyin, pyparsing, pydantic-core, pycryptodome, pycparser, pyarrow, protobuf, propcache, proces, Pillow, orjson, numpy, multidict, msgpack, more_itertools, mdurl, markdown, loguru, llvmlite, lightning-utilities, lazy-loader, kiwisolver, joblib, jmespath, jinja2, importlib-resources, idna, humanfriendly, httptools, h11, grpcio, gast, future, frozenlist, frozendict, fonttools, ffmpy, einops, editdistance, dnspython, dill, cycler, colorlog, click, charset-normalizer, chardet, certifi, av, audioread, attrs, async-timeout, annotated-types, aiohappyeyeballs, aiofiles, absl-py, yarl, yapf, uvicorn, torch-complex, tensorboardX, tensorboard, soxr, scipy, requests, pytorch-wpe, pyopenjtalk, pydantic, pandas, omegaconf, numba, nltk, multiprocess, markdown-it-py, kaldiio, inflect, httpcore, ffmpeg-python, email-validator, einx, ctranslate2, contourpy, coloredlogs, cn2an, cffi, budoux, anyio, aiosignal, watchfiles, tiktoken, starlette, soundfile, scikit-learn, robust-downloader, rich, pooch, onnxruntime-gpu, matplotlib, hydra-core, huggingface_hub, httpx, g2pk2, g2p_en, cryptography, aiohttp, x_transformers, typer, torchmetrics, tokenizers, rotary_embedding_torch, rich-toolkit, pynndescent, openai-whisper, librosa, gradio-client, fastapi, fast_langdetect, aliyun-python-sdk-core, accelerate, umap-learn, transformers, split-lang, pytorch-lightning, gradio, fastapi-cli, datasets, aliyun-python-sdk-kms, peft, oss2, modelscope, funasr\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.4\n",
            "    Uninstalling Jinja2-3.1.4:\n",
            "      Successfully uninstalled Jinja2-3.1.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "faster-whisper 1.1.1 requires onnxruntime<2,>=1.14, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-10.4.0 PyYAML-6.0.2 ToJyutping-3.2.0 absl-py-2.2.2 accelerate-1.6.0 addict-2.4.0 aiofiles-23.2.1 aiohappyeyeballs-2.6.1 aiohttp-3.11.18 aiosignal-1.3.2 aliyun-python-sdk-core-2.16.0 aliyun-python-sdk-kms-2.16.5 annotated-types-0.7.0 antlr4-python3-runtime-4.9.3 anyio-4.9.0 async-timeout-5.0.1 attrs-25.3.0 audioread-3.0.1 av-14.3.0 budoux-0.7.0 certifi-2025.4.26 cffi-1.17.1 chardet-5.2.0 charset-normalizer-3.4.1 click-8.1.8 cn2an-0.5.23 coloredlogs-15.0.1 colorlog-6.9.0 contourpy-1.3.2 crcmod-1.7 cryptography-44.0.2 ctranslate2-4.6.0 cycler-0.12.1 datasets-3.5.0 dill-0.3.8 distance-0.1.3 dnspython-2.7.0 editdistance-0.8.1 einops-0.8.1 einx-0.3.0 email-validator-2.2.0 fast_langdetect-0.3.2 fastapi-0.115.12 fastapi-cli-0.0.7 fasttext-predict-0.9.2.4 ffmpeg-python-0.2.0 ffmpy-0.5.0 flatbuffers-25.2.10 fonttools-4.57.0 frozendict-2.4.6 frozenlist-1.6.0 funasr-1.0.27 future-1.0.0 g2p_en-2.1.0 g2pk2-0.0.3 gast-0.6.0 gradio-4.44.1 gradio-client-1.3.0 grpcio-1.71.0 h11-0.16.0 httpcore-1.0.9 httptools-0.6.4 httpx-0.28.1 huggingface_hub-0.30.2 humanfriendly-10.0 hydra-core-1.3.2 idna-3.10 importlib-resources-6.5.2 inflect-7.5.0 jaconv-0.4.0 jamo-0.4.1 jieba-0.42.1 jieba_fast-0.53 jinja2-3.1.6 jmespath-0.10.0 joblib-1.4.2 kaldiio-2.18.1 kiwisolver-1.4.8 ko_pron-1.3 lazy-loader-0.4 librosa-0.10.2 lightning-utilities-0.14.3 llvmlite-0.44.0 loguru-0.7.3 markdown-3.8 markdown-it-py-3.0.0 matplotlib-3.10.1 mdurl-0.1.2 modelscope-1.10.0 more_itertools-10.7.0 msgpack-1.1.0 multidict-6.4.3 multiprocess-0.70.16 nltk-3.9.1 numba-0.61.2 numpy-1.26.4 omegaconf-2.3.0 onnxruntime-gpu-1.21.1 openai-whisper-20240930 opencc-1.1.1 orjson-3.10.16 oss2-2.19.1 pandas-2.2.3 peft-0.15.2 pooch-1.8.2 proces-0.1.7 propcache-0.3.1 protobuf-6.30.2 pyarrow-20.0.0 pycparser-2.22 pycryptodome-3.22.0 pydantic-2.10.6 pydantic-core-2.27.2 pydub-0.25.1 pynndescent-0.5.13 pyopenjtalk-0.4.1 pyparsing-3.2.3 pypinyin-0.54.0 python-dotenv-1.1.0 python-mecab-ko-dic-2.1.1.post2 python-multipart-0.0.20 python_mecab_ko-1.3.7 pytorch-lightning-2.5.1.post0 pytorch-wpe-0.0.1 pytz-2025.2 regex-2024.11.6 requests-2.32.3 rich-14.0.0 rich-toolkit-0.14.3 robust-downloader-0.0.2 rotary_embedding_torch-0.8.6 ruff-0.11.7 safetensors-0.5.3 scikit-learn-1.6.1 scipy-1.15.2 semantic-version-2.10.0 sentencepiece-0.2.0 shellingham-1.5.4 simplejson-3.20.1 sniffio-1.3.1 sortedcontainers-2.4.0 soundfile-0.13.1 soxr-0.5.0.post1 split-lang-2.1.0 starlette-0.46.2 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorboardX-2.6.2.2 threadpoolctl-3.6.0 tiktoken-0.9.0 tokenizers-0.21.1 tomli-2.2.1 tomlkit-0.12.0 torch-complex-0.4.4 torchmetrics-1.5.0 tqdm-4.67.1 transformers-4.51.3 typeguard-4.4.2 typer-0.15.2 tzdata-2025.2 umap-learn-0.5.7 urllib3-2.4.0 uvicorn-0.34.2 uvloop-0.21.0 watchfiles-1.0.5 websockets-12.0 werkzeug-3.1.3 wordsegment-1.3.1 x_transformers-2.3.1 xxhash-3.5.0 yapf-0.43.0 yarl-1.20.0\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/cmudict.zip.\n",
            "Installation completed successfully!\n"
          ]
        }
      ],
      "source": [
        "%pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install_from_url(\"https://repo.anaconda.com/archive/Anaconda3-2024.10-1-Linux-x86_64.sh\")\n",
        "!cd /content && bash setup.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWj8zDG5kQOS"
      },
      "source": [
        "## Launch WebUI\n",
        "## 启动 WebUI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4oRGUzkrk8C7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34e3295d-f19e-460a-b9b7-fc5f23c1bbfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: /usr/local/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
            "Running on local URL:  http://0.0.0.0:9874\n",
            "Running on public URL: https://ecc269405413477232.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/uvr5/webui.py \"cuda\" True 9873 True\n",
            "Running on local URL:  http://0.0.0.0:9873\n",
            "Running on public URL: https://930249277b7efc625b.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "Vocal Separation WebUI Process Terminated\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/uvr5/webui.py \"cuda\" True 9873 True\n",
            "Running on local URL:  http://0.0.0.0:9873\n",
            "Running on public URL: https://55ab6ff6edeea07e3f.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "clean_empty_cache\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS/tools/uvr5/webui.py\", line 91, in uvr\n",
            "    if info[\"streams\"][0][\"channels\"] == 2 and info[\"streams\"][0][\"sample_rate\"] == \"44100\":\n",
            "KeyError: 'channels'\n",
            "ffmpeg version 6.1.1 Copyright (c) 2000-2023 the FFmpeg developers\n",
            "  built with gcc 11.2.0 (Anaconda gcc)\n",
            "  configuration: --prefix=/usr/local/envs/GPTSoVITS --cc=/croot/ffmpeg_1743153284778/_build_env/bin/x86_64-conda-linux-gnu-cc --ar=/croot/ffmpeg_1743153284778/_build_env/bin/x86_64-conda-linux-gnu-ar --nm=/croot/ffmpeg_1743153284778/_build_env/bin/x86_64-conda-linux-gnu-nm --ranlib=/croot/ffmpeg_1743153284778/_build_env/bin/x86_64-conda-linux-gnu-ranlib --strip=/croot/ffmpeg_1743153284778/_build_env/bin/x86_64-conda-linux-gnu-strip --disable-doc --enable-swresample --enable-swscale --enable-openssl --enable-libxml2 --enable-libtheora --enable-demuxer=dash --enable-postproc --enable-hardcoded-tables --enable-libfreetype --enable-libharfbuzz --enable-libfontconfig --enable-libdav1d --enable-zlib --enable-libaom --enable-pic --enable-shared --disable-static --disable-gpl --enable-version3 --disable-sdl2 --enable-libopenh264 --enable-libopus --enable-libmp3lame --enable-libopenjpeg --enable-libvorbis --enable-pthreads --enable-libtesseract --enable-libvpx\n",
            "  libavutil      58. 29.100 / 58. 29.100\n",
            "  libavcodec     60. 31.102 / 60. 31.102\n",
            "  libavformat    60. 16.100 / 60. 16.100\n",
            "  libavdevice    60.  3.100 / 60.  3.100\n",
            "  libavfilter     9. 12.100 /  9. 12.100\n",
            "  libswscale      7.  5.100 /  7.  5.100\n",
            "  libswresample   4. 12.100 /  4. 12.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/content/GPT-SoVITS/input/1-1.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2avc1mp41\n",
            "    encoder         : Lavf58.29.100\n",
            "    description     : Packed by Bilibili XCoder v2.0.2\n",
            "  Duration: 00:01:50.92, start: 0.000000, bitrate: 1959 kb/s\n",
            "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 1280x720 [SAR 1:1 DAR 16:9], 1742 kb/s, 30 fps, 30 tbr, 16k tbn (default)\n",
            "    Metadata:\n",
            "      handler_name    : VideoHandler\n",
            "      vendor_id       : [0][0][0][0]\n",
            "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, stereo, fltp, 209 kb/s (default)\n",
            "    Metadata:\n",
            "      handler_name    : SoundHandler\n",
            "      vendor_id       : [0][0][0][0]\n",
            "Stream mapping:\n",
            "  Stream #0:1 -> #0:0 (aac (native) -> pcm_s16le (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, wav, to '/content/GPT-SoVITS/TEMP/1-1.mp4.reformatted.wav':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2avc1mp41\n",
            "    description     : Packed by Bilibili XCoder v2.0.2\n",
            "    ISFT            : Lavf60.16.100\n",
            "  Stream #0:0(und): Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s (default)\n",
            "    Metadata:\n",
            "      handler_name    : SoundHandler\n",
            "      vendor_id       : [0][0][0][0]\n",
            "      encoder         : Lavc60.31.102 pcm_s16le\n",
            "\u001b[1;35m[out#0/wav @ 0x1f1526c0] \u001b[0mvideo:0kB audio:19108kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.000399%\n",
            "size=   19108kB time=00:01:50.89 bitrate=1411.5kbits/s speed= 362x    \n",
            "100% 40/40 [00:03<00:00, 10.20it/s]\n",
            "clean_empty_cache\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/slice_audio.py \"/content/GPT-SoVITS/output/uvr5_opt\" \"output/slicer_opt\" -34 4000 300 10 500 0.9 0.25 0 4\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/slice_audio.py \"/content/GPT-SoVITS/output/uvr5_opt\" \"output/slicer_opt\" -34 4000 300 10 500 0.9 0.25 1 4\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/slice_audio.py \"/content/GPT-SoVITS/output/uvr5_opt\" \"output/slicer_opt\" -34 4000 300 10 500 0.9 0.25 2 4\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/slice_audio.py \"/content/GPT-SoVITS/output/uvr5_opt\" \"output/slicer_opt\" -34 4000 300 10 500 0.9 0.25 3 4\n",
            "Speech Slicing Process Terminated\n",
            "Speech Slicing Process Terminated\n",
            "Speech Slicing Process Terminated\n",
            "Speech Slicing Process Terminated\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/slice_audio.py \"/content/GPT-SoVITS/output/uvr5_opt\" \"output/slicer_opt\" -34 4000 300 10 500 0.9 0.25 0 4\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/slice_audio.py \"/content/GPT-SoVITS/output/uvr5_opt\" \"output/slicer_opt\" -34 4000 300 10 500 0.9 0.25 1 4\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/slice_audio.py \"/content/GPT-SoVITS/output/uvr5_opt\" \"output/slicer_opt\" -34 4000 300 10 500 0.9 0.25 2 4\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/slice_audio.py \"/content/GPT-SoVITS/output/uvr5_opt\" \"output/slicer_opt\" -34 4000 300 10 500 0.9 0.25 3 4\n",
            "执行完毕，请检查输出文件\n",
            "执行完毕，请检查输出文件\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS/tools/my_utils.py\", line 21, in load_audio\n",
            "    ffmpeg.input(file, threads=0)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/ffmpeg/_run.py\", line 325, in run\n",
            "    raise Error('ffmpeg', out, err)\n",
            "ffmpeg._run.Error: ffmpeg error (see stderr output for detail)\n",
            "/content/GPT-SoVITS/output/uvr5_opt/.ipynb_checkpoints ->fail-> Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS/tools/my_utils.py\", line 21, in load_audio\n",
            "    ffmpeg.input(file, threads=0)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/ffmpeg/_run.py\", line 325, in run\n",
            "    raise Error('ffmpeg', out, err)\n",
            "ffmpeg._run.Error: ffmpeg error (see stderr output for detail)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS/tools/slice_audio.py\", line 35, in slice\n",
            "    audio = load_audio(inp_path, 32000)\n",
            "  File \"/content/GPT-SoVITS/tools/my_utils.py\", line 27, in load_audio\n",
            "    raise RuntimeError(i18n(\"音频加载失败\"))\n",
            "RuntimeError: Failed to Load Audio\n",
            "\n",
            "执行完毕，请检查输出文件\n",
            "执行完毕，请检查输出文件\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/slice_audio.py \"/content/GPT-SoVITS/output/uvr5_opt\" \"output/slicer_opt\" -34 4000 300 10 500 0.9 0.25 0 4\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/slice_audio.py \"/content/GPT-SoVITS/output/uvr5_opt\" \"output/slicer_opt\" -34 4000 300 10 500 0.9 0.25 1 4\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/slice_audio.py \"/content/GPT-SoVITS/output/uvr5_opt\" \"output/slicer_opt\" -34 4000 300 10 500 0.9 0.25 2 4\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/slice_audio.py \"/content/GPT-SoVITS/output/uvr5_opt\" \"output/slicer_opt\" -34 4000 300 10 500 0.9 0.25 3 4\n",
            "执行完毕，请检查输出文件\n",
            "执行完毕，请检查输出文件\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS/tools/my_utils.py\", line 21, in load_audio\n",
            "    ffmpeg.input(file, threads=0)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/ffmpeg/_run.py\", line 325, in run\n",
            "    raise Error('ffmpeg', out, err)\n",
            "ffmpeg._run.Error: ffmpeg error (see stderr output for detail)\n",
            "/content/GPT-SoVITS/output/uvr5_opt/.ipynb_checkpoints ->fail-> Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS/tools/my_utils.py\", line 21, in load_audio\n",
            "    ffmpeg.input(file, threads=0)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/ffmpeg/_run.py\", line 325, in run\n",
            "    raise Error('ffmpeg', out, err)\n",
            "ffmpeg._run.Error: ffmpeg error (see stderr output for detail)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS/tools/slice_audio.py\", line 35, in slice\n",
            "    audio = load_audio(inp_path, 32000)\n",
            "  File \"/content/GPT-SoVITS/tools/my_utils.py\", line 27, in load_audio\n",
            "    raise RuntimeError(i18n(\"音频加载失败\"))\n",
            "RuntimeError: Failed to Load Audio\n",
            "\n",
            "执行完毕，请检查输出文件\n",
            "执行完毕，请检查输出文件\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/subfix_webui.py --load_list \"D:/RVC1006/GPT-SoVITS/raw/xxx.list\" --webui_port 9871 --is_share True\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS/tools/subfix_webui.py\", line 304, in <module>\n",
            "    set_global(args.load_json, args.load_list, args.json_key_text, args.json_key_path, args.g_batch)\n",
            "  File \"/content/GPT-SoVITS/tools/subfix_webui.py\", line 289, in set_global\n",
            "    b_load_file()\n",
            "  File \"/content/GPT-SoVITS/tools/subfix_webui.py\", line 268, in b_load_file\n",
            "    b_load_list()\n",
            "  File \"/content/GPT-SoVITS/tools/subfix_webui.py\", line 243, in b_load_list\n",
            "    with open(g_load_file, \"r\", encoding=\"utf-8\") as source:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'D:/RVC1006/GPT-SoVITS/raw/xxx.list'\n",
            "Audio Labeling WebUI Process Terminated\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/asr/funasr_asr.py -i \"output/slicer_opt\" -o \"output/asr_opt\" -s large -l zh -p float32\n",
            "2025-04-28 13:53:49,998 - modelscope - INFO - PyTorch version 2.5.1+cu124 Found.\n",
            "2025-04-28 13:53:49,999 - modelscope - INFO - Loading ast index from /root/.cache/modelscope/ast_indexer\n",
            "2025-04-28 13:53:49,999 - modelscope - INFO - No valid ast index found from /root/.cache/modelscope/ast_indexer, generating ast index from prebuilt!\n",
            "2025-04-28 13:53:50,058 - modelscope - INFO - Loading done! Current index file version is 1.10.0, with md5 9710ac4fb2f8068bd74ea2bbac1a05b0 and a total number of 946 components indexed\n",
            "2025-04-28 13:53:51,968 - modelscope - INFO - Use user-specified model revision: v2.0.4\n",
            "Downloading: 100% 10.9k/10.9k [00:00<00:00, 39.0MB/s]\n",
            "Downloading: 100% 173k/173k [00:00<00:00, 581kB/s]\n",
            "Downloading: 100% 2.45k/2.45k [00:00<00:00, 14.8MB/s]\n",
            "Downloading: 100% 472/472 [00:00<00:00, 2.56MB/s]\n",
            "Downloading: 100% 840M/840M [00:21<00:00, 41.2MB/s]\n",
            "Downloading: 100% 19.1k/19.1k [00:00<00:00, 260kB/s]\n",
            "Downloading: 100% 7.90M/7.90M [00:01<00:00, 8.13MB/s]\n",
            "Downloading: 100% 48.7k/48.7k [00:00<00:00, 336kB/s]\n",
            "Downloading: 100% 91.5k/91.5k [00:00<00:00, 416kB/s]\n",
            "ckpt: /root/.cache/modelscope/hub/iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/model.pt\n",
            "/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/funasr/train_utils/load_pretrained_model.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  src_state = torch.load(path, map_location=map_location)\n",
            "2025-04-28 13:54:33,553 - modelscope - INFO - Use user-specified model revision: v2.0.4\n",
            "Downloading: 100% 7.85k/7.85k [00:00<00:00, 27.5MB/s]\n",
            "Downloading: 100% 1.19k/1.19k [00:00<00:00, 6.34MB/s]\n",
            "Downloading: 100% 365/365 [00:00<00:00, 1.86MB/s]\n",
            "Downloading: 100% 1.64M/1.64M [00:00<00:00, 2.83MB/s]\n",
            "Downloading: 100% 8.45k/8.45k [00:00<00:00, 28.7MB/s]\n",
            "Downloading: 100% 27.3k/27.3k [00:00<00:00, 370kB/s]\n",
            "Downloading: 100% 2.16M/2.16M [00:00<00:00, 3.67MB/s]\n",
            "ckpt: /root/.cache/modelscope/hub/iic/speech_fsmn_vad_zh-cn-16k-common-pytorch/model.pt\n",
            "2025-04-28 13:54:44,022 - modelscope - INFO - Use user-specified model revision: v2.0.4\n",
            "Downloading: 100% 6.00k/6.00k [00:00<00:00, 18.1MB/s]\n",
            "Downloading: 100% 810/810 [00:00<00:00, 4.70MB/s]\n",
            "Downloading: 100% 373/373 [00:00<00:00, 1.65MB/s]\n",
            "Downloading: 100% 278M/278M [00:12<00:00, 23.6MB/s]\n",
            "Downloading: 100% 863/863 [00:00<00:00, 4.96MB/s]\n",
            "Downloading: 100% 11.2k/11.2k [00:00<00:00, 39.0MB/s]\n",
            "Downloading: 100% 151k/151k [00:00<00:00, 506kB/s]\n",
            "Downloading: 100% 4.01M/4.01M [00:00<00:00, 6.13MB/s]\n",
            "ckpt: /root/.cache/modelscope/hub/iic/punc_ct-transformer_zh-cn-common-vocab272727-pytorch/model.pt\n",
            "FunASR 模型加载完成: ZH\n",
            "  0% 0/9 [00:00<?, ?it/s]\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0000000000_0000498560.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  1.32it/s]\u001b[A\n",
            "{'load_data': '0.268', 'extract_feat': '0.165', 'forward': '0.759', 'batch_size': '1', 'rtf': '0.049'}, : 100% 1/1 [00:00<00:00,  1.32it/s]\u001b[A\n",
            "rtf_avg: 0.049: 100% 1/1 [00:00<00:00,  1.32it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/funasr/models/paraformer/model.py:249: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(False):\n",
            "/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/funasr/models/paraformer/cif_predictor.py:212: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(False):\n",
            "\n",
            "\n",
            "100% 1/1 [00:00<00:00,  1.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.019', 'forward': '0.952', 'batch_size': '1', 'rtf': '0.061'}, : 100% 1/1 [00:00<00:00,  1.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.061: 100% 1/1 [00:00<00:00,  1.05it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.068', 'batch_size': '1', 'rtf': '-0.068'}, : 100% 1/1 [00:00<00:00, 14.60it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.068: 100% 1/1 [00:00<00:00, 14.52it/s]\n",
            "\n",
            "100% 1/1 [00:01<00:00,  1.05s/it]\u001b[A\n",
            "rtf_avg: 0.066, time_speech:  15.580, time_escape: 1.028: 100% 1/1 [00:01<00:00,  1.05s/it]\n",
            " 11% 1/9 [00:01<00:14,  1.81s/it]\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0000498560_0000778880.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  5.49it/s]\u001b[A\n",
            "{'load_data': '0.042', 'extract_feat': '0.022', 'forward': '0.182', 'batch_size': '1', 'rtf': '0.021'}, : 100% 1/1 [00:00<00:00,  5.49it/s]\u001b[A\n",
            "rtf_avg: 0.021: 100% 1/1 [00:00<00:00,  5.45it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  4.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.022', 'forward': '0.205', 'batch_size': '1', 'rtf': '0.023'}, : 100% 1/1 [00:00<00:00,  4.88it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.023: 100% 1/1 [00:00<00:00,  4.82it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.018', 'batch_size': '1', 'rtf': '-0.018'}, : 100% 1/1 [00:00<00:00, 55.99it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.018: 100% 1/1 [00:00<00:00, 54.81it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  3.87it/s]\u001b[A\n",
            "rtf_avg: 0.027, time_speech:  8.760, time_escape: 0.233: 100% 1/1 [00:00<00:00,  3.86it/s]\n",
            " 22% 2/9 [00:02<00:07,  1.01s/it]\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0000778880_0001596160.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  2.20it/s]\u001b[A\n",
            "{'load_data': '0.056', 'extract_feat': '0.062', 'forward': '0.455', 'batch_size': '1', 'rtf': '0.018'}, : 100% 1/1 [00:00<00:00,  2.20it/s]\u001b[A\n",
            "rtf_avg: 0.018: 100% 1/1 [00:00<00:00,  2.19it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  3.15it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.042', 'forward': '0.317', 'batch_size': '1', 'rtf': '0.012'}, : 100% 1/1 [00:00<00:00,  3.15it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.012: 100% 1/1 [00:00<00:00,  3.13it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.034', 'batch_size': '1', 'rtf': '-0.034'}, : 100% 1/1 [00:00<00:00, 29.72it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.034: 100% 1/1 [00:00<00:00, 29.45it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  2.44it/s]\u001b[A\n",
            "rtf_avg: 0.014, time_speech:  25.540, time_escape: 0.361: 100% 1/1 [00:00<00:00,  2.44it/s]\n",
            " 33% 3/9 [00:03<00:05,  1.06it/s]\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0001596160_0002227200.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  3.03it/s]\u001b[A\n",
            "{'load_data': '0.046', 'extract_feat': '0.047', 'forward': '0.330', 'batch_size': '1', 'rtf': '0.017'}, : 100% 1/1 [00:00<00:00,  3.03it/s]\u001b[A\n",
            "rtf_avg: 0.017: 100% 1/1 [00:00<00:00,  3.02it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  3.46it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.039', 'forward': '0.289', 'batch_size': '1', 'rtf': '0.015'}, : 100% 1/1 [00:00<00:00,  3.46it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.015: 100% 1/1 [00:00<00:00,  3.45it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.040', 'batch_size': '1', 'rtf': '-0.040'}, : 100% 1/1 [00:00<00:00, 25.05it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.040: 100% 1/1 [00:00<00:00, 24.82it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  2.66it/s]\u001b[A\n",
            "rtf_avg: 0.017, time_speech:  19.720, time_escape: 0.339: 100% 1/1 [00:00<00:00,  2.66it/s]\n",
            " 44% 4/9 [00:03<00:04,  1.18it/s]\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0002227200_0002548480.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  5.04it/s]\u001b[A\n",
            "{'load_data': '0.034', 'extract_feat': '0.026', 'forward': '0.198', 'batch_size': '1', 'rtf': '0.020'}, : 100% 1/1 [00:00<00:00,  5.04it/s]\u001b[A\n",
            "rtf_avg: 0.020: 100% 1/1 [00:00<00:00,  5.01it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  4.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.022', 'forward': '0.223', 'batch_size': '1', 'rtf': '0.022'}, : 100% 1/1 [00:00<00:00,  4.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.022: 100% 1/1 [00:00<00:00,  4.32it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.021', 'batch_size': '1', 'rtf': '-0.021'}, : 100% 1/1 [00:00<00:00, 48.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.021: 100% 1/1 [00:00<00:00, 47.33it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  3.39it/s]\u001b[A\n",
            "rtf_avg: 0.026, time_speech:  10.040, time_escape: 0.261: 100% 1/1 [00:00<00:00,  3.39it/s]\n",
            " 56% 5/9 [00:04<00:02,  1.38it/s]\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0002548480_0002688000.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "{'load_data': '0.028', 'extract_feat': '0.018', 'forward': '0.089', 'batch_size': '1', 'rtf': '0.020'}, : 100% 1/1 [00:00<00:00, 11.26it/s]\u001b[A\n",
            "rtf_avg: 0.020: 100% 1/1 [00:00<00:00, 11.22it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  6.01it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.007', 'forward': '0.166', 'batch_size': '1', 'rtf': '0.038'}, : 100% 1/1 [00:00<00:00,  6.01it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.038: 100% 1/1 [00:00<00:00,  5.98it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.006', 'batch_size': '1', 'rtf': '-0.006'}, : 100% 1/1 [00:00<00:00, 151.85it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.006: 100% 1/1 [00:00<00:00, 146.27it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  5.20it/s]\u001b[A\n",
            "rtf_avg: 0.041, time_speech:  4.360, time_escape: 0.179: 100% 1/1 [00:00<00:00,  5.19it/s]\n",
            " 67% 6/9 [00:04<00:01,  1.74it/s]\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0002688000_0002827520.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "{'load_data': '0.017', 'extract_feat': '0.009', 'forward': '0.069', 'batch_size': '1', 'rtf': '0.016'}, : 100% 1/1 [00:00<00:00, 14.41it/s]\u001b[A\n",
            "rtf_avg: 0.016: 100% 1/1 [00:00<00:00, 14.35it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  9.95it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.007', 'forward': '0.100', 'batch_size': '1', 'rtf': '0.023'}, : 100% 1/1 [00:00<00:00,  9.95it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.023: 100% 1/1 [00:00<00:00,  9.79it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.006', 'batch_size': '1', 'rtf': '-0.006'}, : 100% 1/1 [00:00<00:00, 157.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.006: 100% 1/1 [00:00<00:00, 150.87it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.88it/s]\u001b[A\n",
            "rtf_avg: 0.026, time_speech:  4.360, time_escape: 0.113: 100% 1/1 [00:00<00:00,  7.86it/s]\n",
            " 78% 7/9 [00:04<00:00,  2.22it/s]\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0002827520_0003172800.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  6.65it/s]\u001b[A\n",
            "{'load_data': '0.021', 'extract_feat': '0.017', 'forward': '0.150', 'batch_size': '1', 'rtf': '0.014'}, : 100% 1/1 [00:00<00:00,  6.65it/s]\u001b[A\n",
            "rtf_avg: 0.014: 100% 1/1 [00:00<00:00,  6.63it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.014', 'forward': '0.137', 'batch_size': '1', 'rtf': '0.013'}, : 100% 1/1 [00:00<00:00,  7.28it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.013: 100% 1/1 [00:00<00:00,  7.24it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.013', 'batch_size': '1', 'rtf': '-0.013'}, : 100% 1/1 [00:00<00:00, 74.99it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.013: 100% 1/1 [00:00<00:00, 72.64it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  5.67it/s]\u001b[A\n",
            "rtf_avg: 0.015, time_speech:  10.790, time_escape: 0.157: 100% 1/1 [00:00<00:00,  5.66it/s]\n",
            " 89% 8/9 [00:05<00:00,  2.43it/s]\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0003172800_0003549440.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  7.05it/s]\u001b[A\n",
            "{'load_data': '0.025', 'extract_feat': '0.018', 'forward': '0.142', 'batch_size': '1', 'rtf': '0.012'}, : 100% 1/1 [00:00<00:00,  7.05it/s]\u001b[A\n",
            "rtf_avg: 0.012: 100% 1/1 [00:00<00:00,  7.00it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  6.98it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.014', 'forward': '0.143', 'batch_size': '1', 'rtf': '0.012'}, : 100% 1/1 [00:00<00:00,  6.98it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.012: 100% 1/1 [00:00<00:00,  6.95it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.014', 'batch_size': '1', 'rtf': '-0.014'}, : 100% 1/1 [00:00<00:00, 72.10it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.014: 100% 1/1 [00:00<00:00, 70.69it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  5.51it/s]\u001b[A\n",
            "rtf_avg: 0.014, time_speech:  11.762, time_escape: 0.163: 100% 1/1 [00:00<00:00,  5.50it/s]\n",
            "100% 9/9 [00:05<00:00,  1.65it/s]\n",
            "ASR 任务完成->标注文件路径: /content/GPT-SoVITS/output/asr_opt/slicer_opt.list\n",
            "\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" tools/subfix_webui.py --load_list \"/content/GPT-SoVITS/output/asr_opt/slicer_opt.list\" --webui_port 9871 --is_share True\n",
            "Running on local URL:  http://0.0.0.0:9871\n",
            "Running on public URL: https://0ba4e1d12d6ef3b334.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/prepare_datasets/1-get-text.py\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/prepare_datasets/1-get-text.py\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/prepare_datasets/2-get-hubert-wav32k.py\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/prepare_datasets/2-get-hubert-wav32k.py\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/prepare_datasets/3-get-semantic.py\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/prepare_datasets/3-get-semantic.py\n",
            "Tokenization & BERT Feature Extraction Process Terminated\n",
            "Tokenization & BERT Feature Extraction Process Terminated\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/queueing.py\", line 575, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/blocks.py\", line 1935, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/blocks.py\", line 1532, in call_function\n",
            "    prediction = await utils.async_iteration(iterator)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/utils.py\", line 671, in async_iteration\n",
            "    return await iterator.__anext__()\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/utils.py\", line 664, in __anext__\n",
            "    return await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/utils.py\", line 647, in run_sync_iterator_async\n",
            "    return next(iterator)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/utils.py\", line 809, in gen_wrapper\n",
            "    response = next(iterator)\n",
            "  File \"/content/GPT-SoVITS/webui.py\", line 904, in open1a\n",
            "    with open(txt_path, \"r\", encoding=\"utf8\") as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'logs/demo01/2-name2text-0.txt'\n",
            "Speech SSL Feature Extraction Process Terminated\n",
            "Speech SSL Feature Extraction Process Terminated\n",
            "Semantics Token Extraction Process Terminated\n",
            "Semantics Token Extraction Process Terminated\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/queueing.py\", line 575, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/blocks.py\", line 1935, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/blocks.py\", line 1532, in call_function\n",
            "    prediction = await utils.async_iteration(iterator)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/utils.py\", line 671, in async_iteration\n",
            "    return await iterator.__anext__()\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/utils.py\", line 664, in __anext__\n",
            "    return await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
            "    return await get_async_backend().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/utils.py\", line 647, in run_sync_iterator_async\n",
            "    return next(iterator)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/gradio/utils.py\", line 809, in gen_wrapper\n",
            "    response = next(iterator)\n",
            "  File \"/content/GPT-SoVITS/webui.py\", line 1063, in open1c\n",
            "    with open(semantic_path, \"r\", encoding=\"utf8\") as f:\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'logs/demo01/6-name2semantic-0.tsv'\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/prepare_datasets/1-get-text.py\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/prepare_datasets/1-get-text.py\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0000498560_0000778880.wav\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0000000000_0000498560.wav\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0001596160_0002227200.wav\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0000778880_0001596160.wav\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0002548480_0002688000.wav\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0002227200_0002548480.wav\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0002827520_0003172800.wav\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0002688000_0002827520.wav\n",
            "vocal_1-1.mp4.reformatted.wav_10.flac_0003172800_0003549440.wav\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/prepare_datasets/2-get-hubert-wav32k.py\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/prepare_datasets/2-get-hubert-wav32k.py\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/prepare_datasets/3-get-semantic.py\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/prepare_datasets/3-get-semantic.py\n",
            "<All keys matched successfully>\n",
            "<All keys matched successfully>\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/s2_train.py --config \"/content/GPT-SoVITS/TEMP/tmp_s2.json\"\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/s1_train.py --config_file \"/content/GPT-SoVITS/TEMP/tmp_s1.yaml\" \n",
            "Seed set to 1234\n",
            "/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:513: You passed `Trainer(accelerator='cpu', precision='16-mixed')` but AMP with fp16 is not supported on CPU. Using `precision='bf16-mixed'` instead.\n",
            "Using bfloat16 Automatic Mixed Precision (AMP)\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "/content/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_lightning_module.py:29: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "<All keys matched successfully>\n",
            "ckpt_path: None\n",
            "semantic_data_len: 9\n",
            "phoneme_data_len: 9\n",
            "                                           item_name                                     semantic_audio\n",
            "0  vocal_1-1.mp4.reformatted.wav_10.flac_00000000...  520 486 53 53 262 197 907 219 369 532 265 532 ...\n",
            "1  vocal_1-1.mp4.reformatted.wav_10.flac_00007788...  913 295 685 949 994 886 69 543 915 69 547 617 ...\n",
            "2  vocal_1-1.mp4.reformatted.wav_10.flac_00022272...  23 673 702 983 825 825 893 692 662 628 282 222...\n",
            "3  vocal_1-1.mp4.reformatted.wav_10.flac_00026880...  913 511 245 0 369 825 825 266 580 330 614 68 5...\n",
            "4  vocal_1-1.mp4.reformatted.wav_10.flac_00031728...  520 17 171 657 566 295 902 994 723 723 723 560...\n",
            "5  vocal_1-1.mp4.reformatted.wav_10.flac_00004985...  726 720 571 70 88 40 172 498 20 886 598 479 17...\n",
            "6  vocal_1-1.mp4.reformatted.wav_10.flac_00015961...  1012 479 735 803 81 835 621 378 589 1016 904 1...\n",
            "7  vocal_1-1.mp4.reformatted.wav_10.flac_00025484...  1005 775 90 582 132 612 642 229 19 869 19 894 ...\n",
            "8  vocal_1-1.mp4.reformatted.wav_10.flac_00028275...  913 596 411 560 893 893 661 266 266 580 621 56...\n",
            "dataset.__len__(): 99\n",
            "\n",
            "  | Name  | Type                 | Params | Mode \n",
            "-------------------------------------------------------\n",
            "0 | model | Text2SemanticDecoder | 77.6 M | train\n",
            "-------------------------------------------------------\n",
            "77.6 M    Trainable params\n",
            "0         Non-trainable params\n",
            "77.6 M    Total params\n",
            "310.426   Total estimated model params size (MB)\n",
            "257       Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/content/GPT-SoVITS/GPT_SoVITS/AR/data/dataset.py:224: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  bert_feature = torch.load(path_bert, map_location=\"cpu\")\n",
            "/content/GPT-SoVITS/GPT_SoVITS/AR/data/dataset.py:224: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  bert_feature = torch.load(path_bert, map_location=\"cpu\")\n",
            "/content/GPT-SoVITS/GPT_SoVITS/AR/data/dataset.py:224: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  bert_feature = torch.load(path_bert, map_location=\"cpu\")\n",
            "/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "Epoch 0:   0% 0/15 [00:00<?, ?it/s] /content/GPT-SoVITS/GPT_SoVITS/AR/data/dataset.py:224: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  bert_feature = torch.load(path_bert, map_location=\"cpu\")\n",
            "phoneme_data_len: 9\n",
            "wav_data_len: 99\n",
            "100% 99/99 [00:00<00:00, 26471.76it/s]\n",
            "skipped_phone:  0 , skipped_dur:  0\n",
            "total left:  99\n",
            "loaded pretrained GPT_SoVITS/pretrained_models/gsv-v2final-pretrained/s2G2333k.pth <All keys matched successfully>\n",
            "loaded pretrained GPT_SoVITS/pretrained_models/gsv-v2final-pretrained/s2D2333k.pth <All keys matched successfully>\n",
            "start training from epoch 1\n",
            "  0% 0/18 [00:00<?, ?it/s]GPT Training Process Terminated\n",
            "SoVITS Training Process Terminated\n",
            "/usr/local/envs/GPTSoVITS/lib/python3.10/multiprocessing/resource_tracker.py:224: UserWarning: resource_tracker: There appear to be 27 leaked semaphore objects to clean up at shutdown\n",
            "  warnings.warn('resource_tracker: There appear to be %d '\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/s2_train.py --config \"/content/GPT-SoVITS/TEMP/tmp_s2.json\"\n",
            "[rank: 0] Received SIGTERM: 15\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS/GPT_SoVITS/s1_train.py\", line 171, in <module>\n",
            "    main(args)\n",
            "  File \"/content/GPT-SoVITS/GPT_SoVITS/s1_train.py\", line 147, in main\n",
            "    trainer.fit(model, data_module, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 561, in fit\n",
            "    call._call_and_handle_interrupt(\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\", line 48, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 599, in _fit_impl\n",
            "    self._run(model, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1012, in _run\n",
            "    results = self._run_stage()\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1056, in _run_stage\n",
            "    self.fit_loop.run()\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py\", line 216, in run\n",
            "    self.advance()\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py\", line 455, in advance\n",
            "    self.epoch_loop.run(self._data_fetcher)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 150, in run\n",
            "    self.advance(data_fetcher)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 322, in advance\n",
            "    batch_output = self.manual_optimization.run(kwargs)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/manual.py\", line 94, in run\n",
            "    self.advance(kwargs)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/manual.py\", line 114, in advance\n",
            "    training_step_output = call._call_strategy_hook(trainer, \"training_step\", *kwargs.values())\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\", line 328, in _call_strategy_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py\", line 391, in training_step\n",
            "    return self.lightning_module.training_step(*args, **kwargs)\n",
            "  File \"/content/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_lightning_module.py\", line 45, in training_step\n",
            "    loss, acc = forward(\n",
            "  File \"/content/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_model.py\", line 501, in forward_old\n",
            "    xy_dec, _ = self.h(\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/GPT-SoVITS/GPT_SoVITS/AR/modules/transformer.py\", line 162, in forward\n",
            "    output = mod(\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/content/GPT-SoVITS/GPT_SoVITS/AR/modules/transformer.py\", line 298, in forward\n",
            "    x = self.norm2(x + self._ff_block(x), stage_embedding)\n",
            "  File \"/content/GPT-SoVITS/GPT_SoVITS/AR/modules/transformer.py\", line 329, in _ff_block\n",
            "    x = self.linear2(self.dropout(self.activation(self.linear1(x))))\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "  File \"/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/torch/utils/data/_utils/signal_handling.py\", line 73, in handler\n",
            "    _error_if_any_worker_fails()\n",
            "RuntimeError: DataLoader worker (pid 14490) is killed by signal: Terminated. \n",
            "Epoch 0:   0%|          | 0/15 [00:20<?, ?it/s]\n",
            "phoneme_data_len: 9\n",
            "wav_data_len: 99\n",
            "100% 99/99 [00:00<00:00, 73688.75it/s]\n",
            "skipped_phone:  0 , skipped_dur:  0\n",
            "total left:  99\n",
            "loaded pretrained GPT_SoVITS/pretrained_models/gsv-v2final-pretrained/s2G2333k.pth <All keys matched successfully>\n",
            "loaded pretrained GPT_SoVITS/pretrained_models/gsv-v2final-pretrained/s2D2333k.pth <All keys matched successfully>\n",
            "start training from epoch 1\n",
            "  0% 0/18 [00:00<?, ?it/s][rank0]:[W428 14:15:17.995674878 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
            "100% 18/18 [01:03<00:00,  3.56s/it]\n",
            "100% 18/18 [00:18<00:00,  1.05s/it]\n",
            "100% 18/18 [00:19<00:00,  1.07s/it]\n",
            "100% 18/18 [00:17<00:00,  1.01it/s]\n",
            "100% 18/18 [00:19<00:00,  1.06s/it]\n",
            "100% 18/18 [00:19<00:00,  1.08s/it]\n",
            "100% 18/18 [00:20<00:00,  1.13s/it]\n",
            "100% 18/18 [00:17<00:00,  1.01it/s]\n",
            "training done\n",
            "[rank0]:[W428 14:19:00.735671019 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/s1_train.py --config_file \"/content/GPT-SoVITS/TEMP/tmp_s1.yaml\" \n",
            "Seed set to 1234\n",
            "/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:513: You passed `Trainer(accelerator='cpu', precision='16-mixed')` but AMP with fp16 is not supported on CPU. Using `precision='bf16-mixed'` instead.\n",
            "Using bfloat16 Automatic Mixed Precision (AMP)\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "/content/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_lightning_module.py:29: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "<All keys matched successfully>\n",
            "ckpt_path: None\n",
            "semantic_data_len: 9\n",
            "phoneme_data_len: 9\n",
            "                                           item_name                                     semantic_audio\n",
            "0  vocal_1-1.mp4.reformatted.wav_10.flac_00000000...  520 486 53 53 262 197 907 219 369 532 265 532 ...\n",
            "1  vocal_1-1.mp4.reformatted.wav_10.flac_00007788...  913 295 685 949 994 886 69 543 915 69 547 617 ...\n",
            "2  vocal_1-1.mp4.reformatted.wav_10.flac_00022272...  23 673 702 983 825 825 893 692 662 628 282 222...\n",
            "3  vocal_1-1.mp4.reformatted.wav_10.flac_00026880...  913 511 245 0 369 825 825 266 580 330 614 68 5...\n",
            "4  vocal_1-1.mp4.reformatted.wav_10.flac_00031728...  520 17 171 657 566 295 902 994 723 723 723 560...\n",
            "5  vocal_1-1.mp4.reformatted.wav_10.flac_00004985...  726 720 571 70 88 40 172 498 20 886 598 479 17...\n",
            "6  vocal_1-1.mp4.reformatted.wav_10.flac_00015961...  1012 479 735 803 81 835 621 378 589 1016 904 1...\n",
            "7  vocal_1-1.mp4.reformatted.wav_10.flac_00025484...  1005 775 90 582 132 612 642 229 19 869 19 894 ...\n",
            "8  vocal_1-1.mp4.reformatted.wav_10.flac_00028275...  913 596 411 560 893 893 661 266 266 580 621 56...\n",
            "dataset.__len__(): 99\n",
            "\n",
            "  | Name  | Type                 | Params | Mode \n",
            "-------------------------------------------------------\n",
            "0 | model | Text2SemanticDecoder | 77.6 M | train\n",
            "-------------------------------------------------------\n",
            "77.6 M    Trainable params\n",
            "0         Non-trainable params\n",
            "77.6 M    Total params\n",
            "310.426   Total estimated model params size (MB)\n",
            "257       Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/content/GPT-SoVITS/GPT_SoVITS/AR/data/dataset.py:224: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  bert_feature = torch.load(path_bert, map_location=\"cpu\")\n",
            "/content/GPT-SoVITS/GPT_SoVITS/AR/data/dataset.py:224: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  bert_feature = torch.load(path_bert, map_location=\"cpu\")\n",
            "/content/GPT-SoVITS/GPT_SoVITS/AR/data/dataset.py:224: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  bert_feature = torch.load(path_bert, map_location=\"cpu\")\n",
            "/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (15) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "Epoch 0:   0% 0/15 [00:00<?, ?it/s] /content/GPT-SoVITS/GPT_SoVITS/AR/data/dataset.py:224: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  bert_feature = torch.load(path_bert, map_location=\"cpu\")\n",
            "Killed\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/s2_train.py --config \"/content/GPT-SoVITS/TEMP/tmp_s2.json\"\n",
            "phoneme_data_len: 9\n",
            "wav_data_len: 99\n",
            "100% 99/99 [00:00<00:00, 68702.20it/s]\n",
            "skipped_phone:  0 , skipped_dur:  0\n",
            "total left:  99\n",
            "logs/demo01/logs_s2_v2/D_233333333333.pth\n",
            "load \n",
            "logs/demo01/logs_s2_v2/G_233333333333.pth\n",
            "load \n",
            "start training from epoch 9\n",
            "training done\n",
            "[rank0]:[W428 14:26:49.563475096 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/s1_train.py --config_file \"/content/GPT-SoVITS/TEMP/tmp_s1.yaml\" \n",
            "Seed set to 1234\n",
            "/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:513: You passed `Trainer(accelerator='cpu', precision='16-mixed')` but AMP with fp16 is not supported on CPU. Using `precision='bf16-mixed'` instead.\n",
            "Using bfloat16 Automatic Mixed Precision (AMP)\n",
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "/content/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_lightning_module.py:29: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "<All keys matched successfully>\n",
            "ckpt_path: None\n",
            "semantic_data_len: 9\n",
            "phoneme_data_len: 9\n",
            "                                           item_name                                     semantic_audio\n",
            "0  vocal_1-1.mp4.reformatted.wav_10.flac_00000000...  520 486 53 53 262 197 907 219 369 532 265 532 ...\n",
            "1  vocal_1-1.mp4.reformatted.wav_10.flac_00007788...  913 295 685 949 994 886 69 543 915 69 547 617 ...\n",
            "2  vocal_1-1.mp4.reformatted.wav_10.flac_00022272...  23 673 702 983 825 825 893 692 662 628 282 222...\n",
            "3  vocal_1-1.mp4.reformatted.wav_10.flac_00026880...  913 511 245 0 369 825 825 266 580 330 614 68 5...\n",
            "4  vocal_1-1.mp4.reformatted.wav_10.flac_00031728...  520 17 171 657 566 295 902 994 723 723 723 560...\n",
            "5  vocal_1-1.mp4.reformatted.wav_10.flac_00004985...  726 720 571 70 88 40 172 498 20 886 598 479 17...\n",
            "6  vocal_1-1.mp4.reformatted.wav_10.flac_00015961...  1012 479 735 803 81 835 621 378 589 1016 904 1...\n",
            "7  vocal_1-1.mp4.reformatted.wav_10.flac_00025484...  1005 775 90 582 132 612 642 229 19 869 19 894 ...\n",
            "8  vocal_1-1.mp4.reformatted.wav_10.flac_00028275...  913 596 411 560 893 893 661 266 266 580 621 56...\n",
            "dataset.__len__(): 99\n",
            "\n",
            "  | Name  | Type                 | Params | Mode \n",
            "-------------------------------------------------------\n",
            "0 | model | Text2SemanticDecoder | 77.6 M | train\n",
            "-------------------------------------------------------\n",
            "77.6 M    Trainable params\n",
            "0         Non-trainable params\n",
            "77.6 M    Total params\n",
            "310.426   Total estimated model params size (MB)\n",
            "257       Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/content/GPT-SoVITS/GPT_SoVITS/AR/data/dataset.py:224: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  bert_feature = torch.load(path_bert, map_location=\"cpu\")\n",
            "/content/GPT-SoVITS/GPT_SoVITS/AR/data/dataset.py:224: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  bert_feature = torch.load(path_bert, map_location=\"cpu\")\n",
            "/content/GPT-SoVITS/GPT_SoVITS/AR/data/dataset.py:224: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  bert_feature = torch.load(path_bert, map_location=\"cpu\")\n",
            "/usr/local/envs/GPTSoVITS/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (17) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "Epoch 0:   0% 0/17 [00:00<?, ?it/s] /content/GPT-SoVITS/GPT_SoVITS/AR/data/dataset.py:224: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  bert_feature = torch.load(path_bert, map_location=\"cpu\")\n",
            "Killed\n",
            "\"/usr/local/envs/GPTSoVITS/bin/python\" GPT_SoVITS/inference_webui_fast.py \"Auto\"\n",
            "---------------------------------------------TTS Config---------------------------------------------\n",
            "device              : cuda\n",
            "is_half             : True\n",
            "version             : v2\n",
            "t2s_weights_path    : GPT_SoVITS/pretrained_models/s1bert25hz-2kh-longer-epoch=68e-step=50232.ckpt\n",
            "vits_weights_path   : GPT_SoVITS/pretrained_models/s2G488k.pth\n",
            "bert_base_path      : GPT_SoVITS/pretrained_models/chinese-roberta-wwm-ext-large\n",
            "cnhuhbert_base_path : GPT_SoVITS/pretrained_models/chinese-hubert-base\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "Loading Text2Semantic weights from GPT_SoVITS/pretrained_models/s1bert25hz-2kh-longer-epoch=68e-step=50232.ckpt\n",
            "Loading VITS weights from GPT_SoVITS/pretrained_models/s2G488k.pth. <All keys matched successfully>\n",
            "Loading BERT weights from GPT_SoVITS/pretrained_models/chinese-roberta-wwm-ext-large\n",
            "Loading CNHuBERT weights from GPT_SoVITS/pretrained_models/chinese-hubert-base\n",
            "Running on local URL:  http://0.0.0.0:9872\n",
            "Running on public URL: https://68f7898763c5d8b4fe.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "Set seed to 3705959594\n",
            "Parallel Inference Mode Enabled\n",
            "Bucket Processing Mode Enabled\n",
            "Actual Input Reference Text: 我是恕瑞玛的黎明。\n",
            "############ Segment Text ############\n",
            "Actual Input Target Text:\n",
            "德玛西亚 你们的皇帝回来了\n",
            "Actual Input Target Text (after sentence segmentation):\n",
            "['德玛西亚 你们的皇帝回来了。']\n",
            "############ Extract Text BERT Features ############\n",
            "100% 1/1 [00:00<00:00, 26.39it/s]\n",
            "############ 推理 ############\n",
            "Processed text from the frontend (per sentence): ['德玛西亚你们的皇帝回来了.']\n",
            "############ 预测语义Token ############\n",
            "  5% 77/1500 [00:01<00:17, 80.60it/s]T2S Decoding EOS [123 -> 209]\n",
            "  6% 85/1500 [00:01<00:23, 59.91it/s]\n",
            "############ 合成音频 ############\n",
            "并行合成中...\n",
            "10.660\t0.041\t1.533\t0.878\n",
            "Set seed to 2779154054\n",
            "Parallel Inference Mode Disabled\n",
            "Bucket Processing Mode Enabled\n",
            "Actual Input Reference Text: 我是恕瑞玛的黎明。\n",
            "############ Segment Text ############\n",
            "Actual Input Target Text:\n",
            "德玛西亚，你们的皇帝回来了\n",
            "Actual Input Target Text (after sentence segmentation):\n",
            "['德玛西亚，你们的皇帝回来了。']\n",
            "############ Extract Text BERT Features ############\n",
            "100% 1/1 [00:00<00:00, 15.49it/s]\n",
            "############ 推理 ############\n",
            "Processed text from the frontend (per sentence): ['德玛西亚,你们的皇帝回来了.']\n",
            "############ 预测语义Token ############\n",
            "  8% 125/1500 [00:01<00:13, 104.84it/s]T2S Decoding EOS [123 -> 257]\n",
            "  9% 133/1500 [00:01<00:15, 91.11it/s] \n",
            "############ 合成音频 ############\n",
            "并行合成中...\n",
            "0.000\t0.066\t1.462\t0.254\n",
            "Set seed to 2458041581\n",
            "Parallel Inference Mode Disabled\n",
            "Bucket Processing Mode Enabled\n",
            "Actual Input Reference Text: 我是恕瑞玛的黎明。\n",
            "############ Segment Text ############\n",
            "Actual Input Target Text:\n",
            "德玛西亚，你们的皇帝回来了\n",
            "Actual Input Target Text (after sentence segmentation):\n",
            "['德玛西亚，你们的皇帝回来了。']\n",
            "############ Extract Text BERT Features ############\n",
            "100% 1/1 [00:00<00:00, 25.72it/s]\n",
            "############ 推理 ############\n",
            "Processed text from the frontend (per sentence): ['德玛西亚,你们的皇帝回来了.']\n",
            "############ 预测语义Token ############\n",
            "  8% 124/1500 [00:01<00:16, 82.90it/s]T2S Decoding EOS [123 -> 249]\n",
            "  8% 125/1500 [00:01<00:15, 90.30it/s]\n",
            "############ 合成音频 ############\n",
            "并行合成中...\n",
            "0.000\t0.040\t1.386\t0.753\n",
            "Set seed to 2071734650\n",
            "Parallel Inference Mode Disabled\n",
            "Bucket Processing Mode Disabled\n",
            "Actual Input Reference Text: 我是恕瑞玛的黎明。\n",
            "############ Segment Text ############\n",
            "Actual Input Target Text:\n",
            "德玛西亚，你们的皇帝回来了\n",
            "Actual Input Target Text (after sentence segmentation):\n",
            "['德玛西亚，你们的皇帝回来了。']\n",
            "############ Extract Text BERT Features ############\n",
            "100% 1/1 [00:00<00:00, 25.68it/s]\n",
            "############ 推理 ############\n",
            "Processed text from the frontend (per sentence): ['德玛西亚,你们的皇帝回来了.']\n",
            "############ 预测语义Token ############\n",
            "  9% 136/1500 [00:01<00:12, 108.28it/s]T2S Decoding EOS [123 -> 266]\n",
            "  9% 142/1500 [00:01<00:12, 106.71it/s]\n",
            "############ 合成音频 ############\n",
            "并行合成中...\n",
            "0.000\t0.040\t1.332\t0.158\n"
          ]
        }
      ],
      "source": [
        "!cd /content/GPT-SoVITS && source activate GPTSoVITS && export is_share=True && python webui.py"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}